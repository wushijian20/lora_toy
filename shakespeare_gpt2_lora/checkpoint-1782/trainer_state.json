{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1782,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08417508417508418,
      "grad_norm": 0.6402638554573059,
      "learning_rate": 0.00029175084175084174,
      "loss": 4.3855,
      "step": 50
    },
    {
      "epoch": 0.16835016835016836,
      "grad_norm": 0.7176704406738281,
      "learning_rate": 0.0002833333333333333,
      "loss": 4.0863,
      "step": 100
    },
    {
      "epoch": 0.25252525252525254,
      "grad_norm": 0.8290733098983765,
      "learning_rate": 0.00027491582491582486,
      "loss": 3.9745,
      "step": 150
    },
    {
      "epoch": 0.3367003367003367,
      "grad_norm": 0.6909710764884949,
      "learning_rate": 0.0002664983164983165,
      "loss": 3.8978,
      "step": 200
    },
    {
      "epoch": 0.4208754208754209,
      "grad_norm": 0.7226698398590088,
      "learning_rate": 0.00025808080808080805,
      "loss": 3.9411,
      "step": 250
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 0.7139084935188293,
      "learning_rate": 0.00024966329966329967,
      "loss": 3.9027,
      "step": 300
    },
    {
      "epoch": 0.5892255892255892,
      "grad_norm": 0.773926854133606,
      "learning_rate": 0.0002412457912457912,
      "loss": 3.8663,
      "step": 350
    },
    {
      "epoch": 0.6734006734006734,
      "grad_norm": 0.8037477731704712,
      "learning_rate": 0.0002328282828282828,
      "loss": 3.8851,
      "step": 400
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 0.8151893019676208,
      "learning_rate": 0.00022441077441077439,
      "loss": 3.8417,
      "step": 450
    },
    {
      "epoch": 0.8417508417508418,
      "grad_norm": 0.7317604422569275,
      "learning_rate": 0.00021599326599326598,
      "loss": 3.8678,
      "step": 500
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.7892307639122009,
      "learning_rate": 0.00020757575757575757,
      "loss": 3.8451,
      "step": 550
    },
    {
      "epoch": 1.0,
      "eval_loss": 3.748555898666382,
      "eval_runtime": 0.7982,
      "eval_samples_per_second": 330.727,
      "eval_steps_per_second": 41.341,
      "step": 594
    },
    {
      "epoch": 1.0101010101010102,
      "grad_norm": 0.9771547913551331,
      "learning_rate": 0.00019915824915824916,
      "loss": 3.847,
      "step": 600
    },
    {
      "epoch": 1.0942760942760943,
      "grad_norm": 0.7855883240699768,
      "learning_rate": 0.00019074074074074073,
      "loss": 3.8035,
      "step": 650
    },
    {
      "epoch": 1.1784511784511784,
      "grad_norm": 0.8686173558235168,
      "learning_rate": 0.0001823232323232323,
      "loss": 3.8659,
      "step": 700
    },
    {
      "epoch": 1.2626262626262625,
      "grad_norm": 0.8600142598152161,
      "learning_rate": 0.00017390572390572388,
      "loss": 3.7311,
      "step": 750
    },
    {
      "epoch": 1.3468013468013469,
      "grad_norm": 0.7987275719642639,
      "learning_rate": 0.00016548821548821547,
      "loss": 3.839,
      "step": 800
    },
    {
      "epoch": 1.430976430976431,
      "grad_norm": 0.8306595683097839,
      "learning_rate": 0.00015707070707070706,
      "loss": 3.8205,
      "step": 850
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 0.9785406589508057,
      "learning_rate": 0.00014865319865319866,
      "loss": 3.8611,
      "step": 900
    },
    {
      "epoch": 1.5993265993265995,
      "grad_norm": 0.9926576614379883,
      "learning_rate": 0.00014023569023569022,
      "loss": 3.7791,
      "step": 950
    },
    {
      "epoch": 1.6835016835016834,
      "grad_norm": 0.7954939007759094,
      "learning_rate": 0.0001318181818181818,
      "loss": 3.8111,
      "step": 1000
    },
    {
      "epoch": 1.7676767676767677,
      "grad_norm": 0.9302150011062622,
      "learning_rate": 0.0001234006734006734,
      "loss": 3.7173,
      "step": 1050
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.9347680807113647,
      "learning_rate": 0.00011498316498316497,
      "loss": 3.7609,
      "step": 1100
    },
    {
      "epoch": 1.936026936026936,
      "grad_norm": 0.8606362342834473,
      "learning_rate": 0.00010656565656565656,
      "loss": 3.7583,
      "step": 1150
    },
    {
      "epoch": 2.0,
      "eval_loss": 3.6935956478118896,
      "eval_runtime": 0.866,
      "eval_samples_per_second": 304.854,
      "eval_steps_per_second": 38.107,
      "step": 1188
    },
    {
      "epoch": 2.0202020202020203,
      "grad_norm": 0.8352904915809631,
      "learning_rate": 9.814814814814814e-05,
      "loss": 3.7477,
      "step": 1200
    },
    {
      "epoch": 2.1043771043771042,
      "grad_norm": 0.795225203037262,
      "learning_rate": 8.973063973063973e-05,
      "loss": 3.8203,
      "step": 1250
    },
    {
      "epoch": 2.1885521885521886,
      "grad_norm": 0.8762179017066956,
      "learning_rate": 8.13131313131313e-05,
      "loss": 3.7843,
      "step": 1300
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 1.0512267351150513,
      "learning_rate": 7.289562289562288e-05,
      "loss": 3.6851,
      "step": 1350
    },
    {
      "epoch": 2.356902356902357,
      "grad_norm": 0.9096311330795288,
      "learning_rate": 6.447811447811448e-05,
      "loss": 3.6712,
      "step": 1400
    },
    {
      "epoch": 2.441077441077441,
      "grad_norm": 0.9246127605438232,
      "learning_rate": 5.606060606060606e-05,
      "loss": 3.7433,
      "step": 1450
    },
    {
      "epoch": 2.525252525252525,
      "grad_norm": 0.9426774978637695,
      "learning_rate": 4.764309764309764e-05,
      "loss": 3.7445,
      "step": 1500
    },
    {
      "epoch": 2.6094276094276094,
      "grad_norm": 0.9425538182258606,
      "learning_rate": 3.922558922558922e-05,
      "loss": 3.7491,
      "step": 1550
    },
    {
      "epoch": 2.6936026936026938,
      "grad_norm": 0.8448057770729065,
      "learning_rate": 3.080808080808081e-05,
      "loss": 3.718,
      "step": 1600
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 1.0009710788726807,
      "learning_rate": 2.2390572390572386e-05,
      "loss": 3.8399,
      "step": 1650
    },
    {
      "epoch": 2.861952861952862,
      "grad_norm": 0.9153834581375122,
      "learning_rate": 1.3973063973063973e-05,
      "loss": 3.7012,
      "step": 1700
    },
    {
      "epoch": 2.9461279461279464,
      "grad_norm": 0.9201978445053101,
      "learning_rate": 5.555555555555555e-06,
      "loss": 3.7474,
      "step": 1750
    }
  ],
  "logging_steps": 50,
  "max_steps": 1782,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 468851276906496.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
