{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1782,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08417508417508418,
      "grad_norm": 0.6422441601753235,
      "learning_rate": 0.00029175084175084174,
      "loss": 4.3829,
      "step": 50
    },
    {
      "epoch": 0.16835016835016836,
      "grad_norm": 0.6934662461280823,
      "learning_rate": 0.0002833333333333333,
      "loss": 4.0838,
      "step": 100
    },
    {
      "epoch": 0.25252525252525254,
      "grad_norm": 0.8600949645042419,
      "learning_rate": 0.00027491582491582486,
      "loss": 3.9732,
      "step": 150
    },
    {
      "epoch": 0.3367003367003367,
      "grad_norm": 0.6973191499710083,
      "learning_rate": 0.0002664983164983165,
      "loss": 3.8971,
      "step": 200
    },
    {
      "epoch": 0.4208754208754209,
      "grad_norm": 0.7268248796463013,
      "learning_rate": 0.00025808080808080805,
      "loss": 3.9411,
      "step": 250
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 0.6963949799537659,
      "learning_rate": 0.00024966329966329967,
      "loss": 3.9025,
      "step": 300
    },
    {
      "epoch": 0.5892255892255892,
      "grad_norm": 0.7925378680229187,
      "learning_rate": 0.0002412457912457912,
      "loss": 3.8667,
      "step": 350
    },
    {
      "epoch": 0.6734006734006734,
      "grad_norm": 0.8329005241394043,
      "learning_rate": 0.0002328282828282828,
      "loss": 3.8853,
      "step": 400
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 0.8325341939926147,
      "learning_rate": 0.00022441077441077439,
      "loss": 3.8436,
      "step": 450
    },
    {
      "epoch": 0.8417508417508418,
      "grad_norm": 0.7504794001579285,
      "learning_rate": 0.00021599326599326598,
      "loss": 3.8678,
      "step": 500
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.7906916737556458,
      "learning_rate": 0.00020757575757575757,
      "loss": 3.8459,
      "step": 550
    },
    {
      "epoch": 1.0,
      "eval_loss": 3.7508347034454346,
      "eval_runtime": 0.8769,
      "eval_samples_per_second": 301.072,
      "eval_steps_per_second": 37.634,
      "step": 594
    },
    {
      "epoch": 1.0101010101010102,
      "grad_norm": 1.102588415145874,
      "learning_rate": 0.00019915824915824916,
      "loss": 3.8469,
      "step": 600
    },
    {
      "epoch": 1.0942760942760943,
      "grad_norm": 0.8275116682052612,
      "learning_rate": 0.00019074074074074073,
      "loss": 3.8029,
      "step": 650
    },
    {
      "epoch": 1.1784511784511784,
      "grad_norm": 0.8502169847488403,
      "learning_rate": 0.0001823232323232323,
      "loss": 3.8662,
      "step": 700
    },
    {
      "epoch": 1.2626262626262625,
      "grad_norm": 0.8773718476295471,
      "learning_rate": 0.00017390572390572388,
      "loss": 3.7323,
      "step": 750
    },
    {
      "epoch": 1.3468013468013469,
      "grad_norm": 0.7739614248275757,
      "learning_rate": 0.00016548821548821547,
      "loss": 3.8378,
      "step": 800
    },
    {
      "epoch": 1.430976430976431,
      "grad_norm": 0.8226134181022644,
      "learning_rate": 0.00015707070707070706,
      "loss": 3.8218,
      "step": 850
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 1.0120906829833984,
      "learning_rate": 0.00014865319865319866,
      "loss": 3.8625,
      "step": 900
    },
    {
      "epoch": 1.5993265993265995,
      "grad_norm": 1.0346189737319946,
      "learning_rate": 0.00014023569023569022,
      "loss": 3.7787,
      "step": 950
    },
    {
      "epoch": 1.6835016835016834,
      "grad_norm": 0.8100800514221191,
      "learning_rate": 0.0001318181818181818,
      "loss": 3.8116,
      "step": 1000
    },
    {
      "epoch": 1.7676767676767677,
      "grad_norm": 0.9261299967765808,
      "learning_rate": 0.0001234006734006734,
      "loss": 3.7176,
      "step": 1050
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.9217208623886108,
      "learning_rate": 0.00011498316498316497,
      "loss": 3.7618,
      "step": 1100
    },
    {
      "epoch": 1.936026936026936,
      "grad_norm": 0.8525938987731934,
      "learning_rate": 0.00010656565656565656,
      "loss": 3.7584,
      "step": 1150
    },
    {
      "epoch": 2.0,
      "eval_loss": 3.694932699203491,
      "eval_runtime": 0.8339,
      "eval_samples_per_second": 316.6,
      "eval_steps_per_second": 39.575,
      "step": 1188
    },
    {
      "epoch": 2.0202020202020203,
      "grad_norm": 0.8404818177223206,
      "learning_rate": 9.814814814814814e-05,
      "loss": 3.7477,
      "step": 1200
    },
    {
      "epoch": 2.1043771043771042,
      "grad_norm": 0.7944558262825012,
      "learning_rate": 8.973063973063973e-05,
      "loss": 3.8199,
      "step": 1250
    },
    {
      "epoch": 2.1885521885521886,
      "grad_norm": 0.8979241847991943,
      "learning_rate": 8.13131313131313e-05,
      "loss": 3.7862,
      "step": 1300
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 1.07011079788208,
      "learning_rate": 7.289562289562288e-05,
      "loss": 3.6851,
      "step": 1350
    },
    {
      "epoch": 2.356902356902357,
      "grad_norm": 1.015110969543457,
      "learning_rate": 6.447811447811448e-05,
      "loss": 3.6702,
      "step": 1400
    },
    {
      "epoch": 2.441077441077441,
      "grad_norm": 0.9700049161911011,
      "learning_rate": 5.606060606060606e-05,
      "loss": 3.7438,
      "step": 1450
    },
    {
      "epoch": 2.525252525252525,
      "grad_norm": 0.9283174276351929,
      "learning_rate": 4.764309764309764e-05,
      "loss": 3.7458,
      "step": 1500
    },
    {
      "epoch": 2.6094276094276094,
      "grad_norm": 0.9661673307418823,
      "learning_rate": 3.922558922558922e-05,
      "loss": 3.7489,
      "step": 1550
    },
    {
      "epoch": 2.6936026936026938,
      "grad_norm": 0.8651089072227478,
      "learning_rate": 3.080808080808081e-05,
      "loss": 3.7161,
      "step": 1600
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 1.047115683555603,
      "learning_rate": 2.2390572390572386e-05,
      "loss": 3.8395,
      "step": 1650
    },
    {
      "epoch": 2.861952861952862,
      "grad_norm": 0.908147931098938,
      "learning_rate": 1.3973063973063973e-05,
      "loss": 3.7033,
      "step": 1700
    },
    {
      "epoch": 2.9461279461279464,
      "grad_norm": 0.9262121319770813,
      "learning_rate": 5.555555555555555e-06,
      "loss": 3.7485,
      "step": 1750
    }
  ],
  "logging_steps": 50,
  "max_steps": 1782,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 468851276906496.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
