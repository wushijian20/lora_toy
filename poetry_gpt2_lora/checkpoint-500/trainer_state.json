{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.16041065126724416,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003208213025344883,
      "grad_norm": 0.9929807782173157,
      "learning_rate": 0.00019980750721847933,
      "loss": 6.6175,
      "step": 10
    },
    {
      "epoch": 0.006416426050689766,
      "grad_norm": 1.3569743633270264,
      "learning_rate": 0.000199593626350123,
      "loss": 6.4576,
      "step": 20
    },
    {
      "epoch": 0.009624639076034648,
      "grad_norm": 1.9002569913864136,
      "learning_rate": 0.00019937974548176667,
      "loss": 5.9434,
      "step": 30
    },
    {
      "epoch": 0.012832852101379532,
      "grad_norm": 2.187473773956299,
      "learning_rate": 0.00019916586461341034,
      "loss": 4.9691,
      "step": 40
    },
    {
      "epoch": 0.016041065126724416,
      "grad_norm": 1.5395301580429077,
      "learning_rate": 0.000198951983745054,
      "loss": 5.1283,
      "step": 50
    },
    {
      "epoch": 0.019249278152069296,
      "grad_norm": 1.0944130420684814,
      "learning_rate": 0.0001987381028766977,
      "loss": 5.014,
      "step": 60
    },
    {
      "epoch": 0.02245749117741418,
      "grad_norm": 1.463235855102539,
      "learning_rate": 0.00019852422200834134,
      "loss": 4.8141,
      "step": 70
    },
    {
      "epoch": 0.025665704202759064,
      "grad_norm": 1.5792930126190186,
      "learning_rate": 0.00019831034113998504,
      "loss": 4.8278,
      "step": 80
    },
    {
      "epoch": 0.028873917228103944,
      "grad_norm": 1.4631986618041992,
      "learning_rate": 0.0001980964602716287,
      "loss": 4.6946,
      "step": 90
    },
    {
      "epoch": 0.03208213025344883,
      "grad_norm": 1.7708677053451538,
      "learning_rate": 0.0001978825794032724,
      "loss": 4.5593,
      "step": 100
    },
    {
      "epoch": 0.03529034327879371,
      "grad_norm": 1.3442966938018799,
      "learning_rate": 0.00019766869853491605,
      "loss": 4.5715,
      "step": 110
    },
    {
      "epoch": 0.03849855630413859,
      "grad_norm": 3.7381999492645264,
      "learning_rate": 0.00019745481766655974,
      "loss": 4.361,
      "step": 120
    },
    {
      "epoch": 0.04170676932948348,
      "grad_norm": 1.6169660091400146,
      "learning_rate": 0.0001972409367982034,
      "loss": 4.3992,
      "step": 130
    },
    {
      "epoch": 0.04491498235482836,
      "grad_norm": 1.7813392877578735,
      "learning_rate": 0.00019702705592984708,
      "loss": 4.5034,
      "step": 140
    },
    {
      "epoch": 0.04812319538017324,
      "grad_norm": 1.304078221321106,
      "learning_rate": 0.00019681317506149075,
      "loss": 4.6195,
      "step": 150
    },
    {
      "epoch": 0.05133140840551813,
      "grad_norm": 1.8750945329666138,
      "learning_rate": 0.00019659929419313442,
      "loss": 4.2862,
      "step": 160
    },
    {
      "epoch": 0.05453962143086301,
      "grad_norm": 1.4983075857162476,
      "learning_rate": 0.00019638541332477811,
      "loss": 4.3601,
      "step": 170
    },
    {
      "epoch": 0.05774783445620789,
      "grad_norm": 1.5268137454986572,
      "learning_rate": 0.00019617153245642178,
      "loss": 4.443,
      "step": 180
    },
    {
      "epoch": 0.060956047481552776,
      "grad_norm": 1.523414134979248,
      "learning_rate": 0.00019595765158806545,
      "loss": 4.4724,
      "step": 190
    },
    {
      "epoch": 0.06416426050689766,
      "grad_norm": 1.7114750146865845,
      "learning_rate": 0.00019574377071970912,
      "loss": 4.4758,
      "step": 200
    },
    {
      "epoch": 0.06737247353224254,
      "grad_norm": 2.3549723625183105,
      "learning_rate": 0.00019552988985135282,
      "loss": 4.4372,
      "step": 210
    },
    {
      "epoch": 0.07058068655758742,
      "grad_norm": 2.8332765102386475,
      "learning_rate": 0.0001953160089829965,
      "loss": 4.4495,
      "step": 220
    },
    {
      "epoch": 0.0737888995829323,
      "grad_norm": 2.200261354446411,
      "learning_rate": 0.00019510212811464016,
      "loss": 4.3283,
      "step": 230
    },
    {
      "epoch": 0.07699711260827719,
      "grad_norm": 1.7542457580566406,
      "learning_rate": 0.00019488824724628383,
      "loss": 4.3585,
      "step": 240
    },
    {
      "epoch": 0.08020532563362208,
      "grad_norm": 2.2906546592712402,
      "learning_rate": 0.00019467436637792752,
      "loss": 4.3102,
      "step": 250
    },
    {
      "epoch": 0.08341353865896696,
      "grad_norm": 3.6942086219787598,
      "learning_rate": 0.0001944604855095712,
      "loss": 4.515,
      "step": 260
    },
    {
      "epoch": 0.08662175168431184,
      "grad_norm": 1.9311494827270508,
      "learning_rate": 0.00019424660464121486,
      "loss": 4.0416,
      "step": 270
    },
    {
      "epoch": 0.08982996470965672,
      "grad_norm": 3.2551963329315186,
      "learning_rate": 0.00019403272377285853,
      "loss": 4.2073,
      "step": 280
    },
    {
      "epoch": 0.0930381777350016,
      "grad_norm": 2.0594606399536133,
      "learning_rate": 0.0001938188429045022,
      "loss": 4.0984,
      "step": 290
    },
    {
      "epoch": 0.09624639076034648,
      "grad_norm": 2.2760660648345947,
      "learning_rate": 0.0001936049620361459,
      "loss": 4.291,
      "step": 300
    },
    {
      "epoch": 0.09945460378569138,
      "grad_norm": 1.9606152772903442,
      "learning_rate": 0.00019339108116778954,
      "loss": 4.0656,
      "step": 310
    },
    {
      "epoch": 0.10266281681103626,
      "grad_norm": 1.33408522605896,
      "learning_rate": 0.00019317720029943323,
      "loss": 4.2605,
      "step": 320
    },
    {
      "epoch": 0.10587102983638114,
      "grad_norm": 3.5272436141967773,
      "learning_rate": 0.0001929633194310769,
      "loss": 4.0691,
      "step": 330
    },
    {
      "epoch": 0.10907924286172602,
      "grad_norm": 3.050316333770752,
      "learning_rate": 0.00019274943856272057,
      "loss": 4.1776,
      "step": 340
    },
    {
      "epoch": 0.1122874558870709,
      "grad_norm": 1.6468826532363892,
      "learning_rate": 0.00019253555769436424,
      "loss": 4.405,
      "step": 350
    },
    {
      "epoch": 0.11549566891241578,
      "grad_norm": 1.9157220125198364,
      "learning_rate": 0.00019232167682600794,
      "loss": 4.1456,
      "step": 360
    },
    {
      "epoch": 0.11870388193776067,
      "grad_norm": 3.1583054065704346,
      "learning_rate": 0.0001921077959576516,
      "loss": 4.1256,
      "step": 370
    },
    {
      "epoch": 0.12191209496310555,
      "grad_norm": 1.8012769222259521,
      "learning_rate": 0.00019189391508929527,
      "loss": 4.156,
      "step": 380
    },
    {
      "epoch": 0.12512030798845045,
      "grad_norm": 2.0717804431915283,
      "learning_rate": 0.00019168003422093894,
      "loss": 4.397,
      "step": 390
    },
    {
      "epoch": 0.12832852101379533,
      "grad_norm": 2.4557945728302,
      "learning_rate": 0.0001914661533525826,
      "loss": 4.2566,
      "step": 400
    },
    {
      "epoch": 0.1315367340391402,
      "grad_norm": 1.787262201309204,
      "learning_rate": 0.0001912522724842263,
      "loss": 4.38,
      "step": 410
    },
    {
      "epoch": 0.1347449470644851,
      "grad_norm": 1.9285707473754883,
      "learning_rate": 0.00019103839161586995,
      "loss": 4.0746,
      "step": 420
    },
    {
      "epoch": 0.13795316008982997,
      "grad_norm": 2.7452640533447266,
      "learning_rate": 0.00019082451074751365,
      "loss": 4.2652,
      "step": 430
    },
    {
      "epoch": 0.14116137311517485,
      "grad_norm": 2.027345895767212,
      "learning_rate": 0.00019061062987915732,
      "loss": 4.1917,
      "step": 440
    },
    {
      "epoch": 0.14436958614051973,
      "grad_norm": 1.647667407989502,
      "learning_rate": 0.000190396749010801,
      "loss": 4.2686,
      "step": 450
    },
    {
      "epoch": 0.1475777991658646,
      "grad_norm": 2.308013916015625,
      "learning_rate": 0.00019018286814244465,
      "loss": 4.2013,
      "step": 460
    },
    {
      "epoch": 0.1507860121912095,
      "grad_norm": 2.484921932220459,
      "learning_rate": 0.00018996898727408835,
      "loss": 4.2281,
      "step": 470
    },
    {
      "epoch": 0.15399422521655437,
      "grad_norm": 1.358372688293457,
      "learning_rate": 0.00018975510640573202,
      "loss": 3.7731,
      "step": 480
    },
    {
      "epoch": 0.15720243824189925,
      "grad_norm": 1.484513521194458,
      "learning_rate": 0.0001895412255373757,
      "loss": 4.2264,
      "step": 490
    },
    {
      "epoch": 0.16041065126724416,
      "grad_norm": 1.9827213287353516,
      "learning_rate": 0.00018932734466901936,
      "loss": 4.2347,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 9351,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 131099000832000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
