{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0891364902506964,
  "eval_steps": 500,
  "global_step": 7500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002785515320334262,
      "grad_norm": 1.2777702808380127,
      "learning_rate": 0.00099974930362117,
      "loss": 4.3969,
      "step": 10
    },
    {
      "epoch": 0.005571030640668524,
      "grad_norm": 1.7650771141052246,
      "learning_rate": 0.0009994707520891365,
      "loss": 3.4993,
      "step": 20
    },
    {
      "epoch": 0.008356545961002786,
      "grad_norm": 1.121536374092102,
      "learning_rate": 0.0009991922005571031,
      "loss": 3.182,
      "step": 30
    },
    {
      "epoch": 0.011142061281337047,
      "grad_norm": 1.5466363430023193,
      "learning_rate": 0.0009989136490250697,
      "loss": 3.4433,
      "step": 40
    },
    {
      "epoch": 0.013927576601671309,
      "grad_norm": 1.3392200469970703,
      "learning_rate": 0.0009986350974930363,
      "loss": 3.2526,
      "step": 50
    },
    {
      "epoch": 0.016713091922005572,
      "grad_norm": 1.4003591537475586,
      "learning_rate": 0.0009983565459610027,
      "loss": 2.9297,
      "step": 60
    },
    {
      "epoch": 0.019498607242339833,
      "grad_norm": 1.1948171854019165,
      "learning_rate": 0.0009980779944289695,
      "loss": 3.2728,
      "step": 70
    },
    {
      "epoch": 0.022284122562674095,
      "grad_norm": 1.0925664901733398,
      "learning_rate": 0.0009977994428969359,
      "loss": 2.9489,
      "step": 80
    },
    {
      "epoch": 0.025069637883008356,
      "grad_norm": 1.0867161750793457,
      "learning_rate": 0.0009975208913649025,
      "loss": 2.882,
      "step": 90
    },
    {
      "epoch": 0.027855153203342618,
      "grad_norm": 1.4580721855163574,
      "learning_rate": 0.000997242339832869,
      "loss": 2.7389,
      "step": 100
    },
    {
      "epoch": 0.03064066852367688,
      "grad_norm": 1.4019684791564941,
      "learning_rate": 0.0009969637883008356,
      "loss": 2.9995,
      "step": 110
    },
    {
      "epoch": 0.033426183844011144,
      "grad_norm": 1.0926460027694702,
      "learning_rate": 0.0009966852367688022,
      "loss": 3.1596,
      "step": 120
    },
    {
      "epoch": 0.036211699164345405,
      "grad_norm": 1.4548900127410889,
      "learning_rate": 0.0009964066852367688,
      "loss": 2.9555,
      "step": 130
    },
    {
      "epoch": 0.03899721448467967,
      "grad_norm": 1.5399762392044067,
      "learning_rate": 0.0009961281337047354,
      "loss": 3.1365,
      "step": 140
    },
    {
      "epoch": 0.04178272980501393,
      "grad_norm": 1.2968024015426636,
      "learning_rate": 0.000995849582172702,
      "loss": 2.8939,
      "step": 150
    },
    {
      "epoch": 0.04456824512534819,
      "grad_norm": 1.696082353591919,
      "learning_rate": 0.0009955710306406686,
      "loss": 2.7374,
      "step": 160
    },
    {
      "epoch": 0.04735376044568245,
      "grad_norm": 1.30885648727417,
      "learning_rate": 0.000995292479108635,
      "loss": 2.8485,
      "step": 170
    },
    {
      "epoch": 0.05013927576601671,
      "grad_norm": 1.320600152015686,
      "learning_rate": 0.0009950139275766018,
      "loss": 2.7569,
      "step": 180
    },
    {
      "epoch": 0.052924791086350974,
      "grad_norm": 1.1281540393829346,
      "learning_rate": 0.0009947353760445684,
      "loss": 3.1554,
      "step": 190
    },
    {
      "epoch": 0.055710306406685235,
      "grad_norm": 1.2007540464401245,
      "learning_rate": 0.0009944568245125348,
      "loss": 2.8286,
      "step": 200
    },
    {
      "epoch": 0.0584958217270195,
      "grad_norm": 1.0410748720169067,
      "learning_rate": 0.0009941782729805016,
      "loss": 3.0681,
      "step": 210
    },
    {
      "epoch": 0.06128133704735376,
      "grad_norm": 1.1308516263961792,
      "learning_rate": 0.000993899721448468,
      "loss": 2.823,
      "step": 220
    },
    {
      "epoch": 0.06406685236768803,
      "grad_norm": 1.7718303203582764,
      "learning_rate": 0.0009936211699164345,
      "loss": 2.9794,
      "step": 230
    },
    {
      "epoch": 0.06685236768802229,
      "grad_norm": 1.3107385635375977,
      "learning_rate": 0.0009933426183844011,
      "loss": 2.86,
      "step": 240
    },
    {
      "epoch": 0.06963788300835655,
      "grad_norm": 1.2536839246749878,
      "learning_rate": 0.0009930640668523677,
      "loss": 2.9039,
      "step": 250
    },
    {
      "epoch": 0.07242339832869081,
      "grad_norm": 1.420477032661438,
      "learning_rate": 0.0009927855153203343,
      "loss": 3.126,
      "step": 260
    },
    {
      "epoch": 0.07520891364902507,
      "grad_norm": 1.6711881160736084,
      "learning_rate": 0.0009925069637883009,
      "loss": 2.8972,
      "step": 270
    },
    {
      "epoch": 0.07799442896935933,
      "grad_norm": 1.694988489151001,
      "learning_rate": 0.0009922284122562675,
      "loss": 2.7816,
      "step": 280
    },
    {
      "epoch": 0.0807799442896936,
      "grad_norm": 1.0983426570892334,
      "learning_rate": 0.000991949860724234,
      "loss": 2.8463,
      "step": 290
    },
    {
      "epoch": 0.08356545961002786,
      "grad_norm": 1.1392773389816284,
      "learning_rate": 0.0009916713091922007,
      "loss": 2.9405,
      "step": 300
    },
    {
      "epoch": 0.08635097493036212,
      "grad_norm": 1.1083364486694336,
      "learning_rate": 0.000991392757660167,
      "loss": 2.9489,
      "step": 310
    },
    {
      "epoch": 0.08913649025069638,
      "grad_norm": 1.0049762725830078,
      "learning_rate": 0.0009911142061281338,
      "loss": 2.7545,
      "step": 320
    },
    {
      "epoch": 0.09192200557103064,
      "grad_norm": 1.4989159107208252,
      "learning_rate": 0.0009908356545961002,
      "loss": 2.827,
      "step": 330
    },
    {
      "epoch": 0.0947075208913649,
      "grad_norm": 1.4460601806640625,
      "learning_rate": 0.0009905571030640668,
      "loss": 2.922,
      "step": 340
    },
    {
      "epoch": 0.09749303621169916,
      "grad_norm": 1.2647724151611328,
      "learning_rate": 0.0009902785515320334,
      "loss": 2.6402,
      "step": 350
    },
    {
      "epoch": 0.10027855153203342,
      "grad_norm": 1.137195348739624,
      "learning_rate": 0.00099,
      "loss": 2.8358,
      "step": 360
    },
    {
      "epoch": 0.10306406685236769,
      "grad_norm": 1.1965945959091187,
      "learning_rate": 0.0009897214484679666,
      "loss": 2.871,
      "step": 370
    },
    {
      "epoch": 0.10584958217270195,
      "grad_norm": 1.1259201765060425,
      "learning_rate": 0.0009894428969359332,
      "loss": 2.8081,
      "step": 380
    },
    {
      "epoch": 0.10863509749303621,
      "grad_norm": 2.0894253253936768,
      "learning_rate": 0.0009891643454038998,
      "loss": 2.8969,
      "step": 390
    },
    {
      "epoch": 0.11142061281337047,
      "grad_norm": 1.2286434173583984,
      "learning_rate": 0.0009888857938718664,
      "loss": 2.8072,
      "step": 400
    },
    {
      "epoch": 0.11420612813370473,
      "grad_norm": 1.0757712125778198,
      "learning_rate": 0.000988607242339833,
      "loss": 2.7003,
      "step": 410
    },
    {
      "epoch": 0.116991643454039,
      "grad_norm": 1.7179458141326904,
      "learning_rate": 0.0009883286908077993,
      "loss": 2.7788,
      "step": 420
    },
    {
      "epoch": 0.11977715877437325,
      "grad_norm": 1.3726903200149536,
      "learning_rate": 0.0009880501392757661,
      "loss": 2.5696,
      "step": 430
    },
    {
      "epoch": 0.12256267409470752,
      "grad_norm": 1.14989173412323,
      "learning_rate": 0.0009877715877437327,
      "loss": 2.7331,
      "step": 440
    },
    {
      "epoch": 0.12534818941504178,
      "grad_norm": 1.2878109216690063,
      "learning_rate": 0.000987493036211699,
      "loss": 2.624,
      "step": 450
    },
    {
      "epoch": 0.12813370473537605,
      "grad_norm": 1.1452126502990723,
      "learning_rate": 0.0009872144846796657,
      "loss": 2.6156,
      "step": 460
    },
    {
      "epoch": 0.1309192200557103,
      "grad_norm": 1.4346585273742676,
      "learning_rate": 0.0009869359331476323,
      "loss": 2.6586,
      "step": 470
    },
    {
      "epoch": 0.13370473537604458,
      "grad_norm": 1.4669582843780518,
      "learning_rate": 0.0009866573816155989,
      "loss": 2.7476,
      "step": 480
    },
    {
      "epoch": 0.13649025069637882,
      "grad_norm": 1.610460638999939,
      "learning_rate": 0.0009863788300835655,
      "loss": 2.5211,
      "step": 490
    },
    {
      "epoch": 0.1392757660167131,
      "grad_norm": 1.2787543535232544,
      "learning_rate": 0.000986100278551532,
      "loss": 2.6962,
      "step": 500
    },
    {
      "epoch": 0.14206128133704735,
      "grad_norm": 1.3625420331954956,
      "learning_rate": 0.0009858217270194986,
      "loss": 2.6626,
      "step": 510
    },
    {
      "epoch": 0.14484679665738162,
      "grad_norm": 1.6599339246749878,
      "learning_rate": 0.0009855431754874652,
      "loss": 2.9541,
      "step": 520
    },
    {
      "epoch": 0.14763231197771587,
      "grad_norm": 1.3805036544799805,
      "learning_rate": 0.0009852646239554318,
      "loss": 2.9058,
      "step": 530
    },
    {
      "epoch": 0.15041782729805014,
      "grad_norm": 1.1459840536117554,
      "learning_rate": 0.0009849860724233984,
      "loss": 2.4951,
      "step": 540
    },
    {
      "epoch": 0.1532033426183844,
      "grad_norm": 1.278351068496704,
      "learning_rate": 0.000984707520891365,
      "loss": 2.7882,
      "step": 550
    },
    {
      "epoch": 0.15598885793871867,
      "grad_norm": 1.062248945236206,
      "learning_rate": 0.0009844289693593314,
      "loss": 2.9183,
      "step": 560
    },
    {
      "epoch": 0.15877437325905291,
      "grad_norm": 1.8217440843582153,
      "learning_rate": 0.000984150417827298,
      "loss": 2.7318,
      "step": 570
    },
    {
      "epoch": 0.1615598885793872,
      "grad_norm": 1.2369275093078613,
      "learning_rate": 0.0009838718662952646,
      "loss": 2.7745,
      "step": 580
    },
    {
      "epoch": 0.16434540389972144,
      "grad_norm": 1.242400050163269,
      "learning_rate": 0.0009835933147632312,
      "loss": 2.7332,
      "step": 590
    },
    {
      "epoch": 0.1671309192200557,
      "grad_norm": 1.8199281692504883,
      "learning_rate": 0.0009833147632311977,
      "loss": 2.9746,
      "step": 600
    },
    {
      "epoch": 0.16991643454038996,
      "grad_norm": 1.4614086151123047,
      "learning_rate": 0.0009830362116991643,
      "loss": 2.6833,
      "step": 610
    },
    {
      "epoch": 0.17270194986072424,
      "grad_norm": 1.246872067451477,
      "learning_rate": 0.000982757660167131,
      "loss": 2.8365,
      "step": 620
    },
    {
      "epoch": 0.17548746518105848,
      "grad_norm": 1.0792508125305176,
      "learning_rate": 0.0009824791086350975,
      "loss": 2.795,
      "step": 630
    },
    {
      "epoch": 0.17827298050139276,
      "grad_norm": 1.401904821395874,
      "learning_rate": 0.0009822005571030641,
      "loss": 2.4939,
      "step": 640
    },
    {
      "epoch": 0.181058495821727,
      "grad_norm": 1.273613452911377,
      "learning_rate": 0.0009819220055710307,
      "loss": 2.7808,
      "step": 650
    },
    {
      "epoch": 0.18384401114206128,
      "grad_norm": 1.510461449623108,
      "learning_rate": 0.0009816434540389973,
      "loss": 2.606,
      "step": 660
    },
    {
      "epoch": 0.18662952646239556,
      "grad_norm": 1.4030647277832031,
      "learning_rate": 0.0009813649025069639,
      "loss": 2.7183,
      "step": 670
    },
    {
      "epoch": 0.1894150417827298,
      "grad_norm": 1.3902904987335205,
      "learning_rate": 0.0009810863509749305,
      "loss": 2.6436,
      "step": 680
    },
    {
      "epoch": 0.19220055710306408,
      "grad_norm": 1.282233715057373,
      "learning_rate": 0.000980807799442897,
      "loss": 2.7614,
      "step": 690
    },
    {
      "epoch": 0.19498607242339833,
      "grad_norm": 1.247700572013855,
      "learning_rate": 0.0009805292479108634,
      "loss": 2.7213,
      "step": 700
    },
    {
      "epoch": 0.1977715877437326,
      "grad_norm": 1.9423047304153442,
      "learning_rate": 0.00098025069637883,
      "loss": 2.6238,
      "step": 710
    },
    {
      "epoch": 0.20055710306406685,
      "grad_norm": 1.189522385597229,
      "learning_rate": 0.0009799721448467966,
      "loss": 2.7811,
      "step": 720
    },
    {
      "epoch": 0.20334261838440112,
      "grad_norm": 1.268925428390503,
      "learning_rate": 0.0009796935933147632,
      "loss": 2.5515,
      "step": 730
    },
    {
      "epoch": 0.20612813370473537,
      "grad_norm": 1.566765308380127,
      "learning_rate": 0.0009794150417827298,
      "loss": 2.8544,
      "step": 740
    },
    {
      "epoch": 0.20891364902506965,
      "grad_norm": 1.4222410917282104,
      "learning_rate": 0.0009791364902506964,
      "loss": 2.7452,
      "step": 750
    },
    {
      "epoch": 0.2116991643454039,
      "grad_norm": 1.7793817520141602,
      "learning_rate": 0.000978857938718663,
      "loss": 2.6258,
      "step": 760
    },
    {
      "epoch": 0.21448467966573817,
      "grad_norm": 1.2203317880630493,
      "learning_rate": 0.0009785793871866296,
      "loss": 2.6129,
      "step": 770
    },
    {
      "epoch": 0.21727019498607242,
      "grad_norm": 1.2296749353408813,
      "learning_rate": 0.0009783008356545962,
      "loss": 2.4147,
      "step": 780
    },
    {
      "epoch": 0.2200557103064067,
      "grad_norm": 2.012601137161255,
      "learning_rate": 0.0009780222841225628,
      "loss": 2.8097,
      "step": 790
    },
    {
      "epoch": 0.22284122562674094,
      "grad_norm": 1.5866401195526123,
      "learning_rate": 0.0009777437325905294,
      "loss": 2.7063,
      "step": 800
    },
    {
      "epoch": 0.22562674094707522,
      "grad_norm": 1.1381161212921143,
      "learning_rate": 0.0009774651810584957,
      "loss": 2.6254,
      "step": 810
    },
    {
      "epoch": 0.22841225626740946,
      "grad_norm": 1.323906660079956,
      "learning_rate": 0.0009771866295264623,
      "loss": 2.6625,
      "step": 820
    },
    {
      "epoch": 0.23119777158774374,
      "grad_norm": 1.2379060983657837,
      "learning_rate": 0.000976908077994429,
      "loss": 2.829,
      "step": 830
    },
    {
      "epoch": 0.233983286908078,
      "grad_norm": 0.9392759799957275,
      "learning_rate": 0.0009766295264623955,
      "loss": 2.5653,
      "step": 840
    },
    {
      "epoch": 0.23676880222841226,
      "grad_norm": 1.0966740846633911,
      "learning_rate": 0.0009763509749303622,
      "loss": 2.542,
      "step": 850
    },
    {
      "epoch": 0.2395543175487465,
      "grad_norm": 1.1827309131622314,
      "learning_rate": 0.0009760724233983287,
      "loss": 2.6657,
      "step": 860
    },
    {
      "epoch": 0.24233983286908078,
      "grad_norm": 2.1995315551757812,
      "learning_rate": 0.0009757938718662953,
      "loss": 2.5712,
      "step": 870
    },
    {
      "epoch": 0.24512534818941503,
      "grad_norm": 1.3757152557373047,
      "learning_rate": 0.0009755153203342619,
      "loss": 2.5045,
      "step": 880
    },
    {
      "epoch": 0.2479108635097493,
      "grad_norm": 1.300731897354126,
      "learning_rate": 0.0009752367688022285,
      "loss": 2.5062,
      "step": 890
    },
    {
      "epoch": 0.25069637883008355,
      "grad_norm": 1.7121989727020264,
      "learning_rate": 0.0009749582172701949,
      "loss": 2.5394,
      "step": 900
    },
    {
      "epoch": 0.25348189415041783,
      "grad_norm": 1.4732779264450073,
      "learning_rate": 0.0009746796657381615,
      "loss": 2.467,
      "step": 910
    },
    {
      "epoch": 0.2562674094707521,
      "grad_norm": 1.0222309827804565,
      "learning_rate": 0.0009744011142061282,
      "loss": 2.7814,
      "step": 920
    },
    {
      "epoch": 0.2590529247910863,
      "grad_norm": 1.4269797801971436,
      "learning_rate": 0.0009741225626740947,
      "loss": 2.7467,
      "step": 930
    },
    {
      "epoch": 0.2618384401114206,
      "grad_norm": 1.3660566806793213,
      "learning_rate": 0.0009738440111420613,
      "loss": 2.68,
      "step": 940
    },
    {
      "epoch": 0.2646239554317549,
      "grad_norm": 1.7619974613189697,
      "learning_rate": 0.0009735654596100279,
      "loss": 2.9038,
      "step": 950
    },
    {
      "epoch": 0.26740947075208915,
      "grad_norm": 1.4360049962997437,
      "learning_rate": 0.0009732869080779945,
      "loss": 2.7045,
      "step": 960
    },
    {
      "epoch": 0.27019498607242337,
      "grad_norm": 1.2218104600906372,
      "learning_rate": 0.000973008356545961,
      "loss": 2.5466,
      "step": 970
    },
    {
      "epoch": 0.27298050139275765,
      "grad_norm": 1.2115695476531982,
      "learning_rate": 0.0009727298050139276,
      "loss": 2.6825,
      "step": 980
    },
    {
      "epoch": 0.2757660167130919,
      "grad_norm": 1.121020793914795,
      "learning_rate": 0.0009724512534818942,
      "loss": 2.4503,
      "step": 990
    },
    {
      "epoch": 0.2785515320334262,
      "grad_norm": 1.2568773031234741,
      "learning_rate": 0.0009721727019498607,
      "loss": 2.6551,
      "step": 1000
    },
    {
      "epoch": 0.28133704735376047,
      "grad_norm": 2.096107244491577,
      "learning_rate": 0.0009718941504178273,
      "loss": 2.4537,
      "step": 1010
    },
    {
      "epoch": 0.2841225626740947,
      "grad_norm": 1.1138832569122314,
      "learning_rate": 0.0009716155988857938,
      "loss": 2.6241,
      "step": 1020
    },
    {
      "epoch": 0.28690807799442897,
      "grad_norm": 1.082237720489502,
      "learning_rate": 0.0009713370473537605,
      "loss": 2.8076,
      "step": 1030
    },
    {
      "epoch": 0.28969359331476324,
      "grad_norm": 1.759205937385559,
      "learning_rate": 0.000971058495821727,
      "loss": 2.4967,
      "step": 1040
    },
    {
      "epoch": 0.2924791086350975,
      "grad_norm": 1.4228224754333496,
      "learning_rate": 0.0009707799442896936,
      "loss": 2.5495,
      "step": 1050
    },
    {
      "epoch": 0.29526462395543174,
      "grad_norm": 1.2179782390594482,
      "learning_rate": 0.0009705013927576602,
      "loss": 2.5726,
      "step": 1060
    },
    {
      "epoch": 0.298050139275766,
      "grad_norm": 1.0589041709899902,
      "learning_rate": 0.0009702228412256268,
      "loss": 2.5539,
      "step": 1070
    },
    {
      "epoch": 0.3008356545961003,
      "grad_norm": 1.321881651878357,
      "learning_rate": 0.0009699442896935934,
      "loss": 2.7221,
      "step": 1080
    },
    {
      "epoch": 0.30362116991643456,
      "grad_norm": 1.3781636953353882,
      "learning_rate": 0.0009696657381615599,
      "loss": 2.6005,
      "step": 1090
    },
    {
      "epoch": 0.3064066852367688,
      "grad_norm": 1.297652006149292,
      "learning_rate": 0.0009693871866295266,
      "loss": 2.6716,
      "step": 1100
    },
    {
      "epoch": 0.30919220055710306,
      "grad_norm": 1.3703551292419434,
      "learning_rate": 0.000969108635097493,
      "loss": 2.7372,
      "step": 1110
    },
    {
      "epoch": 0.31197771587743733,
      "grad_norm": 1.2973988056182861,
      "learning_rate": 0.0009688300835654596,
      "loss": 2.6567,
      "step": 1120
    },
    {
      "epoch": 0.3147632311977716,
      "grad_norm": 1.3623809814453125,
      "learning_rate": 0.0009685515320334262,
      "loss": 2.508,
      "step": 1130
    },
    {
      "epoch": 0.31754874651810583,
      "grad_norm": 1.2565559148788452,
      "learning_rate": 0.0009682729805013928,
      "loss": 2.6754,
      "step": 1140
    },
    {
      "epoch": 0.3203342618384401,
      "grad_norm": 1.1795793771743774,
      "learning_rate": 0.0009679944289693593,
      "loss": 2.6742,
      "step": 1150
    },
    {
      "epoch": 0.3231197771587744,
      "grad_norm": 1.4879752397537231,
      "learning_rate": 0.0009677158774373259,
      "loss": 2.4956,
      "step": 1160
    },
    {
      "epoch": 0.32590529247910865,
      "grad_norm": 1.2180157899856567,
      "learning_rate": 0.0009674373259052926,
      "loss": 2.6508,
      "step": 1170
    },
    {
      "epoch": 0.3286908077994429,
      "grad_norm": 1.2524197101593018,
      "learning_rate": 0.0009671587743732591,
      "loss": 2.6679,
      "step": 1180
    },
    {
      "epoch": 0.33147632311977715,
      "grad_norm": 1.35256826877594,
      "learning_rate": 0.0009668802228412257,
      "loss": 2.8273,
      "step": 1190
    },
    {
      "epoch": 0.3342618384401114,
      "grad_norm": 1.5260603427886963,
      "learning_rate": 0.0009666016713091921,
      "loss": 2.6268,
      "step": 1200
    },
    {
      "epoch": 0.3370473537604457,
      "grad_norm": 1.7540775537490845,
      "learning_rate": 0.0009663231197771588,
      "loss": 2.519,
      "step": 1210
    },
    {
      "epoch": 0.3398328690807799,
      "grad_norm": 1.5949130058288574,
      "learning_rate": 0.0009660445682451253,
      "loss": 2.5143,
      "step": 1220
    },
    {
      "epoch": 0.3426183844011142,
      "grad_norm": 1.0860681533813477,
      "learning_rate": 0.0009657660167130919,
      "loss": 2.5586,
      "step": 1230
    },
    {
      "epoch": 0.34540389972144847,
      "grad_norm": 1.1188979148864746,
      "learning_rate": 0.0009654874651810586,
      "loss": 2.5164,
      "step": 1240
    },
    {
      "epoch": 0.34818941504178275,
      "grad_norm": 1.1286648511886597,
      "learning_rate": 0.0009652089136490251,
      "loss": 2.5772,
      "step": 1250
    },
    {
      "epoch": 0.35097493036211697,
      "grad_norm": 1.5116323232650757,
      "learning_rate": 0.0009649303621169917,
      "loss": 2.6543,
      "step": 1260
    },
    {
      "epoch": 0.35376044568245124,
      "grad_norm": 1.458951711654663,
      "learning_rate": 0.0009646518105849582,
      "loss": 2.8363,
      "step": 1270
    },
    {
      "epoch": 0.3565459610027855,
      "grad_norm": 1.2095354795455933,
      "learning_rate": 0.0009643732590529249,
      "loss": 2.6857,
      "step": 1280
    },
    {
      "epoch": 0.3593314763231198,
      "grad_norm": 1.0491148233413696,
      "learning_rate": 0.0009640947075208914,
      "loss": 2.5778,
      "step": 1290
    },
    {
      "epoch": 0.362116991643454,
      "grad_norm": 1.2475234270095825,
      "learning_rate": 0.0009638161559888579,
      "loss": 2.6415,
      "step": 1300
    },
    {
      "epoch": 0.3649025069637883,
      "grad_norm": 1.9963531494140625,
      "learning_rate": 0.0009635376044568245,
      "loss": 2.5831,
      "step": 1310
    },
    {
      "epoch": 0.36768802228412256,
      "grad_norm": 1.413554310798645,
      "learning_rate": 0.0009632590529247911,
      "loss": 2.7378,
      "step": 1320
    },
    {
      "epoch": 0.37047353760445684,
      "grad_norm": 1.80016028881073,
      "learning_rate": 0.0009629805013927577,
      "loss": 2.6622,
      "step": 1330
    },
    {
      "epoch": 0.3732590529247911,
      "grad_norm": 1.4611876010894775,
      "learning_rate": 0.0009627019498607242,
      "loss": 2.503,
      "step": 1340
    },
    {
      "epoch": 0.37604456824512533,
      "grad_norm": 1.1218934059143066,
      "learning_rate": 0.0009624233983286909,
      "loss": 2.6757,
      "step": 1350
    },
    {
      "epoch": 0.3788300835654596,
      "grad_norm": 1.5722981691360474,
      "learning_rate": 0.0009621448467966574,
      "loss": 2.7089,
      "step": 1360
    },
    {
      "epoch": 0.3816155988857939,
      "grad_norm": 1.2269376516342163,
      "learning_rate": 0.000961866295264624,
      "loss": 2.7037,
      "step": 1370
    },
    {
      "epoch": 0.38440111420612816,
      "grad_norm": 1.387017011642456,
      "learning_rate": 0.0009615877437325905,
      "loss": 2.586,
      "step": 1380
    },
    {
      "epoch": 0.3871866295264624,
      "grad_norm": 1.515525221824646,
      "learning_rate": 0.0009613091922005572,
      "loss": 2.6129,
      "step": 1390
    },
    {
      "epoch": 0.38997214484679665,
      "grad_norm": 1.1997807025909424,
      "learning_rate": 0.0009610306406685237,
      "loss": 2.488,
      "step": 1400
    },
    {
      "epoch": 0.39275766016713093,
      "grad_norm": 1.5051579475402832,
      "learning_rate": 0.0009607520891364902,
      "loss": 2.7434,
      "step": 1410
    },
    {
      "epoch": 0.3955431754874652,
      "grad_norm": 1.159185767173767,
      "learning_rate": 0.0009604735376044569,
      "loss": 2.6266,
      "step": 1420
    },
    {
      "epoch": 0.3983286908077994,
      "grad_norm": 1.232654094696045,
      "learning_rate": 0.0009601949860724234,
      "loss": 2.5591,
      "step": 1430
    },
    {
      "epoch": 0.4011142061281337,
      "grad_norm": 1.1168028116226196,
      "learning_rate": 0.00095991643454039,
      "loss": 2.397,
      "step": 1440
    },
    {
      "epoch": 0.403899721448468,
      "grad_norm": 1.3815401792526245,
      "learning_rate": 0.0009596378830083565,
      "loss": 2.3866,
      "step": 1450
    },
    {
      "epoch": 0.40668523676880225,
      "grad_norm": 1.520772933959961,
      "learning_rate": 0.0009593593314763232,
      "loss": 2.5404,
      "step": 1460
    },
    {
      "epoch": 0.40947075208913647,
      "grad_norm": 1.3483422994613647,
      "learning_rate": 0.0009590807799442897,
      "loss": 2.5735,
      "step": 1470
    },
    {
      "epoch": 0.41225626740947074,
      "grad_norm": 1.2592273950576782,
      "learning_rate": 0.0009588022284122563,
      "loss": 2.6864,
      "step": 1480
    },
    {
      "epoch": 0.415041782729805,
      "grad_norm": 1.1354230642318726,
      "learning_rate": 0.000958523676880223,
      "loss": 2.4747,
      "step": 1490
    },
    {
      "epoch": 0.4178272980501393,
      "grad_norm": 1.1164798736572266,
      "learning_rate": 0.0009582451253481894,
      "loss": 2.5945,
      "step": 1500
    },
    {
      "epoch": 0.4206128133704735,
      "grad_norm": 1.7407081127166748,
      "learning_rate": 0.000957966573816156,
      "loss": 2.6287,
      "step": 1510
    },
    {
      "epoch": 0.4233983286908078,
      "grad_norm": 1.4179469347000122,
      "learning_rate": 0.0009576880222841225,
      "loss": 2.6931,
      "step": 1520
    },
    {
      "epoch": 0.42618384401114207,
      "grad_norm": 0.9913387894630432,
      "learning_rate": 0.0009574094707520892,
      "loss": 2.5683,
      "step": 1530
    },
    {
      "epoch": 0.42896935933147634,
      "grad_norm": 1.288426160812378,
      "learning_rate": 0.0009571309192200557,
      "loss": 2.6026,
      "step": 1540
    },
    {
      "epoch": 0.43175487465181056,
      "grad_norm": 1.3299269676208496,
      "learning_rate": 0.0009568523676880223,
      "loss": 2.588,
      "step": 1550
    },
    {
      "epoch": 0.43454038997214484,
      "grad_norm": 1.922222375869751,
      "learning_rate": 0.0009565738161559889,
      "loss": 2.5401,
      "step": 1560
    },
    {
      "epoch": 0.4373259052924791,
      "grad_norm": 1.565882921218872,
      "learning_rate": 0.0009562952646239555,
      "loss": 2.6152,
      "step": 1570
    },
    {
      "epoch": 0.4401114206128134,
      "grad_norm": 1.2204829454421997,
      "learning_rate": 0.0009560167130919221,
      "loss": 2.6914,
      "step": 1580
    },
    {
      "epoch": 0.4428969359331476,
      "grad_norm": 1.1876715421676636,
      "learning_rate": 0.0009557381615598885,
      "loss": 2.6338,
      "step": 1590
    },
    {
      "epoch": 0.4456824512534819,
      "grad_norm": 1.4208650588989258,
      "learning_rate": 0.0009554596100278552,
      "loss": 2.5563,
      "step": 1600
    },
    {
      "epoch": 0.44846796657381616,
      "grad_norm": 1.0509493350982666,
      "learning_rate": 0.0009551810584958217,
      "loss": 2.4876,
      "step": 1610
    },
    {
      "epoch": 0.45125348189415043,
      "grad_norm": 1.0826983451843262,
      "learning_rate": 0.0009549025069637883,
      "loss": 2.591,
      "step": 1620
    },
    {
      "epoch": 0.45403899721448465,
      "grad_norm": 1.4745317697525024,
      "learning_rate": 0.0009546239554317548,
      "loss": 2.6145,
      "step": 1630
    },
    {
      "epoch": 0.4568245125348189,
      "grad_norm": 1.3137785196304321,
      "learning_rate": 0.0009543454038997215,
      "loss": 2.5078,
      "step": 1640
    },
    {
      "epoch": 0.4596100278551532,
      "grad_norm": 1.4456435441970825,
      "learning_rate": 0.0009540668523676881,
      "loss": 2.576,
      "step": 1650
    },
    {
      "epoch": 0.4623955431754875,
      "grad_norm": 2.9058103561401367,
      "learning_rate": 0.0009537883008356546,
      "loss": 2.8123,
      "step": 1660
    },
    {
      "epoch": 0.46518105849582175,
      "grad_norm": 1.210128903388977,
      "learning_rate": 0.0009535097493036213,
      "loss": 2.6477,
      "step": 1670
    },
    {
      "epoch": 0.467966573816156,
      "grad_norm": 1.3550188541412354,
      "learning_rate": 0.0009532311977715878,
      "loss": 2.3989,
      "step": 1680
    },
    {
      "epoch": 0.47075208913649025,
      "grad_norm": 1.533486247062683,
      "learning_rate": 0.0009529526462395543,
      "loss": 2.7835,
      "step": 1690
    },
    {
      "epoch": 0.4735376044568245,
      "grad_norm": 1.1093838214874268,
      "learning_rate": 0.0009526740947075208,
      "loss": 2.6051,
      "step": 1700
    },
    {
      "epoch": 0.4763231197771588,
      "grad_norm": 1.8435648679733276,
      "learning_rate": 0.0009523955431754875,
      "loss": 2.5926,
      "step": 1710
    },
    {
      "epoch": 0.479108635097493,
      "grad_norm": 1.6711620092391968,
      "learning_rate": 0.0009521169916434541,
      "loss": 2.4779,
      "step": 1720
    },
    {
      "epoch": 0.4818941504178273,
      "grad_norm": 1.3479443788528442,
      "learning_rate": 0.0009518384401114206,
      "loss": 2.5155,
      "step": 1730
    },
    {
      "epoch": 0.48467966573816157,
      "grad_norm": 1.5922962427139282,
      "learning_rate": 0.0009515598885793872,
      "loss": 2.795,
      "step": 1740
    },
    {
      "epoch": 0.48746518105849584,
      "grad_norm": 1.2577641010284424,
      "learning_rate": 0.0009512813370473538,
      "loss": 2.6942,
      "step": 1750
    },
    {
      "epoch": 0.49025069637883006,
      "grad_norm": 1.1868338584899902,
      "learning_rate": 0.0009510027855153204,
      "loss": 2.4699,
      "step": 1760
    },
    {
      "epoch": 0.49303621169916434,
      "grad_norm": 1.3853003978729248,
      "learning_rate": 0.0009507242339832869,
      "loss": 2.5375,
      "step": 1770
    },
    {
      "epoch": 0.4958217270194986,
      "grad_norm": 1.1781913042068481,
      "learning_rate": 0.0009504456824512536,
      "loss": 2.5025,
      "step": 1780
    },
    {
      "epoch": 0.4986072423398329,
      "grad_norm": 1.262628197669983,
      "learning_rate": 0.00095016713091922,
      "loss": 2.5345,
      "step": 1790
    },
    {
      "epoch": 0.5013927576601671,
      "grad_norm": 1.1075992584228516,
      "learning_rate": 0.0009498885793871866,
      "loss": 2.6029,
      "step": 1800
    },
    {
      "epoch": 0.5041782729805014,
      "grad_norm": 1.3424242734909058,
      "learning_rate": 0.0009496100278551532,
      "loss": 2.137,
      "step": 1810
    },
    {
      "epoch": 0.5069637883008357,
      "grad_norm": 1.1349455118179321,
      "learning_rate": 0.0009493314763231198,
      "loss": 2.5881,
      "step": 1820
    },
    {
      "epoch": 0.5097493036211699,
      "grad_norm": 1.6739836931228638,
      "learning_rate": 0.0009490529247910864,
      "loss": 2.6388,
      "step": 1830
    },
    {
      "epoch": 0.5125348189415042,
      "grad_norm": 1.2096190452575684,
      "learning_rate": 0.0009487743732590529,
      "loss": 2.2502,
      "step": 1840
    },
    {
      "epoch": 0.5153203342618384,
      "grad_norm": 1.1820263862609863,
      "learning_rate": 0.0009484958217270196,
      "loss": 2.5372,
      "step": 1850
    },
    {
      "epoch": 0.5181058495821727,
      "grad_norm": 1.23209810256958,
      "learning_rate": 0.0009482172701949861,
      "loss": 2.6936,
      "step": 1860
    },
    {
      "epoch": 0.520891364902507,
      "grad_norm": 1.1804924011230469,
      "learning_rate": 0.0009479387186629527,
      "loss": 2.7291,
      "step": 1870
    },
    {
      "epoch": 0.5236768802228412,
      "grad_norm": 1.5289980173110962,
      "learning_rate": 0.0009476601671309193,
      "loss": 2.6525,
      "step": 1880
    },
    {
      "epoch": 0.5264623955431755,
      "grad_norm": 1.6307711601257324,
      "learning_rate": 0.0009473816155988858,
      "loss": 2.6374,
      "step": 1890
    },
    {
      "epoch": 0.5292479108635098,
      "grad_norm": 2.069382429122925,
      "learning_rate": 0.0009471030640668524,
      "loss": 2.2964,
      "step": 1900
    },
    {
      "epoch": 0.532033426183844,
      "grad_norm": 7.963252067565918,
      "learning_rate": 0.0009468245125348189,
      "loss": 2.6508,
      "step": 1910
    },
    {
      "epoch": 0.5348189415041783,
      "grad_norm": 1.3602561950683594,
      "learning_rate": 0.0009465459610027855,
      "loss": 2.516,
      "step": 1920
    },
    {
      "epoch": 0.5376044568245125,
      "grad_norm": 1.2182590961456299,
      "learning_rate": 0.0009462674094707521,
      "loss": 2.6688,
      "step": 1930
    },
    {
      "epoch": 0.5403899721448467,
      "grad_norm": 1.422895908355713,
      "learning_rate": 0.0009459888579387187,
      "loss": 2.3212,
      "step": 1940
    },
    {
      "epoch": 0.5431754874651811,
      "grad_norm": 1.41317880153656,
      "learning_rate": 0.0009457103064066852,
      "loss": 2.7405,
      "step": 1950
    },
    {
      "epoch": 0.5459610027855153,
      "grad_norm": 1.0755990743637085,
      "learning_rate": 0.0009454317548746519,
      "loss": 2.6927,
      "step": 1960
    },
    {
      "epoch": 0.5487465181058496,
      "grad_norm": 1.3661142587661743,
      "learning_rate": 0.0009451532033426185,
      "loss": 2.5271,
      "step": 1970
    },
    {
      "epoch": 0.5515320334261838,
      "grad_norm": 1.6025452613830566,
      "learning_rate": 0.000944874651810585,
      "loss": 2.5678,
      "step": 1980
    },
    {
      "epoch": 0.5543175487465181,
      "grad_norm": 1.1793705224990845,
      "learning_rate": 0.0009445961002785515,
      "loss": 2.3317,
      "step": 1990
    },
    {
      "epoch": 0.5571030640668524,
      "grad_norm": 1.1052885055541992,
      "learning_rate": 0.0009443175487465181,
      "loss": 2.5183,
      "step": 2000
    },
    {
      "epoch": 0.5598885793871866,
      "grad_norm": 1.877814531326294,
      "learning_rate": 0.0009440389972144847,
      "loss": 2.5533,
      "step": 2010
    },
    {
      "epoch": 0.5626740947075209,
      "grad_norm": 0.9979457259178162,
      "learning_rate": 0.0009437604456824512,
      "loss": 2.5141,
      "step": 2020
    },
    {
      "epoch": 0.5654596100278552,
      "grad_norm": 1.664000391960144,
      "learning_rate": 0.0009434818941504178,
      "loss": 2.5995,
      "step": 2030
    },
    {
      "epoch": 0.5682451253481894,
      "grad_norm": 1.327587366104126,
      "learning_rate": 0.0009432033426183845,
      "loss": 2.5348,
      "step": 2040
    },
    {
      "epoch": 0.5710306406685237,
      "grad_norm": 1.4465824365615845,
      "learning_rate": 0.000942924791086351,
      "loss": 2.5717,
      "step": 2050
    },
    {
      "epoch": 0.5738161559888579,
      "grad_norm": 1.3093647956848145,
      "learning_rate": 0.0009426462395543176,
      "loss": 2.4578,
      "step": 2060
    },
    {
      "epoch": 0.5766016713091922,
      "grad_norm": 1.901842713356018,
      "learning_rate": 0.0009423676880222842,
      "loss": 2.4301,
      "step": 2070
    },
    {
      "epoch": 0.5793871866295265,
      "grad_norm": 1.1070830821990967,
      "learning_rate": 0.0009420891364902508,
      "loss": 2.5675,
      "step": 2080
    },
    {
      "epoch": 0.5821727019498607,
      "grad_norm": 1.551803469657898,
      "learning_rate": 0.0009418105849582172,
      "loss": 2.6159,
      "step": 2090
    },
    {
      "epoch": 0.584958217270195,
      "grad_norm": 1.1841830015182495,
      "learning_rate": 0.0009415320334261838,
      "loss": 2.5513,
      "step": 2100
    },
    {
      "epoch": 0.5877437325905293,
      "grad_norm": 1.2188178300857544,
      "learning_rate": 0.0009412534818941504,
      "loss": 2.6357,
      "step": 2110
    },
    {
      "epoch": 0.5905292479108635,
      "grad_norm": 1.1983903646469116,
      "learning_rate": 0.000940974930362117,
      "loss": 2.6012,
      "step": 2120
    },
    {
      "epoch": 0.5933147632311978,
      "grad_norm": 1.570056438446045,
      "learning_rate": 0.0009406963788300836,
      "loss": 2.6183,
      "step": 2130
    },
    {
      "epoch": 0.596100278551532,
      "grad_norm": 1.232574701309204,
      "learning_rate": 0.0009404178272980502,
      "loss": 2.665,
      "step": 2140
    },
    {
      "epoch": 0.5988857938718662,
      "grad_norm": 1.6553981304168701,
      "learning_rate": 0.0009401392757660168,
      "loss": 2.4081,
      "step": 2150
    },
    {
      "epoch": 0.6016713091922006,
      "grad_norm": 1.0133997201919556,
      "learning_rate": 0.0009398607242339833,
      "loss": 2.4542,
      "step": 2160
    },
    {
      "epoch": 0.6044568245125348,
      "grad_norm": 1.5961579084396362,
      "learning_rate": 0.0009395821727019499,
      "loss": 2.5394,
      "step": 2170
    },
    {
      "epoch": 0.6072423398328691,
      "grad_norm": 0.9842129349708557,
      "learning_rate": 0.0009393036211699164,
      "loss": 2.485,
      "step": 2180
    },
    {
      "epoch": 0.6100278551532033,
      "grad_norm": 0.976337194442749,
      "learning_rate": 0.000939025069637883,
      "loss": 2.6303,
      "step": 2190
    },
    {
      "epoch": 0.6128133704735376,
      "grad_norm": 1.148184061050415,
      "learning_rate": 0.0009387465181058496,
      "loss": 2.7469,
      "step": 2200
    },
    {
      "epoch": 0.6155988857938719,
      "grad_norm": 1.2292206287384033,
      "learning_rate": 0.0009384679665738161,
      "loss": 2.5788,
      "step": 2210
    },
    {
      "epoch": 0.6183844011142061,
      "grad_norm": 1.4672414064407349,
      "learning_rate": 0.0009381894150417828,
      "loss": 2.3803,
      "step": 2220
    },
    {
      "epoch": 0.6211699164345403,
      "grad_norm": 1.0753039121627808,
      "learning_rate": 0.0009379108635097493,
      "loss": 2.5741,
      "step": 2230
    },
    {
      "epoch": 0.6239554317548747,
      "grad_norm": 1.4006630182266235,
      "learning_rate": 0.0009376323119777159,
      "loss": 2.3706,
      "step": 2240
    },
    {
      "epoch": 0.6267409470752089,
      "grad_norm": 1.2724519968032837,
      "learning_rate": 0.0009373537604456825,
      "loss": 2.539,
      "step": 2250
    },
    {
      "epoch": 0.6295264623955432,
      "grad_norm": 1.2491227388381958,
      "learning_rate": 0.0009370752089136491,
      "loss": 2.7182,
      "step": 2260
    },
    {
      "epoch": 0.6323119777158774,
      "grad_norm": 1.4925132989883423,
      "learning_rate": 0.0009367966573816156,
      "loss": 2.7096,
      "step": 2270
    },
    {
      "epoch": 0.6350974930362117,
      "grad_norm": 1.388200044631958,
      "learning_rate": 0.0009365181058495821,
      "loss": 2.5473,
      "step": 2280
    },
    {
      "epoch": 0.637883008356546,
      "grad_norm": 1.309496521949768,
      "learning_rate": 0.0009362395543175488,
      "loss": 2.5842,
      "step": 2290
    },
    {
      "epoch": 0.6406685236768802,
      "grad_norm": 1.8393137454986572,
      "learning_rate": 0.0009359610027855153,
      "loss": 2.7737,
      "step": 2300
    },
    {
      "epoch": 0.6434540389972145,
      "grad_norm": 4.742587566375732,
      "learning_rate": 0.0009356824512534819,
      "loss": 2.7859,
      "step": 2310
    },
    {
      "epoch": 0.6462395543175488,
      "grad_norm": 1.2533297538757324,
      "learning_rate": 0.0009354038997214485,
      "loss": 2.5762,
      "step": 2320
    },
    {
      "epoch": 0.649025069637883,
      "grad_norm": 1.3019458055496216,
      "learning_rate": 0.0009351253481894151,
      "loss": 2.4436,
      "step": 2330
    },
    {
      "epoch": 0.6518105849582173,
      "grad_norm": 1.2244460582733154,
      "learning_rate": 0.0009348467966573816,
      "loss": 2.3524,
      "step": 2340
    },
    {
      "epoch": 0.6545961002785515,
      "grad_norm": 1.6538617610931396,
      "learning_rate": 0.0009345682451253482,
      "loss": 2.4802,
      "step": 2350
    },
    {
      "epoch": 0.6573816155988857,
      "grad_norm": 3.2586660385131836,
      "learning_rate": 0.0009342896935933149,
      "loss": 2.6909,
      "step": 2360
    },
    {
      "epoch": 0.6601671309192201,
      "grad_norm": 1.18228280544281,
      "learning_rate": 0.0009340111420612814,
      "loss": 2.6456,
      "step": 2370
    },
    {
      "epoch": 0.6629526462395543,
      "grad_norm": 1.20558500289917,
      "learning_rate": 0.000933732590529248,
      "loss": 2.4466,
      "step": 2380
    },
    {
      "epoch": 0.6657381615598886,
      "grad_norm": 1.121671199798584,
      "learning_rate": 0.0009334540389972144,
      "loss": 2.481,
      "step": 2390
    },
    {
      "epoch": 0.6685236768802229,
      "grad_norm": 1.2893065214157104,
      "learning_rate": 0.0009331754874651811,
      "loss": 2.3008,
      "step": 2400
    },
    {
      "epoch": 0.6713091922005571,
      "grad_norm": 3.232966423034668,
      "learning_rate": 0.0009328969359331476,
      "loss": 2.5298,
      "step": 2410
    },
    {
      "epoch": 0.6740947075208914,
      "grad_norm": 1.07889986038208,
      "learning_rate": 0.0009326183844011142,
      "loss": 2.602,
      "step": 2420
    },
    {
      "epoch": 0.6768802228412256,
      "grad_norm": 1.2069727182388306,
      "learning_rate": 0.0009323398328690808,
      "loss": 2.5107,
      "step": 2430
    },
    {
      "epoch": 0.6796657381615598,
      "grad_norm": 1.1511386632919312,
      "learning_rate": 0.0009320612813370474,
      "loss": 2.5646,
      "step": 2440
    },
    {
      "epoch": 0.6824512534818942,
      "grad_norm": 1.3445967435836792,
      "learning_rate": 0.000931782729805014,
      "loss": 2.5636,
      "step": 2450
    },
    {
      "epoch": 0.6852367688022284,
      "grad_norm": 2.175687074661255,
      "learning_rate": 0.0009315041782729805,
      "loss": 2.5484,
      "step": 2460
    },
    {
      "epoch": 0.6880222841225627,
      "grad_norm": 1.77033269405365,
      "learning_rate": 0.0009312256267409472,
      "loss": 2.6023,
      "step": 2470
    },
    {
      "epoch": 0.6908077994428969,
      "grad_norm": 1.3223330974578857,
      "learning_rate": 0.0009309470752089136,
      "loss": 2.5597,
      "step": 2480
    },
    {
      "epoch": 0.6935933147632312,
      "grad_norm": 0.973379909992218,
      "learning_rate": 0.0009306685236768802,
      "loss": 2.5106,
      "step": 2490
    },
    {
      "epoch": 0.6963788300835655,
      "grad_norm": 1.3978427648544312,
      "learning_rate": 0.0009303899721448468,
      "loss": 2.475,
      "step": 2500
    },
    {
      "epoch": 0.6991643454038997,
      "grad_norm": 1.1118197441101074,
      "learning_rate": 0.0009301114206128134,
      "loss": 2.6572,
      "step": 2510
    },
    {
      "epoch": 0.7019498607242339,
      "grad_norm": 1.159158706665039,
      "learning_rate": 0.0009298328690807799,
      "loss": 2.744,
      "step": 2520
    },
    {
      "epoch": 0.7047353760445683,
      "grad_norm": 1.4264073371887207,
      "learning_rate": 0.0009295543175487465,
      "loss": 2.2988,
      "step": 2530
    },
    {
      "epoch": 0.7075208913649025,
      "grad_norm": 1.0038737058639526,
      "learning_rate": 0.0009292757660167132,
      "loss": 2.6336,
      "step": 2540
    },
    {
      "epoch": 0.7103064066852368,
      "grad_norm": 1.3323882818222046,
      "learning_rate": 0.0009289972144846797,
      "loss": 2.5943,
      "step": 2550
    },
    {
      "epoch": 0.713091922005571,
      "grad_norm": 1.0147569179534912,
      "learning_rate": 0.0009287186629526463,
      "loss": 2.5134,
      "step": 2560
    },
    {
      "epoch": 0.7158774373259053,
      "grad_norm": 1.4271459579467773,
      "learning_rate": 0.0009284401114206127,
      "loss": 2.5186,
      "step": 2570
    },
    {
      "epoch": 0.7186629526462396,
      "grad_norm": 1.2987439632415771,
      "learning_rate": 0.0009281615598885794,
      "loss": 2.3949,
      "step": 2580
    },
    {
      "epoch": 0.7214484679665738,
      "grad_norm": 1.4954429864883423,
      "learning_rate": 0.0009278830083565459,
      "loss": 2.6412,
      "step": 2590
    },
    {
      "epoch": 0.724233983286908,
      "grad_norm": 1.090782880783081,
      "learning_rate": 0.0009276044568245125,
      "loss": 2.5332,
      "step": 2600
    },
    {
      "epoch": 0.7270194986072424,
      "grad_norm": 1.0385299921035767,
      "learning_rate": 0.0009273259052924792,
      "loss": 2.5205,
      "step": 2610
    },
    {
      "epoch": 0.7298050139275766,
      "grad_norm": 1.2220218181610107,
      "learning_rate": 0.0009270473537604457,
      "loss": 2.549,
      "step": 2620
    },
    {
      "epoch": 0.7325905292479109,
      "grad_norm": 1.1563817262649536,
      "learning_rate": 0.0009267688022284123,
      "loss": 2.4725,
      "step": 2630
    },
    {
      "epoch": 0.7353760445682451,
      "grad_norm": 1.2204904556274414,
      "learning_rate": 0.0009264902506963788,
      "loss": 2.4911,
      "step": 2640
    },
    {
      "epoch": 0.7381615598885793,
      "grad_norm": 1.47650146484375,
      "learning_rate": 0.0009262116991643455,
      "loss": 2.7053,
      "step": 2650
    },
    {
      "epoch": 0.7409470752089137,
      "grad_norm": 1.2485514879226685,
      "learning_rate": 0.000925933147632312,
      "loss": 2.4443,
      "step": 2660
    },
    {
      "epoch": 0.7437325905292479,
      "grad_norm": 1.210825800895691,
      "learning_rate": 0.0009256545961002786,
      "loss": 2.5861,
      "step": 2670
    },
    {
      "epoch": 0.7465181058495822,
      "grad_norm": 1.133064866065979,
      "learning_rate": 0.0009253760445682451,
      "loss": 2.2651,
      "step": 2680
    },
    {
      "epoch": 0.7493036211699164,
      "grad_norm": 1.1768527030944824,
      "learning_rate": 0.0009250974930362117,
      "loss": 2.5199,
      "step": 2690
    },
    {
      "epoch": 0.7520891364902507,
      "grad_norm": 1.5120288133621216,
      "learning_rate": 0.0009248189415041783,
      "loss": 2.4315,
      "step": 2700
    },
    {
      "epoch": 0.754874651810585,
      "grad_norm": 1.159740924835205,
      "learning_rate": 0.0009245403899721448,
      "loss": 2.5868,
      "step": 2710
    },
    {
      "epoch": 0.7576601671309192,
      "grad_norm": 1.1845282316207886,
      "learning_rate": 0.0009242618384401115,
      "loss": 2.5479,
      "step": 2720
    },
    {
      "epoch": 0.7604456824512534,
      "grad_norm": 1.0858104228973389,
      "learning_rate": 0.000923983286908078,
      "loss": 2.5822,
      "step": 2730
    },
    {
      "epoch": 0.7632311977715878,
      "grad_norm": 1.2327394485473633,
      "learning_rate": 0.0009237047353760446,
      "loss": 2.4777,
      "step": 2740
    },
    {
      "epoch": 0.766016713091922,
      "grad_norm": 1.2286115884780884,
      "learning_rate": 0.0009234261838440111,
      "loss": 2.6194,
      "step": 2750
    },
    {
      "epoch": 0.7688022284122563,
      "grad_norm": 1.4070664644241333,
      "learning_rate": 0.0009231476323119778,
      "loss": 2.309,
      "step": 2760
    },
    {
      "epoch": 0.7715877437325905,
      "grad_norm": 1.4126564264297485,
      "learning_rate": 0.0009228690807799444,
      "loss": 2.5326,
      "step": 2770
    },
    {
      "epoch": 0.7743732590529248,
      "grad_norm": 1.49712336063385,
      "learning_rate": 0.0009225905292479108,
      "loss": 2.3481,
      "step": 2780
    },
    {
      "epoch": 0.7771587743732591,
      "grad_norm": 1.2510416507720947,
      "learning_rate": 0.0009223119777158775,
      "loss": 2.7475,
      "step": 2790
    },
    {
      "epoch": 0.7799442896935933,
      "grad_norm": 1.1437839269638062,
      "learning_rate": 0.000922033426183844,
      "loss": 2.3777,
      "step": 2800
    },
    {
      "epoch": 0.7827298050139275,
      "grad_norm": 1.3473021984100342,
      "learning_rate": 0.0009217548746518106,
      "loss": 2.516,
      "step": 2810
    },
    {
      "epoch": 0.7855153203342619,
      "grad_norm": 1.4354236125946045,
      "learning_rate": 0.0009214763231197771,
      "loss": 2.648,
      "step": 2820
    },
    {
      "epoch": 0.7883008356545961,
      "grad_norm": 1.357447862625122,
      "learning_rate": 0.0009211977715877438,
      "loss": 2.7018,
      "step": 2830
    },
    {
      "epoch": 0.7910863509749304,
      "grad_norm": 1.419813871383667,
      "learning_rate": 0.0009209192200557103,
      "loss": 2.5181,
      "step": 2840
    },
    {
      "epoch": 0.7938718662952646,
      "grad_norm": 1.271546483039856,
      "learning_rate": 0.0009206406685236769,
      "loss": 2.3738,
      "step": 2850
    },
    {
      "epoch": 0.7966573816155988,
      "grad_norm": 1.5175025463104248,
      "learning_rate": 0.0009203621169916436,
      "loss": 2.4937,
      "step": 2860
    },
    {
      "epoch": 0.7994428969359332,
      "grad_norm": 1.38618004322052,
      "learning_rate": 0.00092008356545961,
      "loss": 2.2005,
      "step": 2870
    },
    {
      "epoch": 0.8022284122562674,
      "grad_norm": 1.6078341007232666,
      "learning_rate": 0.0009198050139275766,
      "loss": 2.4386,
      "step": 2880
    },
    {
      "epoch": 0.8050139275766016,
      "grad_norm": 1.3587883710861206,
      "learning_rate": 0.0009195264623955431,
      "loss": 2.4942,
      "step": 2890
    },
    {
      "epoch": 0.807799442896936,
      "grad_norm": 0.9999790787696838,
      "learning_rate": 0.0009192479108635098,
      "loss": 2.4569,
      "step": 2900
    },
    {
      "epoch": 0.8105849582172702,
      "grad_norm": 1.2193816900253296,
      "learning_rate": 0.0009189693593314763,
      "loss": 2.5595,
      "step": 2910
    },
    {
      "epoch": 0.8133704735376045,
      "grad_norm": 1.1606136560440063,
      "learning_rate": 0.0009186908077994429,
      "loss": 2.5728,
      "step": 2920
    },
    {
      "epoch": 0.8161559888579387,
      "grad_norm": 1.3408945798873901,
      "learning_rate": 0.0009184122562674095,
      "loss": 2.4564,
      "step": 2930
    },
    {
      "epoch": 0.8189415041782729,
      "grad_norm": 1.4720326662063599,
      "learning_rate": 0.0009181337047353761,
      "loss": 2.6006,
      "step": 2940
    },
    {
      "epoch": 0.8217270194986073,
      "grad_norm": 1.1836766004562378,
      "learning_rate": 0.0009178551532033427,
      "loss": 2.6311,
      "step": 2950
    },
    {
      "epoch": 0.8245125348189415,
      "grad_norm": 1.6117591857910156,
      "learning_rate": 0.0009175766016713092,
      "loss": 2.6878,
      "step": 2960
    },
    {
      "epoch": 0.8272980501392758,
      "grad_norm": 1.055732011795044,
      "learning_rate": 0.0009172980501392759,
      "loss": 2.4587,
      "step": 2970
    },
    {
      "epoch": 0.83008356545961,
      "grad_norm": 1.7295316457748413,
      "learning_rate": 0.0009170194986072423,
      "loss": 2.4898,
      "step": 2980
    },
    {
      "epoch": 0.8328690807799443,
      "grad_norm": 2.995147705078125,
      "learning_rate": 0.0009167409470752089,
      "loss": 2.4622,
      "step": 2990
    },
    {
      "epoch": 0.8356545961002786,
      "grad_norm": 1.1673688888549805,
      "learning_rate": 0.0009164623955431754,
      "loss": 2.5147,
      "step": 3000
    },
    {
      "epoch": 0.8384401114206128,
      "grad_norm": 1.1923869848251343,
      "learning_rate": 0.0009161838440111421,
      "loss": 2.5471,
      "step": 3010
    },
    {
      "epoch": 0.841225626740947,
      "grad_norm": 1.7218519449234009,
      "learning_rate": 0.0009159052924791087,
      "loss": 2.4566,
      "step": 3020
    },
    {
      "epoch": 0.8440111420612814,
      "grad_norm": 1.2605904340744019,
      "learning_rate": 0.0009156267409470752,
      "loss": 2.4132,
      "step": 3030
    },
    {
      "epoch": 0.8467966573816156,
      "grad_norm": 1.4090555906295776,
      "learning_rate": 0.0009153481894150419,
      "loss": 2.539,
      "step": 3040
    },
    {
      "epoch": 0.8495821727019499,
      "grad_norm": 1.4345227479934692,
      "learning_rate": 0.0009150696378830084,
      "loss": 2.6776,
      "step": 3050
    },
    {
      "epoch": 0.8523676880222841,
      "grad_norm": 1.1424943208694458,
      "learning_rate": 0.000914791086350975,
      "loss": 2.658,
      "step": 3060
    },
    {
      "epoch": 0.8551532033426184,
      "grad_norm": 1.2283047437667847,
      "learning_rate": 0.0009145125348189414,
      "loss": 2.618,
      "step": 3070
    },
    {
      "epoch": 0.8579387186629527,
      "grad_norm": 1.3770256042480469,
      "learning_rate": 0.0009142339832869081,
      "loss": 2.4941,
      "step": 3080
    },
    {
      "epoch": 0.8607242339832869,
      "grad_norm": 3.363332748413086,
      "learning_rate": 0.0009139554317548747,
      "loss": 2.4735,
      "step": 3090
    },
    {
      "epoch": 0.8635097493036211,
      "grad_norm": 1.307361364364624,
      "learning_rate": 0.0009136768802228412,
      "loss": 2.4563,
      "step": 3100
    },
    {
      "epoch": 0.8662952646239555,
      "grad_norm": 1.243944525718689,
      "learning_rate": 0.0009133983286908078,
      "loss": 2.559,
      "step": 3110
    },
    {
      "epoch": 0.8690807799442897,
      "grad_norm": 1.2397347688674927,
      "learning_rate": 0.0009131197771587744,
      "loss": 2.4407,
      "step": 3120
    },
    {
      "epoch": 0.871866295264624,
      "grad_norm": 1.4625368118286133,
      "learning_rate": 0.000912841225626741,
      "loss": 2.5931,
      "step": 3130
    },
    {
      "epoch": 0.8746518105849582,
      "grad_norm": 1.2405434846878052,
      "learning_rate": 0.0009125626740947075,
      "loss": 2.5325,
      "step": 3140
    },
    {
      "epoch": 0.8774373259052924,
      "grad_norm": 1.9752392768859863,
      "learning_rate": 0.0009122841225626742,
      "loss": 2.565,
      "step": 3150
    },
    {
      "epoch": 0.8802228412256268,
      "grad_norm": 1.3646939992904663,
      "learning_rate": 0.0009120055710306407,
      "loss": 2.5743,
      "step": 3160
    },
    {
      "epoch": 0.883008356545961,
      "grad_norm": 1.5579534769058228,
      "learning_rate": 0.0009117270194986072,
      "loss": 2.5472,
      "step": 3170
    },
    {
      "epoch": 0.8857938718662952,
      "grad_norm": 2.42226243019104,
      "learning_rate": 0.0009114484679665738,
      "loss": 2.3035,
      "step": 3180
    },
    {
      "epoch": 0.8885793871866295,
      "grad_norm": 1.1674410104751587,
      "learning_rate": 0.0009111699164345404,
      "loss": 2.5894,
      "step": 3190
    },
    {
      "epoch": 0.8913649025069638,
      "grad_norm": 1.3225926160812378,
      "learning_rate": 0.000910891364902507,
      "loss": 2.249,
      "step": 3200
    },
    {
      "epoch": 0.8941504178272981,
      "grad_norm": 1.2591214179992676,
      "learning_rate": 0.0009106128133704735,
      "loss": 2.688,
      "step": 3210
    },
    {
      "epoch": 0.8969359331476323,
      "grad_norm": 0.9997440576553345,
      "learning_rate": 0.0009103342618384402,
      "loss": 2.5501,
      "step": 3220
    },
    {
      "epoch": 0.8997214484679665,
      "grad_norm": 1.4348294734954834,
      "learning_rate": 0.0009100557103064067,
      "loss": 2.4578,
      "step": 3230
    },
    {
      "epoch": 0.9025069637883009,
      "grad_norm": 1.8786579370498657,
      "learning_rate": 0.0009097771587743733,
      "loss": 2.4413,
      "step": 3240
    },
    {
      "epoch": 0.9052924791086351,
      "grad_norm": 1.268146276473999,
      "learning_rate": 0.0009094986072423399,
      "loss": 2.6339,
      "step": 3250
    },
    {
      "epoch": 0.9080779944289693,
      "grad_norm": 1.290724754333496,
      "learning_rate": 0.0009092200557103065,
      "loss": 2.5075,
      "step": 3260
    },
    {
      "epoch": 0.9108635097493036,
      "grad_norm": 1.3573336601257324,
      "learning_rate": 0.000908941504178273,
      "loss": 2.5851,
      "step": 3270
    },
    {
      "epoch": 0.9136490250696379,
      "grad_norm": 1.4669519662857056,
      "learning_rate": 0.0009086629526462395,
      "loss": 2.363,
      "step": 3280
    },
    {
      "epoch": 0.9164345403899722,
      "grad_norm": 1.8897361755371094,
      "learning_rate": 0.0009083844011142061,
      "loss": 2.5062,
      "step": 3290
    },
    {
      "epoch": 0.9192200557103064,
      "grad_norm": 1.1699302196502686,
      "learning_rate": 0.0009081058495821727,
      "loss": 2.5882,
      "step": 3300
    },
    {
      "epoch": 0.9220055710306406,
      "grad_norm": 1.0322651863098145,
      "learning_rate": 0.0009078272980501393,
      "loss": 2.3308,
      "step": 3310
    },
    {
      "epoch": 0.924791086350975,
      "grad_norm": 1.6198482513427734,
      "learning_rate": 0.0009075487465181058,
      "loss": 2.5845,
      "step": 3320
    },
    {
      "epoch": 0.9275766016713092,
      "grad_norm": 1.4595698118209839,
      "learning_rate": 0.0009072701949860725,
      "loss": 2.5231,
      "step": 3330
    },
    {
      "epoch": 0.9303621169916435,
      "grad_norm": 2.1530861854553223,
      "learning_rate": 0.0009069916434540391,
      "loss": 2.6477,
      "step": 3340
    },
    {
      "epoch": 0.9331476323119777,
      "grad_norm": 1.2015318870544434,
      "learning_rate": 0.0009067130919220056,
      "loss": 2.4752,
      "step": 3350
    },
    {
      "epoch": 0.935933147632312,
      "grad_norm": 1.059872031211853,
      "learning_rate": 0.0009064345403899722,
      "loss": 2.4365,
      "step": 3360
    },
    {
      "epoch": 0.9387186629526463,
      "grad_norm": 1.626658320426941,
      "learning_rate": 0.0009061559888579387,
      "loss": 2.4973,
      "step": 3370
    },
    {
      "epoch": 0.9415041782729805,
      "grad_norm": 2.131232738494873,
      "learning_rate": 0.0009058774373259053,
      "loss": 2.4464,
      "step": 3380
    },
    {
      "epoch": 0.9442896935933147,
      "grad_norm": 1.3092647790908813,
      "learning_rate": 0.0009055988857938718,
      "loss": 2.5117,
      "step": 3390
    },
    {
      "epoch": 0.947075208913649,
      "grad_norm": 0.9204092621803284,
      "learning_rate": 0.0009053203342618385,
      "loss": 2.4254,
      "step": 3400
    },
    {
      "epoch": 0.9498607242339833,
      "grad_norm": 1.6563459634780884,
      "learning_rate": 0.0009050417827298051,
      "loss": 2.4794,
      "step": 3410
    },
    {
      "epoch": 0.9526462395543176,
      "grad_norm": 1.1215386390686035,
      "learning_rate": 0.0009047632311977716,
      "loss": 2.6263,
      "step": 3420
    },
    {
      "epoch": 0.9554317548746518,
      "grad_norm": 1.5183919668197632,
      "learning_rate": 0.0009044846796657382,
      "loss": 2.6815,
      "step": 3430
    },
    {
      "epoch": 0.958217270194986,
      "grad_norm": 1.588484525680542,
      "learning_rate": 0.0009042061281337048,
      "loss": 2.5717,
      "step": 3440
    },
    {
      "epoch": 0.9610027855153204,
      "grad_norm": 1.6100398302078247,
      "learning_rate": 0.0009039275766016714,
      "loss": 2.4423,
      "step": 3450
    },
    {
      "epoch": 0.9637883008356546,
      "grad_norm": 1.4368380308151245,
      "learning_rate": 0.0009036490250696378,
      "loss": 2.5486,
      "step": 3460
    },
    {
      "epoch": 0.9665738161559888,
      "grad_norm": 1.3462988138198853,
      "learning_rate": 0.0009033704735376044,
      "loss": 2.8811,
      "step": 3470
    },
    {
      "epoch": 0.9693593314763231,
      "grad_norm": 2.7722113132476807,
      "learning_rate": 0.000903091922005571,
      "loss": 2.5645,
      "step": 3480
    },
    {
      "epoch": 0.9721448467966574,
      "grad_norm": 1.2402198314666748,
      "learning_rate": 0.0009028133704735376,
      "loss": 2.5775,
      "step": 3490
    },
    {
      "epoch": 0.9749303621169917,
      "grad_norm": 1.575783610343933,
      "learning_rate": 0.0009025348189415042,
      "loss": 2.4571,
      "step": 3500
    },
    {
      "epoch": 0.9777158774373259,
      "grad_norm": 1.9783412218093872,
      "learning_rate": 0.0009022562674094708,
      "loss": 2.3175,
      "step": 3510
    },
    {
      "epoch": 0.9805013927576601,
      "grad_norm": 1.3348389863967896,
      "learning_rate": 0.0009019777158774374,
      "loss": 2.5341,
      "step": 3520
    },
    {
      "epoch": 0.9832869080779945,
      "grad_norm": 1.2009682655334473,
      "learning_rate": 0.0009016991643454039,
      "loss": 2.4764,
      "step": 3530
    },
    {
      "epoch": 0.9860724233983287,
      "grad_norm": 1.5894309282302856,
      "learning_rate": 0.0009014206128133705,
      "loss": 2.4736,
      "step": 3540
    },
    {
      "epoch": 0.9888579387186629,
      "grad_norm": 1.083309531211853,
      "learning_rate": 0.0009011420612813371,
      "loss": 2.5119,
      "step": 3550
    },
    {
      "epoch": 0.9916434540389972,
      "grad_norm": 1.9603224992752075,
      "learning_rate": 0.0009008635097493037,
      "loss": 2.2679,
      "step": 3560
    },
    {
      "epoch": 0.9944289693593314,
      "grad_norm": 1.474579095840454,
      "learning_rate": 0.0009005849582172702,
      "loss": 2.529,
      "step": 3570
    },
    {
      "epoch": 0.9972144846796658,
      "grad_norm": 1.3432501554489136,
      "learning_rate": 0.0009003064066852367,
      "loss": 2.7045,
      "step": 3580
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.6508357524871826,
      "learning_rate": 0.0009000278551532034,
      "loss": 2.3741,
      "step": 3590
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.406306028366089,
      "eval_runtime": 8.5545,
      "eval_samples_per_second": 373.136,
      "eval_steps_per_second": 46.642,
      "step": 3590
    },
    {
      "epoch": 1.0027855153203342,
      "grad_norm": 1.4612566232681274,
      "learning_rate": 0.0008997493036211699,
      "loss": 2.4591,
      "step": 3600
    },
    {
      "epoch": 1.0055710306406684,
      "grad_norm": 1.2919337749481201,
      "learning_rate": 0.0008994707520891365,
      "loss": 2.4201,
      "step": 3610
    },
    {
      "epoch": 1.0083565459610029,
      "grad_norm": 1.6829274892807007,
      "learning_rate": 0.0008991922005571031,
      "loss": 2.7765,
      "step": 3620
    },
    {
      "epoch": 1.011142061281337,
      "grad_norm": 1.3170417547225952,
      "learning_rate": 0.0008989136490250697,
      "loss": 2.5798,
      "step": 3630
    },
    {
      "epoch": 1.0139275766016713,
      "grad_norm": 1.157371997833252,
      "learning_rate": 0.0008986350974930362,
      "loss": 2.4809,
      "step": 3640
    },
    {
      "epoch": 1.0167130919220055,
      "grad_norm": 1.3536180257797241,
      "learning_rate": 0.0008983565459610028,
      "loss": 2.4149,
      "step": 3650
    },
    {
      "epoch": 1.0194986072423398,
      "grad_norm": 1.1478989124298096,
      "learning_rate": 0.0008980779944289695,
      "loss": 2.4977,
      "step": 3660
    },
    {
      "epoch": 1.0222841225626742,
      "grad_norm": 1.1603747606277466,
      "learning_rate": 0.0008977994428969359,
      "loss": 2.4717,
      "step": 3670
    },
    {
      "epoch": 1.0250696378830084,
      "grad_norm": 1.632210373878479,
      "learning_rate": 0.0008975208913649025,
      "loss": 2.3034,
      "step": 3680
    },
    {
      "epoch": 1.0278551532033426,
      "grad_norm": 2.301032066345215,
      "learning_rate": 0.0008972423398328691,
      "loss": 2.5353,
      "step": 3690
    },
    {
      "epoch": 1.0306406685236769,
      "grad_norm": 1.5368854999542236,
      "learning_rate": 0.0008969637883008357,
      "loss": 2.5873,
      "step": 3700
    },
    {
      "epoch": 1.033426183844011,
      "grad_norm": 1.2738960981369019,
      "learning_rate": 0.0008966852367688022,
      "loss": 2.49,
      "step": 3710
    },
    {
      "epoch": 1.0362116991643453,
      "grad_norm": 1.8657538890838623,
      "learning_rate": 0.0008964066852367688,
      "loss": 2.3966,
      "step": 3720
    },
    {
      "epoch": 1.0389972144846797,
      "grad_norm": 2.4652726650238037,
      "learning_rate": 0.0008961281337047355,
      "loss": 2.5077,
      "step": 3730
    },
    {
      "epoch": 1.041782729805014,
      "grad_norm": 1.2079960107803345,
      "learning_rate": 0.000895849582172702,
      "loss": 2.4518,
      "step": 3740
    },
    {
      "epoch": 1.0445682451253482,
      "grad_norm": 1.5822467803955078,
      "learning_rate": 0.0008955710306406686,
      "loss": 2.3529,
      "step": 3750
    },
    {
      "epoch": 1.0473537604456824,
      "grad_norm": 1.4387261867523193,
      "learning_rate": 0.000895292479108635,
      "loss": 2.4588,
      "step": 3760
    },
    {
      "epoch": 1.0501392757660166,
      "grad_norm": 1.5031903982162476,
      "learning_rate": 0.0008950139275766017,
      "loss": 2.4766,
      "step": 3770
    },
    {
      "epoch": 1.052924791086351,
      "grad_norm": 1.5071768760681152,
      "learning_rate": 0.0008947353760445682,
      "loss": 2.4465,
      "step": 3780
    },
    {
      "epoch": 1.0557103064066853,
      "grad_norm": 2.0635712146759033,
      "learning_rate": 0.0008944568245125348,
      "loss": 2.6647,
      "step": 3790
    },
    {
      "epoch": 1.0584958217270195,
      "grad_norm": 1.1401463747024536,
      "learning_rate": 0.0008941782729805014,
      "loss": 2.3361,
      "step": 3800
    },
    {
      "epoch": 1.0612813370473537,
      "grad_norm": 1.2125036716461182,
      "learning_rate": 0.000893899721448468,
      "loss": 2.304,
      "step": 3810
    },
    {
      "epoch": 1.064066852367688,
      "grad_norm": 1.3619002103805542,
      "learning_rate": 0.0008936211699164346,
      "loss": 2.5081,
      "step": 3820
    },
    {
      "epoch": 1.0668523676880224,
      "grad_norm": 1.1637217998504639,
      "learning_rate": 0.0008933426183844011,
      "loss": 2.5704,
      "step": 3830
    },
    {
      "epoch": 1.0696378830083566,
      "grad_norm": 1.3032349348068237,
      "learning_rate": 0.0008930640668523678,
      "loss": 2.4805,
      "step": 3840
    },
    {
      "epoch": 1.0724233983286908,
      "grad_norm": 1.1482923030853271,
      "learning_rate": 0.0008927855153203343,
      "loss": 2.3806,
      "step": 3850
    },
    {
      "epoch": 1.075208913649025,
      "grad_norm": 1.4730639457702637,
      "learning_rate": 0.0008925069637883008,
      "loss": 2.6235,
      "step": 3860
    },
    {
      "epoch": 1.0779944289693593,
      "grad_norm": 1.486322045326233,
      "learning_rate": 0.0008922284122562674,
      "loss": 2.4399,
      "step": 3870
    },
    {
      "epoch": 1.0807799442896937,
      "grad_norm": 1.3524055480957031,
      "learning_rate": 0.000891949860724234,
      "loss": 2.36,
      "step": 3880
    },
    {
      "epoch": 1.083565459610028,
      "grad_norm": 1.6733726263046265,
      "learning_rate": 0.0008916713091922006,
      "loss": 2.4964,
      "step": 3890
    },
    {
      "epoch": 1.0863509749303621,
      "grad_norm": 1.3121404647827148,
      "learning_rate": 0.0008913927576601671,
      "loss": 2.5315,
      "step": 3900
    },
    {
      "epoch": 1.0891364902506964,
      "grad_norm": 1.9655492305755615,
      "learning_rate": 0.0008911142061281338,
      "loss": 2.3937,
      "step": 3910
    },
    {
      "epoch": 1.0919220055710306,
      "grad_norm": 1.5588632822036743,
      "learning_rate": 0.0008908356545961003,
      "loss": 2.5644,
      "step": 3920
    },
    {
      "epoch": 1.0947075208913648,
      "grad_norm": 1.5936354398727417,
      "learning_rate": 0.0008905571030640669,
      "loss": 2.3736,
      "step": 3930
    },
    {
      "epoch": 1.0974930362116992,
      "grad_norm": 1.463191032409668,
      "learning_rate": 0.0008902785515320334,
      "loss": 2.5791,
      "step": 3940
    },
    {
      "epoch": 1.1002785515320335,
      "grad_norm": 1.4579893350601196,
      "learning_rate": 0.0008900000000000001,
      "loss": 2.3294,
      "step": 3950
    },
    {
      "epoch": 1.1030640668523677,
      "grad_norm": 1.2750009298324585,
      "learning_rate": 0.0008897214484679665,
      "loss": 2.3095,
      "step": 3960
    },
    {
      "epoch": 1.105849582172702,
      "grad_norm": 1.2659629583358765,
      "learning_rate": 0.0008894428969359331,
      "loss": 2.3713,
      "step": 3970
    },
    {
      "epoch": 1.1086350974930361,
      "grad_norm": 1.2793024778366089,
      "learning_rate": 0.0008891643454038998,
      "loss": 2.4815,
      "step": 3980
    },
    {
      "epoch": 1.1114206128133706,
      "grad_norm": 1.5348848104476929,
      "learning_rate": 0.0008888857938718663,
      "loss": 2.3644,
      "step": 3990
    },
    {
      "epoch": 1.1142061281337048,
      "grad_norm": 1.8643014430999756,
      "learning_rate": 0.0008886072423398329,
      "loss": 2.2616,
      "step": 4000
    },
    {
      "epoch": 1.116991643454039,
      "grad_norm": 1.6432875394821167,
      "learning_rate": 0.0008883286908077994,
      "loss": 2.5874,
      "step": 4010
    },
    {
      "epoch": 1.1197771587743732,
      "grad_norm": 1.241422414779663,
      "learning_rate": 0.0008880501392757661,
      "loss": 2.5802,
      "step": 4020
    },
    {
      "epoch": 1.1225626740947074,
      "grad_norm": 1.4932185411453247,
      "learning_rate": 0.0008877715877437326,
      "loss": 2.4742,
      "step": 4030
    },
    {
      "epoch": 1.1253481894150417,
      "grad_norm": 1.326904058456421,
      "learning_rate": 0.0008874930362116992,
      "loss": 2.47,
      "step": 4040
    },
    {
      "epoch": 1.128133704735376,
      "grad_norm": 1.4641865491867065,
      "learning_rate": 0.0008872144846796659,
      "loss": 2.4871,
      "step": 4050
    },
    {
      "epoch": 1.1309192200557103,
      "grad_norm": 1.4165868759155273,
      "learning_rate": 0.0008869359331476323,
      "loss": 2.5226,
      "step": 4060
    },
    {
      "epoch": 1.1337047353760445,
      "grad_norm": 1.5237942934036255,
      "learning_rate": 0.0008866573816155989,
      "loss": 2.4413,
      "step": 4070
    },
    {
      "epoch": 1.1364902506963788,
      "grad_norm": 1.4232450723648071,
      "learning_rate": 0.0008863788300835654,
      "loss": 2.5276,
      "step": 4080
    },
    {
      "epoch": 1.1392757660167132,
      "grad_norm": 1.457831859588623,
      "learning_rate": 0.0008861002785515321,
      "loss": 2.4979,
      "step": 4090
    },
    {
      "epoch": 1.1420612813370474,
      "grad_norm": 1.1287785768508911,
      "learning_rate": 0.0008858217270194986,
      "loss": 2.5198,
      "step": 4100
    },
    {
      "epoch": 1.1448467966573816,
      "grad_norm": 2.2144477367401123,
      "learning_rate": 0.0008855431754874652,
      "loss": 2.5851,
      "step": 4110
    },
    {
      "epoch": 1.1476323119777159,
      "grad_norm": 1.1904432773590088,
      "learning_rate": 0.0008852646239554317,
      "loss": 2.4309,
      "step": 4120
    },
    {
      "epoch": 1.15041782729805,
      "grad_norm": 1.1705002784729004,
      "learning_rate": 0.0008849860724233984,
      "loss": 2.3675,
      "step": 4130
    },
    {
      "epoch": 1.1532033426183843,
      "grad_norm": 2.155735731124878,
      "learning_rate": 0.000884707520891365,
      "loss": 2.4777,
      "step": 4140
    },
    {
      "epoch": 1.1559888579387188,
      "grad_norm": 1.389912486076355,
      "learning_rate": 0.0008844289693593314,
      "loss": 2.4497,
      "step": 4150
    },
    {
      "epoch": 1.158774373259053,
      "grad_norm": 1.416368007659912,
      "learning_rate": 0.0008841504178272981,
      "loss": 2.3,
      "step": 4160
    },
    {
      "epoch": 1.1615598885793872,
      "grad_norm": 1.5125023126602173,
      "learning_rate": 0.0008838718662952646,
      "loss": 2.3537,
      "step": 4170
    },
    {
      "epoch": 1.1643454038997214,
      "grad_norm": 1.3144712448120117,
      "learning_rate": 0.0008835933147632312,
      "loss": 2.527,
      "step": 4180
    },
    {
      "epoch": 1.1671309192200556,
      "grad_norm": 1.2422128915786743,
      "learning_rate": 0.0008833147632311977,
      "loss": 2.3369,
      "step": 4190
    },
    {
      "epoch": 1.16991643454039,
      "grad_norm": 1.2286884784698486,
      "learning_rate": 0.0008830362116991644,
      "loss": 2.7417,
      "step": 4200
    },
    {
      "epoch": 1.1727019498607243,
      "grad_norm": 1.094249963760376,
      "learning_rate": 0.0008827576601671309,
      "loss": 2.3996,
      "step": 4210
    },
    {
      "epoch": 1.1754874651810585,
      "grad_norm": 1.1764394044876099,
      "learning_rate": 0.0008824791086350975,
      "loss": 2.4468,
      "step": 4220
    },
    {
      "epoch": 1.1782729805013927,
      "grad_norm": 1.2035174369812012,
      "learning_rate": 0.0008822005571030642,
      "loss": 2.3648,
      "step": 4230
    },
    {
      "epoch": 1.181058495821727,
      "grad_norm": 1.5827460289001465,
      "learning_rate": 0.0008819220055710307,
      "loss": 2.5205,
      "step": 4240
    },
    {
      "epoch": 1.1838440111420612,
      "grad_norm": 1.7215116024017334,
      "learning_rate": 0.0008816434540389973,
      "loss": 2.4784,
      "step": 4250
    },
    {
      "epoch": 1.1866295264623956,
      "grad_norm": 1.2432202100753784,
      "learning_rate": 0.0008813649025069637,
      "loss": 2.4597,
      "step": 4260
    },
    {
      "epoch": 1.1894150417827298,
      "grad_norm": 2.093928098678589,
      "learning_rate": 0.0008810863509749304,
      "loss": 2.4894,
      "step": 4270
    },
    {
      "epoch": 1.192200557103064,
      "grad_norm": 1.614795446395874,
      "learning_rate": 0.0008808077994428969,
      "loss": 2.586,
      "step": 4280
    },
    {
      "epoch": 1.1949860724233983,
      "grad_norm": 1.6697884798049927,
      "learning_rate": 0.0008805292479108635,
      "loss": 2.4378,
      "step": 4290
    },
    {
      "epoch": 1.1977715877437327,
      "grad_norm": 1.6672203540802002,
      "learning_rate": 0.0008802506963788301,
      "loss": 2.4101,
      "step": 4300
    },
    {
      "epoch": 1.200557103064067,
      "grad_norm": 1.4323503971099854,
      "learning_rate": 0.0008799721448467967,
      "loss": 2.4614,
      "step": 4310
    },
    {
      "epoch": 1.2033426183844012,
      "grad_norm": 1.6803035736083984,
      "learning_rate": 0.0008796935933147633,
      "loss": 2.4764,
      "step": 4320
    },
    {
      "epoch": 1.2061281337047354,
      "grad_norm": 3.0955936908721924,
      "learning_rate": 0.0008794150417827298,
      "loss": 2.4491,
      "step": 4330
    },
    {
      "epoch": 1.2089136490250696,
      "grad_norm": 1.44463050365448,
      "learning_rate": 0.0008791364902506965,
      "loss": 2.5742,
      "step": 4340
    },
    {
      "epoch": 1.2116991643454038,
      "grad_norm": 1.6345651149749756,
      "learning_rate": 0.000878857938718663,
      "loss": 2.3708,
      "step": 4350
    },
    {
      "epoch": 1.2144846796657383,
      "grad_norm": 1.8529552221298218,
      "learning_rate": 0.0008785793871866295,
      "loss": 2.5324,
      "step": 4360
    },
    {
      "epoch": 1.2172701949860725,
      "grad_norm": 1.1213207244873047,
      "learning_rate": 0.000878300835654596,
      "loss": 2.6369,
      "step": 4370
    },
    {
      "epoch": 1.2200557103064067,
      "grad_norm": 1.5448205471038818,
      "learning_rate": 0.0008780222841225627,
      "loss": 2.5796,
      "step": 4380
    },
    {
      "epoch": 1.222841225626741,
      "grad_norm": 1.3022407293319702,
      "learning_rate": 0.0008777437325905293,
      "loss": 2.4645,
      "step": 4390
    },
    {
      "epoch": 1.2256267409470751,
      "grad_norm": 1.5589473247528076,
      "learning_rate": 0.0008774651810584958,
      "loss": 2.3262,
      "step": 4400
    },
    {
      "epoch": 1.2284122562674096,
      "grad_norm": 1.459229826927185,
      "learning_rate": 0.0008771866295264625,
      "loss": 2.296,
      "step": 4410
    },
    {
      "epoch": 1.2311977715877438,
      "grad_norm": 1.064813494682312,
      "learning_rate": 0.000876908077994429,
      "loss": 2.2014,
      "step": 4420
    },
    {
      "epoch": 1.233983286908078,
      "grad_norm": 1.5980842113494873,
      "learning_rate": 0.0008766295264623956,
      "loss": 2.3131,
      "step": 4430
    },
    {
      "epoch": 1.2367688022284122,
      "grad_norm": 1.0553364753723145,
      "learning_rate": 0.000876350974930362,
      "loss": 2.4306,
      "step": 4440
    },
    {
      "epoch": 1.2395543175487465,
      "grad_norm": 1.982969045639038,
      "learning_rate": 0.0008760724233983288,
      "loss": 2.463,
      "step": 4450
    },
    {
      "epoch": 1.2423398328690807,
      "grad_norm": 1.407447338104248,
      "learning_rate": 0.0008757938718662953,
      "loss": 2.2746,
      "step": 4460
    },
    {
      "epoch": 1.2451253481894151,
      "grad_norm": 1.558633804321289,
      "learning_rate": 0.0008755153203342618,
      "loss": 2.5858,
      "step": 4470
    },
    {
      "epoch": 1.2479108635097493,
      "grad_norm": 1.6369287967681885,
      "learning_rate": 0.0008752367688022284,
      "loss": 2.3685,
      "step": 4480
    },
    {
      "epoch": 1.2506963788300836,
      "grad_norm": 1.4967803955078125,
      "learning_rate": 0.000874958217270195,
      "loss": 2.4378,
      "step": 4490
    },
    {
      "epoch": 1.2534818941504178,
      "grad_norm": 1.395831823348999,
      "learning_rate": 0.0008746796657381616,
      "loss": 2.58,
      "step": 4500
    },
    {
      "epoch": 1.2562674094707522,
      "grad_norm": 1.3929535150527954,
      "learning_rate": 0.0008744011142061281,
      "loss": 2.2813,
      "step": 4510
    },
    {
      "epoch": 1.2590529247910864,
      "grad_norm": 0.9952377080917358,
      "learning_rate": 0.0008741225626740948,
      "loss": 2.41,
      "step": 4520
    },
    {
      "epoch": 1.2618384401114207,
      "grad_norm": 1.4244884252548218,
      "learning_rate": 0.0008738440111420613,
      "loss": 2.6545,
      "step": 4530
    },
    {
      "epoch": 1.2646239554317549,
      "grad_norm": 1.4346792697906494,
      "learning_rate": 0.0008735654596100279,
      "loss": 2.3372,
      "step": 4540
    },
    {
      "epoch": 1.267409470752089,
      "grad_norm": 1.216755986213684,
      "learning_rate": 0.0008732869080779944,
      "loss": 2.2982,
      "step": 4550
    },
    {
      "epoch": 1.2701949860724233,
      "grad_norm": 1.8581485748291016,
      "learning_rate": 0.000873008356545961,
      "loss": 2.6007,
      "step": 4560
    },
    {
      "epoch": 1.2729805013927575,
      "grad_norm": 1.3053561449050903,
      "learning_rate": 0.0008727298050139276,
      "loss": 2.5728,
      "step": 4570
    },
    {
      "epoch": 1.275766016713092,
      "grad_norm": 1.5136610269546509,
      "learning_rate": 0.0008724512534818941,
      "loss": 2.5635,
      "step": 4580
    },
    {
      "epoch": 1.2785515320334262,
      "grad_norm": 1.8121294975280762,
      "learning_rate": 0.0008721727019498608,
      "loss": 2.4537,
      "step": 4590
    },
    {
      "epoch": 1.2813370473537604,
      "grad_norm": 1.2781909704208374,
      "learning_rate": 0.0008718941504178273,
      "loss": 2.2631,
      "step": 4600
    },
    {
      "epoch": 1.2841225626740946,
      "grad_norm": 1.277390480041504,
      "learning_rate": 0.0008716155988857939,
      "loss": 2.2568,
      "step": 4610
    },
    {
      "epoch": 1.286908077994429,
      "grad_norm": 1.217903971672058,
      "learning_rate": 0.0008713370473537605,
      "loss": 2.4022,
      "step": 4620
    },
    {
      "epoch": 1.2896935933147633,
      "grad_norm": 1.4290454387664795,
      "learning_rate": 0.0008710584958217271,
      "loss": 2.4514,
      "step": 4630
    },
    {
      "epoch": 1.2924791086350975,
      "grad_norm": 1.6049617528915405,
      "learning_rate": 0.0008707799442896937,
      "loss": 2.5207,
      "step": 4640
    },
    {
      "epoch": 1.2952646239554317,
      "grad_norm": 2.6267402172088623,
      "learning_rate": 0.0008705013927576601,
      "loss": 2.5118,
      "step": 4650
    },
    {
      "epoch": 1.298050139275766,
      "grad_norm": 1.4410964250564575,
      "learning_rate": 0.0008702228412256267,
      "loss": 2.3168,
      "step": 4660
    },
    {
      "epoch": 1.3008356545961002,
      "grad_norm": 1.5928828716278076,
      "learning_rate": 0.0008699442896935933,
      "loss": 2.4933,
      "step": 4670
    },
    {
      "epoch": 1.3036211699164346,
      "grad_norm": 1.5655015707015991,
      "learning_rate": 0.0008696657381615599,
      "loss": 2.5487,
      "step": 4680
    },
    {
      "epoch": 1.3064066852367688,
      "grad_norm": 1.595541000366211,
      "learning_rate": 0.0008693871866295264,
      "loss": 2.7002,
      "step": 4690
    },
    {
      "epoch": 1.309192200557103,
      "grad_norm": 1.1704699993133545,
      "learning_rate": 0.0008691086350974931,
      "loss": 2.5207,
      "step": 4700
    },
    {
      "epoch": 1.3119777158774373,
      "grad_norm": 1.456167459487915,
      "learning_rate": 0.0008688300835654597,
      "loss": 2.2512,
      "step": 4710
    },
    {
      "epoch": 1.3147632311977717,
      "grad_norm": 1.5502310991287231,
      "learning_rate": 0.0008685515320334262,
      "loss": 2.3478,
      "step": 4720
    },
    {
      "epoch": 1.317548746518106,
      "grad_norm": 1.6640392541885376,
      "learning_rate": 0.0008682729805013928,
      "loss": 2.5919,
      "step": 4730
    },
    {
      "epoch": 1.3203342618384402,
      "grad_norm": 2.0881025791168213,
      "learning_rate": 0.0008679944289693594,
      "loss": 2.4603,
      "step": 4740
    },
    {
      "epoch": 1.3231197771587744,
      "grad_norm": 1.3277233839035034,
      "learning_rate": 0.0008677158774373259,
      "loss": 2.7463,
      "step": 4750
    },
    {
      "epoch": 1.3259052924791086,
      "grad_norm": 1.3412487506866455,
      "learning_rate": 0.0008674373259052924,
      "loss": 2.51,
      "step": 4760
    },
    {
      "epoch": 1.3286908077994428,
      "grad_norm": 1.426458716392517,
      "learning_rate": 0.0008671587743732591,
      "loss": 2.5636,
      "step": 4770
    },
    {
      "epoch": 1.331476323119777,
      "grad_norm": 1.9711438417434692,
      "learning_rate": 0.0008668802228412257,
      "loss": 2.622,
      "step": 4780
    },
    {
      "epoch": 1.3342618384401115,
      "grad_norm": 1.4340852499008179,
      "learning_rate": 0.0008666016713091922,
      "loss": 2.4166,
      "step": 4790
    },
    {
      "epoch": 1.3370473537604457,
      "grad_norm": 1.8819503784179688,
      "learning_rate": 0.0008663231197771588,
      "loss": 2.5511,
      "step": 4800
    },
    {
      "epoch": 1.33983286908078,
      "grad_norm": 1.7910012006759644,
      "learning_rate": 0.0008660445682451254,
      "loss": 2.2883,
      "step": 4810
    },
    {
      "epoch": 1.3426183844011141,
      "grad_norm": 1.11577308177948,
      "learning_rate": 0.000865766016713092,
      "loss": 2.1784,
      "step": 4820
    },
    {
      "epoch": 1.3454038997214486,
      "grad_norm": 1.2146192789077759,
      "learning_rate": 0.0008654874651810585,
      "loss": 2.2619,
      "step": 4830
    },
    {
      "epoch": 1.3481894150417828,
      "grad_norm": 1.162723183631897,
      "learning_rate": 0.000865208913649025,
      "loss": 2.4557,
      "step": 4840
    },
    {
      "epoch": 1.350974930362117,
      "grad_norm": 1.2347052097320557,
      "learning_rate": 0.0008649303621169916,
      "loss": 2.7314,
      "step": 4850
    },
    {
      "epoch": 1.3537604456824512,
      "grad_norm": 1.4150409698486328,
      "learning_rate": 0.0008646518105849582,
      "loss": 2.4856,
      "step": 4860
    },
    {
      "epoch": 1.3565459610027855,
      "grad_norm": 1.5935486555099487,
      "learning_rate": 0.0008643732590529248,
      "loss": 2.3712,
      "step": 4870
    },
    {
      "epoch": 1.3593314763231197,
      "grad_norm": 1.191989541053772,
      "learning_rate": 0.0008640947075208914,
      "loss": 2.3328,
      "step": 4880
    },
    {
      "epoch": 1.362116991643454,
      "grad_norm": 1.498227596282959,
      "learning_rate": 0.000863816155988858,
      "loss": 2.234,
      "step": 4890
    },
    {
      "epoch": 1.3649025069637883,
      "grad_norm": 1.453818678855896,
      "learning_rate": 0.0008635376044568245,
      "loss": 2.4424,
      "step": 4900
    },
    {
      "epoch": 1.3676880222841226,
      "grad_norm": 1.4252535104751587,
      "learning_rate": 0.0008632590529247911,
      "loss": 2.4066,
      "step": 4910
    },
    {
      "epoch": 1.3704735376044568,
      "grad_norm": 1.3077820539474487,
      "learning_rate": 0.0008629805013927577,
      "loss": 2.567,
      "step": 4920
    },
    {
      "epoch": 1.3732590529247912,
      "grad_norm": 1.5380414724349976,
      "learning_rate": 0.0008627019498607243,
      "loss": 2.3976,
      "step": 4930
    },
    {
      "epoch": 1.3760445682451254,
      "grad_norm": 1.2236677408218384,
      "learning_rate": 0.0008624233983286909,
      "loss": 2.5227,
      "step": 4940
    },
    {
      "epoch": 1.3788300835654597,
      "grad_norm": 1.347116231918335,
      "learning_rate": 0.0008621448467966574,
      "loss": 2.4053,
      "step": 4950
    },
    {
      "epoch": 1.3816155988857939,
      "grad_norm": 1.5117372274398804,
      "learning_rate": 0.000861866295264624,
      "loss": 2.4355,
      "step": 4960
    },
    {
      "epoch": 1.384401114206128,
      "grad_norm": 1.423092246055603,
      "learning_rate": 0.0008615877437325905,
      "loss": 2.4882,
      "step": 4970
    },
    {
      "epoch": 1.3871866295264623,
      "grad_norm": 1.3323116302490234,
      "learning_rate": 0.0008613091922005571,
      "loss": 2.4307,
      "step": 4980
    },
    {
      "epoch": 1.3899721448467965,
      "grad_norm": 2.0638983249664307,
      "learning_rate": 0.0008610306406685237,
      "loss": 2.5537,
      "step": 4990
    },
    {
      "epoch": 1.392757660167131,
      "grad_norm": 2.0708186626434326,
      "learning_rate": 0.0008607520891364903,
      "loss": 2.3708,
      "step": 5000
    },
    {
      "epoch": 1.3955431754874652,
      "grad_norm": 2.9912097454071045,
      "learning_rate": 0.0008604735376044568,
      "loss": 2.6424,
      "step": 5010
    },
    {
      "epoch": 1.3983286908077994,
      "grad_norm": 1.644172191619873,
      "learning_rate": 0.0008601949860724234,
      "loss": 2.4277,
      "step": 5020
    },
    {
      "epoch": 1.4011142061281336,
      "grad_norm": 1.307828426361084,
      "learning_rate": 0.0008599164345403901,
      "loss": 2.487,
      "step": 5030
    },
    {
      "epoch": 1.403899721448468,
      "grad_norm": 1.4547945261001587,
      "learning_rate": 0.0008596378830083565,
      "loss": 2.4201,
      "step": 5040
    },
    {
      "epoch": 1.4066852367688023,
      "grad_norm": 1.5435593128204346,
      "learning_rate": 0.0008593593314763231,
      "loss": 2.5642,
      "step": 5050
    },
    {
      "epoch": 1.4094707520891365,
      "grad_norm": 1.1553717851638794,
      "learning_rate": 0.0008590807799442897,
      "loss": 2.3856,
      "step": 5060
    },
    {
      "epoch": 1.4122562674094707,
      "grad_norm": 1.2565151453018188,
      "learning_rate": 0.0008588022284122563,
      "loss": 2.4595,
      "step": 5070
    },
    {
      "epoch": 1.415041782729805,
      "grad_norm": 1.3578641414642334,
      "learning_rate": 0.0008585236768802228,
      "loss": 2.255,
      "step": 5080
    },
    {
      "epoch": 1.4178272980501392,
      "grad_norm": 1.6320995092391968,
      "learning_rate": 0.0008582451253481894,
      "loss": 2.5573,
      "step": 5090
    },
    {
      "epoch": 1.4206128133704734,
      "grad_norm": 1.83077871799469,
      "learning_rate": 0.0008579665738161561,
      "loss": 2.4367,
      "step": 5100
    },
    {
      "epoch": 1.4233983286908078,
      "grad_norm": 1.336504340171814,
      "learning_rate": 0.0008576880222841226,
      "loss": 2.3728,
      "step": 5110
    },
    {
      "epoch": 1.426183844011142,
      "grad_norm": 1.3290684223175049,
      "learning_rate": 0.0008574094707520892,
      "loss": 2.5579,
      "step": 5120
    },
    {
      "epoch": 1.4289693593314763,
      "grad_norm": 1.5716007947921753,
      "learning_rate": 0.0008571309192200557,
      "loss": 2.4424,
      "step": 5130
    },
    {
      "epoch": 1.4317548746518105,
      "grad_norm": 2.309199810028076,
      "learning_rate": 0.0008568523676880224,
      "loss": 2.3258,
      "step": 5140
    },
    {
      "epoch": 1.434540389972145,
      "grad_norm": 2.0193002223968506,
      "learning_rate": 0.0008565738161559888,
      "loss": 2.5223,
      "step": 5150
    },
    {
      "epoch": 1.4373259052924792,
      "grad_norm": 1.114368200302124,
      "learning_rate": 0.0008562952646239554,
      "loss": 2.3876,
      "step": 5160
    },
    {
      "epoch": 1.4401114206128134,
      "grad_norm": 1.0269701480865479,
      "learning_rate": 0.000856016713091922,
      "loss": 2.511,
      "step": 5170
    },
    {
      "epoch": 1.4428969359331476,
      "grad_norm": 1.3479105234146118,
      "learning_rate": 0.0008557381615598886,
      "loss": 2.7617,
      "step": 5180
    },
    {
      "epoch": 1.4456824512534818,
      "grad_norm": 1.152579426765442,
      "learning_rate": 0.0008554596100278552,
      "loss": 2.4129,
      "step": 5190
    },
    {
      "epoch": 1.448467966573816,
      "grad_norm": 1.9077376127243042,
      "learning_rate": 0.0008551810584958217,
      "loss": 2.4303,
      "step": 5200
    },
    {
      "epoch": 1.4512534818941505,
      "grad_norm": 1.5234146118164062,
      "learning_rate": 0.0008549025069637884,
      "loss": 2.4073,
      "step": 5210
    },
    {
      "epoch": 1.4540389972144847,
      "grad_norm": 1.3769124746322632,
      "learning_rate": 0.0008546239554317549,
      "loss": 2.6313,
      "step": 5220
    },
    {
      "epoch": 1.456824512534819,
      "grad_norm": 2.118243932723999,
      "learning_rate": 0.0008543454038997215,
      "loss": 2.4816,
      "step": 5230
    },
    {
      "epoch": 1.4596100278551531,
      "grad_norm": 1.343883752822876,
      "learning_rate": 0.000854066852367688,
      "loss": 2.4175,
      "step": 5240
    },
    {
      "epoch": 1.4623955431754876,
      "grad_norm": 1.85471773147583,
      "learning_rate": 0.0008537883008356546,
      "loss": 2.4087,
      "step": 5250
    },
    {
      "epoch": 1.4651810584958218,
      "grad_norm": 1.2788963317871094,
      "learning_rate": 0.0008535097493036212,
      "loss": 2.4769,
      "step": 5260
    },
    {
      "epoch": 1.467966573816156,
      "grad_norm": 1.537280559539795,
      "learning_rate": 0.0008532311977715877,
      "loss": 2.4658,
      "step": 5270
    },
    {
      "epoch": 1.4707520891364902,
      "grad_norm": 1.3490735292434692,
      "learning_rate": 0.0008529526462395544,
      "loss": 2.5781,
      "step": 5280
    },
    {
      "epoch": 1.4735376044568245,
      "grad_norm": 1.401794195175171,
      "learning_rate": 0.0008526740947075209,
      "loss": 2.4965,
      "step": 5290
    },
    {
      "epoch": 1.4763231197771587,
      "grad_norm": 1.2649232149124146,
      "learning_rate": 0.0008523955431754875,
      "loss": 2.416,
      "step": 5300
    },
    {
      "epoch": 1.479108635097493,
      "grad_norm": 1.411764144897461,
      "learning_rate": 0.000852116991643454,
      "loss": 2.448,
      "step": 5310
    },
    {
      "epoch": 1.4818941504178273,
      "grad_norm": 1.9823192358016968,
      "learning_rate": 0.0008518384401114207,
      "loss": 2.2413,
      "step": 5320
    },
    {
      "epoch": 1.4846796657381616,
      "grad_norm": 1.3081318140029907,
      "learning_rate": 0.0008515598885793872,
      "loss": 2.3889,
      "step": 5330
    },
    {
      "epoch": 1.4874651810584958,
      "grad_norm": 1.4099092483520508,
      "learning_rate": 0.0008512813370473537,
      "loss": 2.6169,
      "step": 5340
    },
    {
      "epoch": 1.49025069637883,
      "grad_norm": 1.5063430070877075,
      "learning_rate": 0.0008510027855153204,
      "loss": 2.533,
      "step": 5350
    },
    {
      "epoch": 1.4930362116991645,
      "grad_norm": 1.7313750982284546,
      "learning_rate": 0.0008507242339832869,
      "loss": 2.4669,
      "step": 5360
    },
    {
      "epoch": 1.4958217270194987,
      "grad_norm": 1.896119475364685,
      "learning_rate": 0.0008504456824512535,
      "loss": 2.6384,
      "step": 5370
    },
    {
      "epoch": 1.498607242339833,
      "grad_norm": 1.1091203689575195,
      "learning_rate": 0.00085016713091922,
      "loss": 2.5833,
      "step": 5380
    },
    {
      "epoch": 1.501392757660167,
      "grad_norm": 1.5639678239822388,
      "learning_rate": 0.0008498885793871867,
      "loss": 2.6135,
      "step": 5390
    },
    {
      "epoch": 1.5041782729805013,
      "grad_norm": 1.9277924299240112,
      "learning_rate": 0.0008496100278551532,
      "loss": 2.4559,
      "step": 5400
    },
    {
      "epoch": 1.5069637883008355,
      "grad_norm": 1.4500378370285034,
      "learning_rate": 0.0008493314763231198,
      "loss": 2.6439,
      "step": 5410
    },
    {
      "epoch": 1.5097493036211698,
      "grad_norm": 1.9656790494918823,
      "learning_rate": 0.0008490529247910865,
      "loss": 2.4827,
      "step": 5420
    },
    {
      "epoch": 1.5125348189415042,
      "grad_norm": 1.4778428077697754,
      "learning_rate": 0.000848774373259053,
      "loss": 2.325,
      "step": 5430
    },
    {
      "epoch": 1.5153203342618384,
      "grad_norm": 1.4972937107086182,
      "learning_rate": 0.0008484958217270195,
      "loss": 2.5825,
      "step": 5440
    },
    {
      "epoch": 1.5181058495821727,
      "grad_norm": 1.6604104042053223,
      "learning_rate": 0.000848217270194986,
      "loss": 2.5202,
      "step": 5450
    },
    {
      "epoch": 1.520891364902507,
      "grad_norm": 2.7263386249542236,
      "learning_rate": 0.0008479387186629527,
      "loss": 2.5038,
      "step": 5460
    },
    {
      "epoch": 1.5236768802228413,
      "grad_norm": 1.2281723022460938,
      "learning_rate": 0.0008476601671309192,
      "loss": 2.5018,
      "step": 5470
    },
    {
      "epoch": 1.5264623955431755,
      "grad_norm": 2.7635321617126465,
      "learning_rate": 0.0008473816155988858,
      "loss": 2.609,
      "step": 5480
    },
    {
      "epoch": 1.5292479108635098,
      "grad_norm": 1.3000730276107788,
      "learning_rate": 0.0008471030640668523,
      "loss": 2.3773,
      "step": 5490
    },
    {
      "epoch": 1.532033426183844,
      "grad_norm": 1.1592458486557007,
      "learning_rate": 0.000846824512534819,
      "loss": 2.3032,
      "step": 5500
    },
    {
      "epoch": 1.5348189415041782,
      "grad_norm": 1.5116746425628662,
      "learning_rate": 0.0008465459610027856,
      "loss": 2.3355,
      "step": 5510
    },
    {
      "epoch": 1.5376044568245124,
      "grad_norm": 1.6036648750305176,
      "learning_rate": 0.0008462674094707521,
      "loss": 2.3178,
      "step": 5520
    },
    {
      "epoch": 1.5403899721448466,
      "grad_norm": 1.2953124046325684,
      "learning_rate": 0.0008459888579387188,
      "loss": 2.5132,
      "step": 5530
    },
    {
      "epoch": 1.543175487465181,
      "grad_norm": 1.2321703433990479,
      "learning_rate": 0.0008457103064066852,
      "loss": 2.3899,
      "step": 5540
    },
    {
      "epoch": 1.5459610027855153,
      "grad_norm": 1.2665367126464844,
      "learning_rate": 0.0008454317548746518,
      "loss": 2.5171,
      "step": 5550
    },
    {
      "epoch": 1.5487465181058497,
      "grad_norm": 5.491153717041016,
      "learning_rate": 0.0008451532033426183,
      "loss": 2.3692,
      "step": 5560
    },
    {
      "epoch": 1.551532033426184,
      "grad_norm": 1.9508066177368164,
      "learning_rate": 0.000844874651810585,
      "loss": 2.0581,
      "step": 5570
    },
    {
      "epoch": 1.5543175487465182,
      "grad_norm": 1.3831769227981567,
      "learning_rate": 0.0008445961002785516,
      "loss": 2.5829,
      "step": 5580
    },
    {
      "epoch": 1.5571030640668524,
      "grad_norm": 1.1479387283325195,
      "learning_rate": 0.0008443175487465181,
      "loss": 2.3515,
      "step": 5590
    },
    {
      "epoch": 1.5598885793871866,
      "grad_norm": 1.3690439462661743,
      "learning_rate": 0.0008440389972144848,
      "loss": 2.4492,
      "step": 5600
    },
    {
      "epoch": 1.5626740947075208,
      "grad_norm": 1.3672510385513306,
      "learning_rate": 0.0008437604456824513,
      "loss": 2.3337,
      "step": 5610
    },
    {
      "epoch": 1.565459610027855,
      "grad_norm": 1.2372057437896729,
      "learning_rate": 0.0008434818941504179,
      "loss": 2.4582,
      "step": 5620
    },
    {
      "epoch": 1.5682451253481893,
      "grad_norm": 1.0453547239303589,
      "learning_rate": 0.0008432033426183843,
      "loss": 2.3788,
      "step": 5630
    },
    {
      "epoch": 1.5710306406685237,
      "grad_norm": 1.5158696174621582,
      "learning_rate": 0.000842924791086351,
      "loss": 2.3808,
      "step": 5640
    },
    {
      "epoch": 1.573816155988858,
      "grad_norm": 1.2887293100357056,
      "learning_rate": 0.0008426462395543175,
      "loss": 2.3433,
      "step": 5650
    },
    {
      "epoch": 1.5766016713091922,
      "grad_norm": 1.4751222133636475,
      "learning_rate": 0.0008423676880222841,
      "loss": 2.5571,
      "step": 5660
    },
    {
      "epoch": 1.5793871866295266,
      "grad_norm": 1.2774983644485474,
      "learning_rate": 0.0008420891364902507,
      "loss": 2.7037,
      "step": 5670
    },
    {
      "epoch": 1.5821727019498608,
      "grad_norm": 1.666767954826355,
      "learning_rate": 0.0008418105849582173,
      "loss": 2.6777,
      "step": 5680
    },
    {
      "epoch": 1.584958217270195,
      "grad_norm": 1.2695374488830566,
      "learning_rate": 0.0008415320334261839,
      "loss": 2.3811,
      "step": 5690
    },
    {
      "epoch": 1.5877437325905293,
      "grad_norm": 1.2878268957138062,
      "learning_rate": 0.0008412534818941504,
      "loss": 2.4794,
      "step": 5700
    },
    {
      "epoch": 1.5905292479108635,
      "grad_norm": 1.232753038406372,
      "learning_rate": 0.0008409749303621171,
      "loss": 2.3441,
      "step": 5710
    },
    {
      "epoch": 1.5933147632311977,
      "grad_norm": 7.615690231323242,
      "learning_rate": 0.0008406963788300836,
      "loss": 2.5287,
      "step": 5720
    },
    {
      "epoch": 1.596100278551532,
      "grad_norm": 1.1922414302825928,
      "learning_rate": 0.0008404178272980501,
      "loss": 2.5361,
      "step": 5730
    },
    {
      "epoch": 1.5988857938718661,
      "grad_norm": 6.901677131652832,
      "learning_rate": 0.0008401392757660166,
      "loss": 2.4592,
      "step": 5740
    },
    {
      "epoch": 1.6016713091922006,
      "grad_norm": 1.0901975631713867,
      "learning_rate": 0.0008398607242339833,
      "loss": 2.4945,
      "step": 5750
    },
    {
      "epoch": 1.6044568245125348,
      "grad_norm": 1.0598312616348267,
      "learning_rate": 0.0008395821727019499,
      "loss": 2.3916,
      "step": 5760
    },
    {
      "epoch": 1.6072423398328692,
      "grad_norm": 1.4701067209243774,
      "learning_rate": 0.0008393036211699164,
      "loss": 2.2952,
      "step": 5770
    },
    {
      "epoch": 1.6100278551532035,
      "grad_norm": 1.685010313987732,
      "learning_rate": 0.0008390250696378831,
      "loss": 2.3241,
      "step": 5780
    },
    {
      "epoch": 1.6128133704735377,
      "grad_norm": 1.1402126550674438,
      "learning_rate": 0.0008387465181058496,
      "loss": 2.4277,
      "step": 5790
    },
    {
      "epoch": 1.615598885793872,
      "grad_norm": 1.5091774463653564,
      "learning_rate": 0.0008384679665738162,
      "loss": 2.3327,
      "step": 5800
    },
    {
      "epoch": 1.6183844011142061,
      "grad_norm": 1.7020095586776733,
      "learning_rate": 0.0008381894150417827,
      "loss": 2.604,
      "step": 5810
    },
    {
      "epoch": 1.6211699164345403,
      "grad_norm": 1.1630966663360596,
      "learning_rate": 0.0008379108635097494,
      "loss": 2.6356,
      "step": 5820
    },
    {
      "epoch": 1.6239554317548746,
      "grad_norm": 1.4947725534439087,
      "learning_rate": 0.000837632311977716,
      "loss": 2.5718,
      "step": 5830
    },
    {
      "epoch": 1.6267409470752088,
      "grad_norm": 1.3917486667633057,
      "learning_rate": 0.0008373537604456824,
      "loss": 2.5618,
      "step": 5840
    },
    {
      "epoch": 1.6295264623955432,
      "grad_norm": 1.2452794313430786,
      "learning_rate": 0.000837075208913649,
      "loss": 2.4527,
      "step": 5850
    },
    {
      "epoch": 1.6323119777158774,
      "grad_norm": 1.2787998914718628,
      "learning_rate": 0.0008367966573816156,
      "loss": 2.4076,
      "step": 5860
    },
    {
      "epoch": 1.6350974930362117,
      "grad_norm": 1.579384207725525,
      "learning_rate": 0.0008365181058495822,
      "loss": 2.3852,
      "step": 5870
    },
    {
      "epoch": 1.637883008356546,
      "grad_norm": 1.3344780206680298,
      "learning_rate": 0.0008362395543175487,
      "loss": 2.391,
      "step": 5880
    },
    {
      "epoch": 1.6406685236768803,
      "grad_norm": 1.2701056003570557,
      "learning_rate": 0.0008359610027855154,
      "loss": 2.3682,
      "step": 5890
    },
    {
      "epoch": 1.6434540389972145,
      "grad_norm": 2.0189638137817383,
      "learning_rate": 0.0008356824512534819,
      "loss": 2.5332,
      "step": 5900
    },
    {
      "epoch": 1.6462395543175488,
      "grad_norm": 1.1444721221923828,
      "learning_rate": 0.0008354038997214485,
      "loss": 2.3393,
      "step": 5910
    },
    {
      "epoch": 1.649025069637883,
      "grad_norm": 1.35390305519104,
      "learning_rate": 0.0008351253481894151,
      "loss": 2.4116,
      "step": 5920
    },
    {
      "epoch": 1.6518105849582172,
      "grad_norm": 1.315775990486145,
      "learning_rate": 0.0008348467966573816,
      "loss": 2.4844,
      "step": 5930
    },
    {
      "epoch": 1.6545961002785514,
      "grad_norm": 1.342215657234192,
      "learning_rate": 0.0008345682451253482,
      "loss": 2.3155,
      "step": 5940
    },
    {
      "epoch": 1.6573816155988856,
      "grad_norm": 1.4621185064315796,
      "learning_rate": 0.0008342896935933147,
      "loss": 2.4632,
      "step": 5950
    },
    {
      "epoch": 1.66016713091922,
      "grad_norm": 1.560271978378296,
      "learning_rate": 0.0008340111420612814,
      "loss": 2.4635,
      "step": 5960
    },
    {
      "epoch": 1.6629526462395543,
      "grad_norm": 1.2337414026260376,
      "learning_rate": 0.0008337325905292479,
      "loss": 2.3149,
      "step": 5970
    },
    {
      "epoch": 1.6657381615598887,
      "grad_norm": 1.6877257823944092,
      "learning_rate": 0.0008334540389972145,
      "loss": 2.2842,
      "step": 5980
    },
    {
      "epoch": 1.668523676880223,
      "grad_norm": 1.5340789556503296,
      "learning_rate": 0.0008331754874651811,
      "loss": 2.4816,
      "step": 5990
    },
    {
      "epoch": 1.6713091922005572,
      "grad_norm": 1.0539878606796265,
      "learning_rate": 0.0008328969359331477,
      "loss": 2.3371,
      "step": 6000
    },
    {
      "epoch": 1.6740947075208914,
      "grad_norm": 1.2730919122695923,
      "learning_rate": 0.0008326183844011143,
      "loss": 2.3748,
      "step": 6010
    },
    {
      "epoch": 1.6768802228412256,
      "grad_norm": 1.3607196807861328,
      "learning_rate": 0.0008323398328690808,
      "loss": 2.4295,
      "step": 6020
    },
    {
      "epoch": 1.6796657381615598,
      "grad_norm": 1.3761805295944214,
      "learning_rate": 0.0008320612813370473,
      "loss": 2.7483,
      "step": 6030
    },
    {
      "epoch": 1.682451253481894,
      "grad_norm": 1.4564507007598877,
      "learning_rate": 0.0008317827298050139,
      "loss": 2.3211,
      "step": 6040
    },
    {
      "epoch": 1.6852367688022283,
      "grad_norm": 1.2749069929122925,
      "learning_rate": 0.0008315041782729805,
      "loss": 2.4103,
      "step": 6050
    },
    {
      "epoch": 1.6880222841225627,
      "grad_norm": 1.183241367340088,
      "learning_rate": 0.000831225626740947,
      "loss": 2.4233,
      "step": 6060
    },
    {
      "epoch": 1.690807799442897,
      "grad_norm": 1.3602735996246338,
      "learning_rate": 0.0008309470752089137,
      "loss": 2.5632,
      "step": 6070
    },
    {
      "epoch": 1.6935933147632312,
      "grad_norm": 2.0438053607940674,
      "learning_rate": 0.0008306685236768803,
      "loss": 2.3983,
      "step": 6080
    },
    {
      "epoch": 1.6963788300835656,
      "grad_norm": 0.9943479895591736,
      "learning_rate": 0.0008303899721448468,
      "loss": 2.536,
      "step": 6090
    },
    {
      "epoch": 1.6991643454038998,
      "grad_norm": 1.4198260307312012,
      "learning_rate": 0.0008301114206128134,
      "loss": 2.6579,
      "step": 6100
    },
    {
      "epoch": 1.701949860724234,
      "grad_norm": 1.9250845909118652,
      "learning_rate": 0.00082983286908078,
      "loss": 2.2715,
      "step": 6110
    },
    {
      "epoch": 1.7047353760445683,
      "grad_norm": 1.8493574857711792,
      "learning_rate": 0.0008295543175487466,
      "loss": 2.4315,
      "step": 6120
    },
    {
      "epoch": 1.7075208913649025,
      "grad_norm": 1.0615828037261963,
      "learning_rate": 0.000829275766016713,
      "loss": 2.3803,
      "step": 6130
    },
    {
      "epoch": 1.7103064066852367,
      "grad_norm": 1.4312912225723267,
      "learning_rate": 0.0008289972144846797,
      "loss": 2.2793,
      "step": 6140
    },
    {
      "epoch": 1.713091922005571,
      "grad_norm": 1.0620651245117188,
      "learning_rate": 0.0008287186629526463,
      "loss": 2.4466,
      "step": 6150
    },
    {
      "epoch": 1.7158774373259051,
      "grad_norm": 1.7495641708374023,
      "learning_rate": 0.0008284401114206128,
      "loss": 2.4945,
      "step": 6160
    },
    {
      "epoch": 1.7186629526462396,
      "grad_norm": 1.5299077033996582,
      "learning_rate": 0.0008281615598885794,
      "loss": 2.3678,
      "step": 6170
    },
    {
      "epoch": 1.7214484679665738,
      "grad_norm": 1.3435090780258179,
      "learning_rate": 0.000827883008356546,
      "loss": 2.3959,
      "step": 6180
    },
    {
      "epoch": 1.724233983286908,
      "grad_norm": 1.240332007408142,
      "learning_rate": 0.0008276044568245126,
      "loss": 2.4142,
      "step": 6190
    },
    {
      "epoch": 1.7270194986072425,
      "grad_norm": 1.466760277748108,
      "learning_rate": 0.0008273259052924791,
      "loss": 2.6543,
      "step": 6200
    },
    {
      "epoch": 1.7298050139275767,
      "grad_norm": 3.769167184829712,
      "learning_rate": 0.0008270473537604457,
      "loss": 2.4302,
      "step": 6210
    },
    {
      "epoch": 1.732590529247911,
      "grad_norm": 1.3401732444763184,
      "learning_rate": 0.0008267688022284122,
      "loss": 2.2791,
      "step": 6220
    },
    {
      "epoch": 1.7353760445682451,
      "grad_norm": 1.4258317947387695,
      "learning_rate": 0.0008264902506963788,
      "loss": 2.4749,
      "step": 6230
    },
    {
      "epoch": 1.7381615598885793,
      "grad_norm": 1.5848344564437866,
      "learning_rate": 0.0008262116991643454,
      "loss": 2.5406,
      "step": 6240
    },
    {
      "epoch": 1.7409470752089136,
      "grad_norm": 1.2846511602401733,
      "learning_rate": 0.000825933147632312,
      "loss": 2.4889,
      "step": 6250
    },
    {
      "epoch": 1.7437325905292478,
      "grad_norm": 1.3900681734085083,
      "learning_rate": 0.0008256545961002786,
      "loss": 2.5036,
      "step": 6260
    },
    {
      "epoch": 1.7465181058495822,
      "grad_norm": 1.317147135734558,
      "learning_rate": 0.0008253760445682451,
      "loss": 2.3661,
      "step": 6270
    },
    {
      "epoch": 1.7493036211699164,
      "grad_norm": 1.7741236686706543,
      "learning_rate": 0.0008250974930362117,
      "loss": 2.3272,
      "step": 6280
    },
    {
      "epoch": 1.7520891364902507,
      "grad_norm": 1.3510454893112183,
      "learning_rate": 0.0008248189415041783,
      "loss": 2.2795,
      "step": 6290
    },
    {
      "epoch": 1.754874651810585,
      "grad_norm": 1.2753394842147827,
      "learning_rate": 0.0008245403899721449,
      "loss": 2.4931,
      "step": 6300
    },
    {
      "epoch": 1.7576601671309193,
      "grad_norm": 1.9052752256393433,
      "learning_rate": 0.0008242618384401115,
      "loss": 2.2879,
      "step": 6310
    },
    {
      "epoch": 1.7604456824512535,
      "grad_norm": 1.6165374517440796,
      "learning_rate": 0.000823983286908078,
      "loss": 2.5197,
      "step": 6320
    },
    {
      "epoch": 1.7632311977715878,
      "grad_norm": 1.2844661474227905,
      "learning_rate": 0.0008237047353760446,
      "loss": 2.2696,
      "step": 6330
    },
    {
      "epoch": 1.766016713091922,
      "grad_norm": 1.3863577842712402,
      "learning_rate": 0.0008234261838440111,
      "loss": 2.5315,
      "step": 6340
    },
    {
      "epoch": 1.7688022284122562,
      "grad_norm": 1.3799529075622559,
      "learning_rate": 0.0008231476323119777,
      "loss": 2.3653,
      "step": 6350
    },
    {
      "epoch": 1.7715877437325904,
      "grad_norm": 1.0960042476654053,
      "learning_rate": 0.0008228690807799443,
      "loss": 2.4842,
      "step": 6360
    },
    {
      "epoch": 1.7743732590529246,
      "grad_norm": 1.3078745603561401,
      "learning_rate": 0.0008225905292479109,
      "loss": 2.3265,
      "step": 6370
    },
    {
      "epoch": 1.777158774373259,
      "grad_norm": 1.4684354066848755,
      "learning_rate": 0.0008223119777158774,
      "loss": 2.3594,
      "step": 6380
    },
    {
      "epoch": 1.7799442896935933,
      "grad_norm": 1.3670852184295654,
      "learning_rate": 0.000822033426183844,
      "loss": 2.5076,
      "step": 6390
    },
    {
      "epoch": 1.7827298050139275,
      "grad_norm": 1.1271620988845825,
      "learning_rate": 0.0008217548746518107,
      "loss": 2.3308,
      "step": 6400
    },
    {
      "epoch": 1.785515320334262,
      "grad_norm": 1.4619067907333374,
      "learning_rate": 0.0008214763231197772,
      "loss": 2.4362,
      "step": 6410
    },
    {
      "epoch": 1.7883008356545962,
      "grad_norm": 1.095137596130371,
      "learning_rate": 0.0008211977715877437,
      "loss": 2.3999,
      "step": 6420
    },
    {
      "epoch": 1.7910863509749304,
      "grad_norm": 1.1994507312774658,
      "learning_rate": 0.0008209192200557103,
      "loss": 2.4043,
      "step": 6430
    },
    {
      "epoch": 1.7938718662952646,
      "grad_norm": 1.6124271154403687,
      "learning_rate": 0.0008206406685236769,
      "loss": 2.4663,
      "step": 6440
    },
    {
      "epoch": 1.7966573816155988,
      "grad_norm": 1.3351354598999023,
      "learning_rate": 0.0008203621169916434,
      "loss": 2.3531,
      "step": 6450
    },
    {
      "epoch": 1.799442896935933,
      "grad_norm": 1.8354355096817017,
      "learning_rate": 0.00082008356545961,
      "loss": 2.3234,
      "step": 6460
    },
    {
      "epoch": 1.8022284122562673,
      "grad_norm": 0.8783612251281738,
      "learning_rate": 0.0008198050139275767,
      "loss": 2.3308,
      "step": 6470
    },
    {
      "epoch": 1.8050139275766015,
      "grad_norm": 1.9236317873001099,
      "learning_rate": 0.0008195264623955432,
      "loss": 2.5139,
      "step": 6480
    },
    {
      "epoch": 1.807799442896936,
      "grad_norm": 0.9463639855384827,
      "learning_rate": 0.0008192479108635098,
      "loss": 2.4948,
      "step": 6490
    },
    {
      "epoch": 1.8105849582172702,
      "grad_norm": 1.4316291809082031,
      "learning_rate": 0.0008189693593314764,
      "loss": 2.4513,
      "step": 6500
    },
    {
      "epoch": 1.8133704735376046,
      "grad_norm": 1.3555768728256226,
      "learning_rate": 0.000818690807799443,
      "loss": 2.4301,
      "step": 6510
    },
    {
      "epoch": 1.8161559888579388,
      "grad_norm": 1.8113563060760498,
      "learning_rate": 0.0008184122562674094,
      "loss": 2.2581,
      "step": 6520
    },
    {
      "epoch": 1.818941504178273,
      "grad_norm": 1.6019859313964844,
      "learning_rate": 0.000818133704735376,
      "loss": 2.5592,
      "step": 6530
    },
    {
      "epoch": 1.8217270194986073,
      "grad_norm": 1.4551405906677246,
      "learning_rate": 0.0008178551532033426,
      "loss": 2.4838,
      "step": 6540
    },
    {
      "epoch": 1.8245125348189415,
      "grad_norm": 1.1586564779281616,
      "learning_rate": 0.0008175766016713092,
      "loss": 2.2018,
      "step": 6550
    },
    {
      "epoch": 1.8272980501392757,
      "grad_norm": 1.094881296157837,
      "learning_rate": 0.0008172980501392758,
      "loss": 2.3093,
      "step": 6560
    },
    {
      "epoch": 1.83008356545961,
      "grad_norm": 1.619089961051941,
      "learning_rate": 0.0008170194986072423,
      "loss": 2.3631,
      "step": 6570
    },
    {
      "epoch": 1.8328690807799441,
      "grad_norm": 1.396796703338623,
      "learning_rate": 0.000816740947075209,
      "loss": 2.4252,
      "step": 6580
    },
    {
      "epoch": 1.8356545961002786,
      "grad_norm": 1.5675032138824463,
      "learning_rate": 0.0008164623955431755,
      "loss": 2.5262,
      "step": 6590
    },
    {
      "epoch": 1.8384401114206128,
      "grad_norm": 1.427345871925354,
      "learning_rate": 0.0008161838440111421,
      "loss": 2.4402,
      "step": 6600
    },
    {
      "epoch": 1.841225626740947,
      "grad_norm": 1.174105167388916,
      "learning_rate": 0.0008159052924791087,
      "loss": 2.2528,
      "step": 6610
    },
    {
      "epoch": 1.8440111420612815,
      "grad_norm": 1.3738512992858887,
      "learning_rate": 0.0008156267409470752,
      "loss": 2.48,
      "step": 6620
    },
    {
      "epoch": 1.8467966573816157,
      "grad_norm": 1.260046362876892,
      "learning_rate": 0.0008153481894150418,
      "loss": 2.3723,
      "step": 6630
    },
    {
      "epoch": 1.84958217270195,
      "grad_norm": 1.9405947923660278,
      "learning_rate": 0.0008150696378830083,
      "loss": 2.3436,
      "step": 6640
    },
    {
      "epoch": 1.8523676880222841,
      "grad_norm": 1.228348731994629,
      "learning_rate": 0.000814791086350975,
      "loss": 2.4296,
      "step": 6650
    },
    {
      "epoch": 1.8551532033426184,
      "grad_norm": 1.2375986576080322,
      "learning_rate": 0.0008145125348189415,
      "loss": 2.485,
      "step": 6660
    },
    {
      "epoch": 1.8579387186629526,
      "grad_norm": 1.0994915962219238,
      "learning_rate": 0.0008142339832869081,
      "loss": 2.2898,
      "step": 6670
    },
    {
      "epoch": 1.8607242339832868,
      "grad_norm": 1.6460318565368652,
      "learning_rate": 0.0008139554317548746,
      "loss": 2.4856,
      "step": 6680
    },
    {
      "epoch": 1.863509749303621,
      "grad_norm": 1.6726387739181519,
      "learning_rate": 0.0008136768802228413,
      "loss": 2.3451,
      "step": 6690
    },
    {
      "epoch": 1.8662952646239555,
      "grad_norm": 1.2864811420440674,
      "learning_rate": 0.0008133983286908078,
      "loss": 2.2958,
      "step": 6700
    },
    {
      "epoch": 1.8690807799442897,
      "grad_norm": 1.158359169960022,
      "learning_rate": 0.0008131197771587744,
      "loss": 2.3702,
      "step": 6710
    },
    {
      "epoch": 1.8718662952646241,
      "grad_norm": 1.398132562637329,
      "learning_rate": 0.000812841225626741,
      "loss": 2.5205,
      "step": 6720
    },
    {
      "epoch": 1.8746518105849583,
      "grad_norm": 1.5372495651245117,
      "learning_rate": 0.0008125626740947075,
      "loss": 2.2513,
      "step": 6730
    },
    {
      "epoch": 1.8774373259052926,
      "grad_norm": 1.239255666732788,
      "learning_rate": 0.0008122841225626741,
      "loss": 2.306,
      "step": 6740
    },
    {
      "epoch": 1.8802228412256268,
      "grad_norm": 1.453840732574463,
      "learning_rate": 0.0008120055710306406,
      "loss": 2.3127,
      "step": 6750
    },
    {
      "epoch": 1.883008356545961,
      "grad_norm": 1.742677927017212,
      "learning_rate": 0.0008117270194986073,
      "loss": 2.5083,
      "step": 6760
    },
    {
      "epoch": 1.8857938718662952,
      "grad_norm": 1.563870906829834,
      "learning_rate": 0.0008114484679665738,
      "loss": 2.3195,
      "step": 6770
    },
    {
      "epoch": 1.8885793871866294,
      "grad_norm": 1.786298155784607,
      "learning_rate": 0.0008111699164345404,
      "loss": 2.4914,
      "step": 6780
    },
    {
      "epoch": 1.8913649025069637,
      "grad_norm": 1.856904149055481,
      "learning_rate": 0.0008108913649025071,
      "loss": 2.3423,
      "step": 6790
    },
    {
      "epoch": 1.894150417827298,
      "grad_norm": 1.3077996969223022,
      "learning_rate": 0.0008106128133704736,
      "loss": 2.381,
      "step": 6800
    },
    {
      "epoch": 1.8969359331476323,
      "grad_norm": 1.6071877479553223,
      "learning_rate": 0.0008103342618384402,
      "loss": 2.3707,
      "step": 6810
    },
    {
      "epoch": 1.8997214484679665,
      "grad_norm": 1.6998291015625,
      "learning_rate": 0.0008100557103064066,
      "loss": 2.3371,
      "step": 6820
    },
    {
      "epoch": 1.902506963788301,
      "grad_norm": 1.3886394500732422,
      "learning_rate": 0.0008097771587743733,
      "loss": 2.325,
      "step": 6830
    },
    {
      "epoch": 1.9052924791086352,
      "grad_norm": 1.2896050214767456,
      "learning_rate": 0.0008094986072423398,
      "loss": 2.5946,
      "step": 6840
    },
    {
      "epoch": 1.9080779944289694,
      "grad_norm": 1.282377004623413,
      "learning_rate": 0.0008092200557103064,
      "loss": 2.4245,
      "step": 6850
    },
    {
      "epoch": 1.9108635097493036,
      "grad_norm": 1.4862234592437744,
      "learning_rate": 0.0008089415041782729,
      "loss": 2.4175,
      "step": 6860
    },
    {
      "epoch": 1.9136490250696379,
      "grad_norm": 1.705293893814087,
      "learning_rate": 0.0008086629526462396,
      "loss": 2.4492,
      "step": 6870
    },
    {
      "epoch": 1.916434540389972,
      "grad_norm": 1.564586877822876,
      "learning_rate": 0.0008083844011142062,
      "loss": 2.4524,
      "step": 6880
    },
    {
      "epoch": 1.9192200557103063,
      "grad_norm": 1.742055058479309,
      "learning_rate": 0.0008081058495821727,
      "loss": 2.2601,
      "step": 6890
    },
    {
      "epoch": 1.9220055710306405,
      "grad_norm": 1.3718092441558838,
      "learning_rate": 0.0008078272980501394,
      "loss": 2.3363,
      "step": 6900
    },
    {
      "epoch": 1.924791086350975,
      "grad_norm": 2.9504823684692383,
      "learning_rate": 0.0008075487465181059,
      "loss": 2.3778,
      "step": 6910
    },
    {
      "epoch": 1.9275766016713092,
      "grad_norm": 1.5638364553451538,
      "learning_rate": 0.0008072701949860724,
      "loss": 2.2609,
      "step": 6920
    },
    {
      "epoch": 1.9303621169916436,
      "grad_norm": 1.2623132467269897,
      "learning_rate": 0.0008069916434540389,
      "loss": 2.4639,
      "step": 6930
    },
    {
      "epoch": 1.9331476323119778,
      "grad_norm": 1.2557053565979004,
      "learning_rate": 0.0008067130919220056,
      "loss": 2.3805,
      "step": 6940
    },
    {
      "epoch": 1.935933147632312,
      "grad_norm": 1.3918931484222412,
      "learning_rate": 0.0008064345403899722,
      "loss": 2.4788,
      "step": 6950
    },
    {
      "epoch": 1.9387186629526463,
      "grad_norm": 1.3058959245681763,
      "learning_rate": 0.0008061559888579387,
      "loss": 2.3741,
      "step": 6960
    },
    {
      "epoch": 1.9415041782729805,
      "grad_norm": 1.588460087776184,
      "learning_rate": 0.0008058774373259054,
      "loss": 2.5464,
      "step": 6970
    },
    {
      "epoch": 1.9442896935933147,
      "grad_norm": 1.1558775901794434,
      "learning_rate": 0.0008055988857938719,
      "loss": 2.4036,
      "step": 6980
    },
    {
      "epoch": 1.947075208913649,
      "grad_norm": 1.438850998878479,
      "learning_rate": 0.0008053203342618385,
      "loss": 2.4994,
      "step": 6990
    },
    {
      "epoch": 1.9498607242339832,
      "grad_norm": 1.253549337387085,
      "learning_rate": 0.000805041782729805,
      "loss": 2.4123,
      "step": 7000
    },
    {
      "epoch": 1.9526462395543176,
      "grad_norm": 1.2849812507629395,
      "learning_rate": 0.0008047632311977717,
      "loss": 2.5346,
      "step": 7010
    },
    {
      "epoch": 1.9554317548746518,
      "grad_norm": 1.3534023761749268,
      "learning_rate": 0.0008044846796657381,
      "loss": 2.37,
      "step": 7020
    },
    {
      "epoch": 1.958217270194986,
      "grad_norm": 1.6432652473449707,
      "learning_rate": 0.0008042061281337047,
      "loss": 2.231,
      "step": 7030
    },
    {
      "epoch": 1.9610027855153205,
      "grad_norm": 1.2143882513046265,
      "learning_rate": 0.0008039275766016713,
      "loss": 2.4258,
      "step": 7040
    },
    {
      "epoch": 1.9637883008356547,
      "grad_norm": 1.1166949272155762,
      "learning_rate": 0.0008036490250696379,
      "loss": 2.5308,
      "step": 7050
    },
    {
      "epoch": 1.966573816155989,
      "grad_norm": 1.7945033311843872,
      "learning_rate": 0.0008033704735376045,
      "loss": 2.4217,
      "step": 7060
    },
    {
      "epoch": 1.9693593314763231,
      "grad_norm": 1.1977458000183105,
      "learning_rate": 0.000803091922005571,
      "loss": 2.4774,
      "step": 7070
    },
    {
      "epoch": 1.9721448467966574,
      "grad_norm": 1.7178343534469604,
      "learning_rate": 0.0008028133704735377,
      "loss": 2.4478,
      "step": 7080
    },
    {
      "epoch": 1.9749303621169916,
      "grad_norm": 1.3880826234817505,
      "learning_rate": 0.0008025348189415042,
      "loss": 2.359,
      "step": 7090
    },
    {
      "epoch": 1.9777158774373258,
      "grad_norm": 1.7445032596588135,
      "learning_rate": 0.0008022562674094708,
      "loss": 2.2314,
      "step": 7100
    },
    {
      "epoch": 1.98050139275766,
      "grad_norm": 1.630293846130371,
      "learning_rate": 0.0008019777158774373,
      "loss": 2.4,
      "step": 7110
    },
    {
      "epoch": 1.9832869080779945,
      "grad_norm": 1.4134390354156494,
      "learning_rate": 0.0008016991643454039,
      "loss": 2.4731,
      "step": 7120
    },
    {
      "epoch": 1.9860724233983287,
      "grad_norm": 1.3871678113937378,
      "learning_rate": 0.0008014206128133705,
      "loss": 2.5525,
      "step": 7130
    },
    {
      "epoch": 1.988857938718663,
      "grad_norm": 1.3510398864746094,
      "learning_rate": 0.000801142061281337,
      "loss": 2.671,
      "step": 7140
    },
    {
      "epoch": 1.9916434540389973,
      "grad_norm": 2.066843271255493,
      "learning_rate": 0.0008008635097493037,
      "loss": 2.5491,
      "step": 7150
    },
    {
      "epoch": 1.9944289693593316,
      "grad_norm": 1.6416343450546265,
      "learning_rate": 0.0008005849582172702,
      "loss": 2.4984,
      "step": 7160
    },
    {
      "epoch": 1.9972144846796658,
      "grad_norm": 1.50349760055542,
      "learning_rate": 0.0008003064066852368,
      "loss": 2.3535,
      "step": 7170
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.689961314201355,
      "learning_rate": 0.0008000278551532033,
      "loss": 2.4883,
      "step": 7180
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.356095314025879,
      "eval_runtime": 5.7728,
      "eval_samples_per_second": 552.934,
      "eval_steps_per_second": 69.117,
      "step": 7180
    },
    {
      "epoch": 2.002785515320334,
      "grad_norm": 1.3793178796768188,
      "learning_rate": 0.00079974930362117,
      "loss": 2.6602,
      "step": 7190
    },
    {
      "epoch": 2.0055710306406684,
      "grad_norm": 1.1510647535324097,
      "learning_rate": 0.0007994707520891366,
      "loss": 2.2967,
      "step": 7200
    },
    {
      "epoch": 2.0083565459610027,
      "grad_norm": 1.4528188705444336,
      "learning_rate": 0.000799192200557103,
      "loss": 2.2547,
      "step": 7210
    },
    {
      "epoch": 2.011142061281337,
      "grad_norm": 2.173064708709717,
      "learning_rate": 0.0007989136490250696,
      "loss": 2.3586,
      "step": 7220
    },
    {
      "epoch": 2.013927576601671,
      "grad_norm": 1.2183516025543213,
      "learning_rate": 0.0007986350974930362,
      "loss": 2.3783,
      "step": 7230
    },
    {
      "epoch": 2.0167130919220058,
      "grad_norm": 1.4444009065628052,
      "learning_rate": 0.0007983565459610028,
      "loss": 2.3445,
      "step": 7240
    },
    {
      "epoch": 2.01949860724234,
      "grad_norm": 1.5153805017471313,
      "learning_rate": 0.0007980779944289693,
      "loss": 2.521,
      "step": 7250
    },
    {
      "epoch": 2.022284122562674,
      "grad_norm": 1.600487470626831,
      "learning_rate": 0.000797799442896936,
      "loss": 2.7149,
      "step": 7260
    },
    {
      "epoch": 2.0250696378830084,
      "grad_norm": 1.5241098403930664,
      "learning_rate": 0.0007975208913649026,
      "loss": 2.4539,
      "step": 7270
    },
    {
      "epoch": 2.0278551532033426,
      "grad_norm": 1.3366420269012451,
      "learning_rate": 0.0007972423398328691,
      "loss": 2.3003,
      "step": 7280
    },
    {
      "epoch": 2.030640668523677,
      "grad_norm": 1.7221125364303589,
      "learning_rate": 0.0007969637883008357,
      "loss": 2.3157,
      "step": 7290
    },
    {
      "epoch": 2.033426183844011,
      "grad_norm": 2.60722017288208,
      "learning_rate": 0.0007966852367688023,
      "loss": 2.3295,
      "step": 7300
    },
    {
      "epoch": 2.0362116991643453,
      "grad_norm": 1.5543239116668701,
      "learning_rate": 0.0007964066852367688,
      "loss": 2.3506,
      "step": 7310
    },
    {
      "epoch": 2.0389972144846795,
      "grad_norm": 1.3007012605667114,
      "learning_rate": 0.0007961281337047353,
      "loss": 2.1479,
      "step": 7320
    },
    {
      "epoch": 2.0417827298050137,
      "grad_norm": 1.315839171409607,
      "learning_rate": 0.000795849582172702,
      "loss": 2.3968,
      "step": 7330
    },
    {
      "epoch": 2.0445682451253484,
      "grad_norm": 1.063215970993042,
      "learning_rate": 0.0007955710306406685,
      "loss": 2.31,
      "step": 7340
    },
    {
      "epoch": 2.0473537604456826,
      "grad_norm": 1.4033770561218262,
      "learning_rate": 0.0007952924791086351,
      "loss": 2.4664,
      "step": 7350
    },
    {
      "epoch": 2.050139275766017,
      "grad_norm": 2.025193929672241,
      "learning_rate": 0.0007950139275766017,
      "loss": 2.3436,
      "step": 7360
    },
    {
      "epoch": 2.052924791086351,
      "grad_norm": 1.1773039102554321,
      "learning_rate": 0.0007947353760445683,
      "loss": 2.2739,
      "step": 7370
    },
    {
      "epoch": 2.0557103064066853,
      "grad_norm": 2.040565013885498,
      "learning_rate": 0.0007944568245125349,
      "loss": 2.4466,
      "step": 7380
    },
    {
      "epoch": 2.0584958217270195,
      "grad_norm": 2.174027919769287,
      "learning_rate": 0.0007941782729805014,
      "loss": 2.4705,
      "step": 7390
    },
    {
      "epoch": 2.0612813370473537,
      "grad_norm": 1.6786584854125977,
      "learning_rate": 0.000793899721448468,
      "loss": 2.5039,
      "step": 7400
    },
    {
      "epoch": 2.064066852367688,
      "grad_norm": 1.4325050115585327,
      "learning_rate": 0.0007936211699164345,
      "loss": 2.2407,
      "step": 7410
    },
    {
      "epoch": 2.066852367688022,
      "grad_norm": 1.2426438331604004,
      "learning_rate": 0.0007933426183844011,
      "loss": 2.2403,
      "step": 7420
    },
    {
      "epoch": 2.0696378830083564,
      "grad_norm": 1.4592970609664917,
      "learning_rate": 0.0007930640668523676,
      "loss": 2.4394,
      "step": 7430
    },
    {
      "epoch": 2.0724233983286906,
      "grad_norm": 2.2457756996154785,
      "learning_rate": 0.0007927855153203343,
      "loss": 2.2899,
      "step": 7440
    },
    {
      "epoch": 2.0752089136490253,
      "grad_norm": 1.8023048639297485,
      "learning_rate": 0.0007925069637883009,
      "loss": 2.4203,
      "step": 7450
    },
    {
      "epoch": 2.0779944289693595,
      "grad_norm": 1.2521294355392456,
      "learning_rate": 0.0007922284122562674,
      "loss": 2.3121,
      "step": 7460
    },
    {
      "epoch": 2.0807799442896937,
      "grad_norm": 1.755453109741211,
      "learning_rate": 0.000791949860724234,
      "loss": 2.4003,
      "step": 7470
    },
    {
      "epoch": 2.083565459610028,
      "grad_norm": 1.4372684955596924,
      "learning_rate": 0.0007916713091922006,
      "loss": 2.5087,
      "step": 7480
    },
    {
      "epoch": 2.086350974930362,
      "grad_norm": 1.170839548110962,
      "learning_rate": 0.0007913927576601672,
      "loss": 2.3172,
      "step": 7490
    },
    {
      "epoch": 2.0891364902506964,
      "grad_norm": 1.3947033882141113,
      "learning_rate": 0.0007911142061281336,
      "loss": 2.3193,
      "step": 7500
    }
  ],
  "logging_steps": 10,
  "max_steps": 35900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 993401550471168.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
