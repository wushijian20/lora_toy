{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13333333333333333,
      "grad_norm": NaN,
      "learning_rate": 0.000988,
      "loss": 5.0663,
      "step": 10
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 2.6001055240631104,
      "learning_rate": 0.0009746666666666666,
      "loss": 3.8665,
      "step": 20
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.5163378715515137,
      "learning_rate": 0.0009613333333333334,
      "loss": 3.3093,
      "step": 30
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 3.3222525119781494,
      "learning_rate": 0.000948,
      "loss": 2.5856,
      "step": 40
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 3.760601043701172,
      "learning_rate": 0.0009346666666666667,
      "loss": 2.0822,
      "step": 50
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.8562357425689697,
      "learning_rate": 0.0009213333333333334,
      "loss": 1.7398,
      "step": 60
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 11.800386428833008,
      "learning_rate": 0.0009080000000000001,
      "loss": 1.7701,
      "step": 70
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.23167085647583,
      "eval_runtime": 0.1224,
      "eval_samples_per_second": 539.368,
      "eval_steps_per_second": 73.55,
      "step": 75
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 1.9540960788726807,
      "learning_rate": 0.0008946666666666668,
      "loss": 1.1022,
      "step": 80
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.1557161808013916,
      "learning_rate": 0.0008813333333333334,
      "loss": 1.4413,
      "step": 90
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 2.092249870300293,
      "learning_rate": 0.0008680000000000001,
      "loss": 1.3243,
      "step": 100
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": NaN,
      "learning_rate": 0.0008546666666666667,
      "loss": 1.3652,
      "step": 110
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.4012067317962646,
      "learning_rate": 0.0008413333333333334,
      "loss": 1.1344,
      "step": 120
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 2.2531325817108154,
      "learning_rate": 0.000828,
      "loss": 1.3115,
      "step": 130
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 2.8297348022460938,
      "learning_rate": 0.0008146666666666667,
      "loss": 0.9962,
      "step": 140
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.0447959899902344,
      "learning_rate": 0.0008013333333333334,
      "loss": 1.0679,
      "step": 150
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.643385112285614,
      "eval_runtime": 0.1226,
      "eval_samples_per_second": 538.282,
      "eval_steps_per_second": 73.402,
      "step": 150
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 1.7622408866882324,
      "learning_rate": 0.0007880000000000001,
      "loss": 1.0865,
      "step": 160
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 2.110036849975586,
      "learning_rate": 0.0007746666666666667,
      "loss": 0.9317,
      "step": 170
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.449591875076294,
      "learning_rate": 0.0007613333333333334,
      "loss": 1.0595,
      "step": 180
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 5.692132949829102,
      "learning_rate": 0.000748,
      "loss": 0.9342,
      "step": 190
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 1.8603492975234985,
      "learning_rate": 0.0007346666666666667,
      "loss": 0.8692,
      "step": 200
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.0506072044372559,
      "learning_rate": 0.0007213333333333334,
      "loss": 0.8615,
      "step": 210
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 2.2011232376098633,
      "learning_rate": 0.000708,
      "loss": 0.6784,
      "step": 220
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.4291241466999054,
      "eval_runtime": 0.1245,
      "eval_samples_per_second": 530.258,
      "eval_steps_per_second": 72.308,
      "step": 225
    },
    {
      "epoch": 3.066666666666667,
      "grad_norm": 2.189128875732422,
      "learning_rate": 0.0006946666666666667,
      "loss": 0.8682,
      "step": 230
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.338993787765503,
      "learning_rate": 0.0006813333333333334,
      "loss": 0.9397,
      "step": 240
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.8359073996543884,
      "learning_rate": 0.0006680000000000001,
      "loss": 0.9079,
      "step": 250
    },
    {
      "epoch": 3.466666666666667,
      "grad_norm": 2.81058931350708,
      "learning_rate": 0.0006546666666666667,
      "loss": 0.8478,
      "step": 260
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.7080042362213135,
      "learning_rate": 0.0006413333333333333,
      "loss": 0.7241,
      "step": 270
    },
    {
      "epoch": 3.7333333333333334,
      "grad_norm": 1.968697190284729,
      "learning_rate": 0.000628,
      "loss": 0.721,
      "step": 280
    },
    {
      "epoch": 3.8666666666666667,
      "grad_norm": 1.4425300359725952,
      "learning_rate": 0.0006146666666666667,
      "loss": 0.8878,
      "step": 290
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.745769739151001,
      "learning_rate": 0.0006013333333333334,
      "loss": 0.6532,
      "step": 300
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.2608583867549896,
      "eval_runtime": 0.139,
      "eval_samples_per_second": 474.74,
      "eval_steps_per_second": 64.737,
      "step": 300
    },
    {
      "epoch": 4.133333333333334,
      "grad_norm": 1.4176664352416992,
      "learning_rate": 0.000588,
      "loss": 0.7997,
      "step": 310
    },
    {
      "epoch": 4.266666666666667,
      "grad_norm": 1.4873656034469604,
      "learning_rate": 0.0005746666666666667,
      "loss": 0.8991,
      "step": 320
    },
    {
      "epoch": 4.4,
      "grad_norm": 2.3828125,
      "learning_rate": 0.0005613333333333334,
      "loss": 0.6752,
      "step": 330
    },
    {
      "epoch": 4.533333333333333,
      "grad_norm": 1.7596418857574463,
      "learning_rate": 0.0005480000000000001,
      "loss": 0.8301,
      "step": 340
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 2.6061980724334717,
      "learning_rate": 0.0005346666666666667,
      "loss": 0.624,
      "step": 350
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.5533162355422974,
      "learning_rate": 0.0005213333333333333,
      "loss": 0.7148,
      "step": 360
    },
    {
      "epoch": 4.933333333333334,
      "grad_norm": 2.1372549533843994,
      "learning_rate": 0.000508,
      "loss": 0.6224,
      "step": 370
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.1930265575647354,
      "eval_runtime": 0.1409,
      "eval_samples_per_second": 468.449,
      "eval_steps_per_second": 63.879,
      "step": 375
    },
    {
      "epoch": 5.066666666666666,
      "grad_norm": 0.8676461577415466,
      "learning_rate": 0.0004946666666666667,
      "loss": 0.8121,
      "step": 380
    },
    {
      "epoch": 5.2,
      "grad_norm": 2.326633930206299,
      "learning_rate": 0.00048133333333333334,
      "loss": 0.5114,
      "step": 390
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 1.9298574924468994,
      "learning_rate": 0.00046800000000000005,
      "loss": 0.548,
      "step": 400
    },
    {
      "epoch": 5.466666666666667,
      "grad_norm": 1.5329718589782715,
      "learning_rate": 0.0004546666666666667,
      "loss": 0.6098,
      "step": 410
    },
    {
      "epoch": 5.6,
      "grad_norm": 2.4357964992523193,
      "learning_rate": 0.00044133333333333335,
      "loss": 0.6767,
      "step": 420
    },
    {
      "epoch": 5.733333333333333,
      "grad_norm": 3.763780355453491,
      "learning_rate": 0.000428,
      "loss": 0.7648,
      "step": 430
    },
    {
      "epoch": 5.866666666666667,
      "grad_norm": 31.1014404296875,
      "learning_rate": 0.0004146666666666667,
      "loss": 0.6556,
      "step": 440
    },
    {
      "epoch": 6.0,
      "grad_norm": 14.320038795471191,
      "learning_rate": 0.00040133333333333335,
      "loss": 0.7197,
      "step": 450
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.22346213459968567,
      "eval_runtime": 0.1149,
      "eval_samples_per_second": 574.275,
      "eval_steps_per_second": 78.31,
      "step": 450
    },
    {
      "epoch": 6.133333333333334,
      "grad_norm": 6.341766834259033,
      "learning_rate": 0.000388,
      "loss": 0.6459,
      "step": 460
    },
    {
      "epoch": 6.266666666666667,
      "grad_norm": 2.1758880615234375,
      "learning_rate": 0.00037466666666666665,
      "loss": 0.7733,
      "step": 470
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.6374659538269043,
      "learning_rate": 0.00036133333333333335,
      "loss": 0.5991,
      "step": 480
    },
    {
      "epoch": 6.533333333333333,
      "grad_norm": 1.6035242080688477,
      "learning_rate": 0.000348,
      "loss": 0.5108,
      "step": 490
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 2.3087282180786133,
      "learning_rate": 0.00033466666666666665,
      "loss": 0.7319,
      "step": 500
    },
    {
      "epoch": 6.8,
      "grad_norm": 5.643202304840088,
      "learning_rate": 0.00032133333333333336,
      "loss": 0.6703,
      "step": 510
    },
    {
      "epoch": 6.933333333333334,
      "grad_norm": 5.210247039794922,
      "learning_rate": 0.000308,
      "loss": 0.7522,
      "step": 520
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.21803438663482666,
      "eval_runtime": 0.1143,
      "eval_samples_per_second": 577.227,
      "eval_steps_per_second": 78.713,
      "step": 525
    },
    {
      "epoch": 7.066666666666666,
      "grad_norm": 1.3518036603927612,
      "learning_rate": 0.0002946666666666667,
      "loss": 0.5958,
      "step": 530
    },
    {
      "epoch": 7.2,
      "grad_norm": 14.335832595825195,
      "learning_rate": 0.0002813333333333333,
      "loss": 0.6864,
      "step": 540
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 1.8394221067428589,
      "learning_rate": 0.000268,
      "loss": 0.5584,
      "step": 550
    },
    {
      "epoch": 7.466666666666667,
      "grad_norm": 5.30362606048584,
      "learning_rate": 0.00025466666666666666,
      "loss": 0.5244,
      "step": 560
    },
    {
      "epoch": 7.6,
      "grad_norm": 3.0273537635803223,
      "learning_rate": 0.00024133333333333334,
      "loss": 0.4999,
      "step": 570
    },
    {
      "epoch": 7.733333333333333,
      "grad_norm": 5.110274314880371,
      "learning_rate": 0.000228,
      "loss": 0.5155,
      "step": 580
    },
    {
      "epoch": 7.866666666666667,
      "grad_norm": 1.127590537071228,
      "learning_rate": 0.0002146666666666667,
      "loss": 0.4523,
      "step": 590
    },
    {
      "epoch": 8.0,
      "grad_norm": 4.839197635650635,
      "learning_rate": 0.00020133333333333334,
      "loss": 0.5478,
      "step": 600
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.17985716462135315,
      "eval_runtime": 0.1139,
      "eval_samples_per_second": 579.611,
      "eval_steps_per_second": 79.038,
      "step": 600
    },
    {
      "epoch": 8.133333333333333,
      "grad_norm": 1.8797966241836548,
      "learning_rate": 0.00018800000000000002,
      "loss": 0.5534,
      "step": 610
    },
    {
      "epoch": 8.266666666666667,
      "grad_norm": 0.933584451675415,
      "learning_rate": 0.00017466666666666667,
      "loss": 0.4507,
      "step": 620
    },
    {
      "epoch": 8.4,
      "grad_norm": 2.843261957168579,
      "learning_rate": 0.00016133333333333334,
      "loss": 0.5237,
      "step": 630
    },
    {
      "epoch": 8.533333333333333,
      "grad_norm": 2.248290777206421,
      "learning_rate": 0.000148,
      "loss": 0.5504,
      "step": 640
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 4.2177276611328125,
      "learning_rate": 0.00013466666666666667,
      "loss": 0.537,
      "step": 650
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.8955833911895752,
      "learning_rate": 0.00012133333333333333,
      "loss": 0.4853,
      "step": 660
    },
    {
      "epoch": 8.933333333333334,
      "grad_norm": 1.9143426418304443,
      "learning_rate": 0.000108,
      "loss": 0.4428,
      "step": 670
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.1802527904510498,
      "eval_runtime": 0.1291,
      "eval_samples_per_second": 511.063,
      "eval_steps_per_second": 69.69,
      "step": 675
    },
    {
      "epoch": 9.066666666666666,
      "grad_norm": 4.406292915344238,
      "learning_rate": 9.466666666666666e-05,
      "loss": 0.5544,
      "step": 680
    },
    {
      "epoch": 9.2,
      "grad_norm": 1.2535990476608276,
      "learning_rate": 8.133333333333332e-05,
      "loss": 0.4059,
      "step": 690
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 1.9479879140853882,
      "learning_rate": 6.800000000000001e-05,
      "loss": 0.4065,
      "step": 700
    },
    {
      "epoch": 9.466666666666667,
      "grad_norm": 1.9660800695419312,
      "learning_rate": 5.466666666666667e-05,
      "loss": 0.4453,
      "step": 710
    },
    {
      "epoch": 9.6,
      "grad_norm": 2.2558224201202393,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.4871,
      "step": 720
    },
    {
      "epoch": 9.733333333333333,
      "grad_norm": 3.8824450969696045,
      "learning_rate": 2.8e-05,
      "loss": 0.4563,
      "step": 730
    },
    {
      "epoch": 9.866666666666667,
      "grad_norm": 1.1462457180023193,
      "learning_rate": 1.4666666666666666e-05,
      "loss": 0.4055,
      "step": 740
    },
    {
      "epoch": 10.0,
      "grad_norm": 4.621945858001709,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.3953,
      "step": 750
    }
  ],
  "logging_steps": 10,
  "max_steps": 750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 98350031831040.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
