{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.1392757660167131,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002785515320334262,
      "grad_norm": 1.2777702808380127,
      "learning_rate": 0.00099974930362117,
      "loss": 4.3969,
      "step": 10
    },
    {
      "epoch": 0.005571030640668524,
      "grad_norm": 1.7650771141052246,
      "learning_rate": 0.0009994707520891365,
      "loss": 3.4993,
      "step": 20
    },
    {
      "epoch": 0.008356545961002786,
      "grad_norm": 1.121536374092102,
      "learning_rate": 0.0009991922005571031,
      "loss": 3.182,
      "step": 30
    },
    {
      "epoch": 0.011142061281337047,
      "grad_norm": 1.5466363430023193,
      "learning_rate": 0.0009989136490250697,
      "loss": 3.4433,
      "step": 40
    },
    {
      "epoch": 0.013927576601671309,
      "grad_norm": 1.3392200469970703,
      "learning_rate": 0.0009986350974930363,
      "loss": 3.2526,
      "step": 50
    },
    {
      "epoch": 0.016713091922005572,
      "grad_norm": 1.4003591537475586,
      "learning_rate": 0.0009983565459610027,
      "loss": 2.9297,
      "step": 60
    },
    {
      "epoch": 0.019498607242339833,
      "grad_norm": 1.1948171854019165,
      "learning_rate": 0.0009980779944289695,
      "loss": 3.2728,
      "step": 70
    },
    {
      "epoch": 0.022284122562674095,
      "grad_norm": 1.0925664901733398,
      "learning_rate": 0.0009977994428969359,
      "loss": 2.9489,
      "step": 80
    },
    {
      "epoch": 0.025069637883008356,
      "grad_norm": 1.0867161750793457,
      "learning_rate": 0.0009975208913649025,
      "loss": 2.882,
      "step": 90
    },
    {
      "epoch": 0.027855153203342618,
      "grad_norm": 1.4580721855163574,
      "learning_rate": 0.000997242339832869,
      "loss": 2.7389,
      "step": 100
    },
    {
      "epoch": 0.03064066852367688,
      "grad_norm": 1.4019684791564941,
      "learning_rate": 0.0009969637883008356,
      "loss": 2.9995,
      "step": 110
    },
    {
      "epoch": 0.033426183844011144,
      "grad_norm": 1.0926460027694702,
      "learning_rate": 0.0009966852367688022,
      "loss": 3.1596,
      "step": 120
    },
    {
      "epoch": 0.036211699164345405,
      "grad_norm": 1.4548900127410889,
      "learning_rate": 0.0009964066852367688,
      "loss": 2.9555,
      "step": 130
    },
    {
      "epoch": 0.03899721448467967,
      "grad_norm": 1.5399762392044067,
      "learning_rate": 0.0009961281337047354,
      "loss": 3.1365,
      "step": 140
    },
    {
      "epoch": 0.04178272980501393,
      "grad_norm": 1.2968024015426636,
      "learning_rate": 0.000995849582172702,
      "loss": 2.8939,
      "step": 150
    },
    {
      "epoch": 0.04456824512534819,
      "grad_norm": 1.696082353591919,
      "learning_rate": 0.0009955710306406686,
      "loss": 2.7374,
      "step": 160
    },
    {
      "epoch": 0.04735376044568245,
      "grad_norm": 1.30885648727417,
      "learning_rate": 0.000995292479108635,
      "loss": 2.8485,
      "step": 170
    },
    {
      "epoch": 0.05013927576601671,
      "grad_norm": 1.320600152015686,
      "learning_rate": 0.0009950139275766018,
      "loss": 2.7569,
      "step": 180
    },
    {
      "epoch": 0.052924791086350974,
      "grad_norm": 1.1281540393829346,
      "learning_rate": 0.0009947353760445684,
      "loss": 3.1554,
      "step": 190
    },
    {
      "epoch": 0.055710306406685235,
      "grad_norm": 1.2007540464401245,
      "learning_rate": 0.0009944568245125348,
      "loss": 2.8286,
      "step": 200
    },
    {
      "epoch": 0.0584958217270195,
      "grad_norm": 1.0410748720169067,
      "learning_rate": 0.0009941782729805016,
      "loss": 3.0681,
      "step": 210
    },
    {
      "epoch": 0.06128133704735376,
      "grad_norm": 1.1308516263961792,
      "learning_rate": 0.000993899721448468,
      "loss": 2.823,
      "step": 220
    },
    {
      "epoch": 0.06406685236768803,
      "grad_norm": 1.7718303203582764,
      "learning_rate": 0.0009936211699164345,
      "loss": 2.9794,
      "step": 230
    },
    {
      "epoch": 0.06685236768802229,
      "grad_norm": 1.3107385635375977,
      "learning_rate": 0.0009933426183844011,
      "loss": 2.86,
      "step": 240
    },
    {
      "epoch": 0.06963788300835655,
      "grad_norm": 1.2536839246749878,
      "learning_rate": 0.0009930640668523677,
      "loss": 2.9039,
      "step": 250
    },
    {
      "epoch": 0.07242339832869081,
      "grad_norm": 1.420477032661438,
      "learning_rate": 0.0009927855153203343,
      "loss": 3.126,
      "step": 260
    },
    {
      "epoch": 0.07520891364902507,
      "grad_norm": 1.6711881160736084,
      "learning_rate": 0.0009925069637883009,
      "loss": 2.8972,
      "step": 270
    },
    {
      "epoch": 0.07799442896935933,
      "grad_norm": 1.694988489151001,
      "learning_rate": 0.0009922284122562675,
      "loss": 2.7816,
      "step": 280
    },
    {
      "epoch": 0.0807799442896936,
      "grad_norm": 1.0983426570892334,
      "learning_rate": 0.000991949860724234,
      "loss": 2.8463,
      "step": 290
    },
    {
      "epoch": 0.08356545961002786,
      "grad_norm": 1.1392773389816284,
      "learning_rate": 0.0009916713091922007,
      "loss": 2.9405,
      "step": 300
    },
    {
      "epoch": 0.08635097493036212,
      "grad_norm": 1.1083364486694336,
      "learning_rate": 0.000991392757660167,
      "loss": 2.9489,
      "step": 310
    },
    {
      "epoch": 0.08913649025069638,
      "grad_norm": 1.0049762725830078,
      "learning_rate": 0.0009911142061281338,
      "loss": 2.7545,
      "step": 320
    },
    {
      "epoch": 0.09192200557103064,
      "grad_norm": 1.4989159107208252,
      "learning_rate": 0.0009908356545961002,
      "loss": 2.827,
      "step": 330
    },
    {
      "epoch": 0.0947075208913649,
      "grad_norm": 1.4460601806640625,
      "learning_rate": 0.0009905571030640668,
      "loss": 2.922,
      "step": 340
    },
    {
      "epoch": 0.09749303621169916,
      "grad_norm": 1.2647724151611328,
      "learning_rate": 0.0009902785515320334,
      "loss": 2.6402,
      "step": 350
    },
    {
      "epoch": 0.10027855153203342,
      "grad_norm": 1.137195348739624,
      "learning_rate": 0.00099,
      "loss": 2.8358,
      "step": 360
    },
    {
      "epoch": 0.10306406685236769,
      "grad_norm": 1.1965945959091187,
      "learning_rate": 0.0009897214484679666,
      "loss": 2.871,
      "step": 370
    },
    {
      "epoch": 0.10584958217270195,
      "grad_norm": 1.1259201765060425,
      "learning_rate": 0.0009894428969359332,
      "loss": 2.8081,
      "step": 380
    },
    {
      "epoch": 0.10863509749303621,
      "grad_norm": 2.0894253253936768,
      "learning_rate": 0.0009891643454038998,
      "loss": 2.8969,
      "step": 390
    },
    {
      "epoch": 0.11142061281337047,
      "grad_norm": 1.2286434173583984,
      "learning_rate": 0.0009888857938718664,
      "loss": 2.8072,
      "step": 400
    },
    {
      "epoch": 0.11420612813370473,
      "grad_norm": 1.0757712125778198,
      "learning_rate": 0.000988607242339833,
      "loss": 2.7003,
      "step": 410
    },
    {
      "epoch": 0.116991643454039,
      "grad_norm": 1.7179458141326904,
      "learning_rate": 0.0009883286908077993,
      "loss": 2.7788,
      "step": 420
    },
    {
      "epoch": 0.11977715877437325,
      "grad_norm": 1.3726903200149536,
      "learning_rate": 0.0009880501392757661,
      "loss": 2.5696,
      "step": 430
    },
    {
      "epoch": 0.12256267409470752,
      "grad_norm": 1.14989173412323,
      "learning_rate": 0.0009877715877437327,
      "loss": 2.7331,
      "step": 440
    },
    {
      "epoch": 0.12534818941504178,
      "grad_norm": 1.2878109216690063,
      "learning_rate": 0.000987493036211699,
      "loss": 2.624,
      "step": 450
    },
    {
      "epoch": 0.12813370473537605,
      "grad_norm": 1.1452126502990723,
      "learning_rate": 0.0009872144846796657,
      "loss": 2.6156,
      "step": 460
    },
    {
      "epoch": 0.1309192200557103,
      "grad_norm": 1.4346585273742676,
      "learning_rate": 0.0009869359331476323,
      "loss": 2.6586,
      "step": 470
    },
    {
      "epoch": 0.13370473537604458,
      "grad_norm": 1.4669582843780518,
      "learning_rate": 0.0009866573816155989,
      "loss": 2.7476,
      "step": 480
    },
    {
      "epoch": 0.13649025069637882,
      "grad_norm": 1.610460638999939,
      "learning_rate": 0.0009863788300835655,
      "loss": 2.5211,
      "step": 490
    },
    {
      "epoch": 0.1392757660167131,
      "grad_norm": 1.2787543535232544,
      "learning_rate": 0.000986100278551532,
      "loss": 2.6962,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 35900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 66228977664000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
