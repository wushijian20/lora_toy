{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.4178272980501393,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002785515320334262,
      "grad_norm": 1.2777702808380127,
      "learning_rate": 0.00099974930362117,
      "loss": 4.3969,
      "step": 10
    },
    {
      "epoch": 0.005571030640668524,
      "grad_norm": 1.7650771141052246,
      "learning_rate": 0.0009994707520891365,
      "loss": 3.4993,
      "step": 20
    },
    {
      "epoch": 0.008356545961002786,
      "grad_norm": 1.121536374092102,
      "learning_rate": 0.0009991922005571031,
      "loss": 3.182,
      "step": 30
    },
    {
      "epoch": 0.011142061281337047,
      "grad_norm": 1.5466363430023193,
      "learning_rate": 0.0009989136490250697,
      "loss": 3.4433,
      "step": 40
    },
    {
      "epoch": 0.013927576601671309,
      "grad_norm": 1.3392200469970703,
      "learning_rate": 0.0009986350974930363,
      "loss": 3.2526,
      "step": 50
    },
    {
      "epoch": 0.016713091922005572,
      "grad_norm": 1.4003591537475586,
      "learning_rate": 0.0009983565459610027,
      "loss": 2.9297,
      "step": 60
    },
    {
      "epoch": 0.019498607242339833,
      "grad_norm": 1.1948171854019165,
      "learning_rate": 0.0009980779944289695,
      "loss": 3.2728,
      "step": 70
    },
    {
      "epoch": 0.022284122562674095,
      "grad_norm": 1.0925664901733398,
      "learning_rate": 0.0009977994428969359,
      "loss": 2.9489,
      "step": 80
    },
    {
      "epoch": 0.025069637883008356,
      "grad_norm": 1.0867161750793457,
      "learning_rate": 0.0009975208913649025,
      "loss": 2.882,
      "step": 90
    },
    {
      "epoch": 0.027855153203342618,
      "grad_norm": 1.4580721855163574,
      "learning_rate": 0.000997242339832869,
      "loss": 2.7389,
      "step": 100
    },
    {
      "epoch": 0.03064066852367688,
      "grad_norm": 1.4019684791564941,
      "learning_rate": 0.0009969637883008356,
      "loss": 2.9995,
      "step": 110
    },
    {
      "epoch": 0.033426183844011144,
      "grad_norm": 1.0926460027694702,
      "learning_rate": 0.0009966852367688022,
      "loss": 3.1596,
      "step": 120
    },
    {
      "epoch": 0.036211699164345405,
      "grad_norm": 1.4548900127410889,
      "learning_rate": 0.0009964066852367688,
      "loss": 2.9555,
      "step": 130
    },
    {
      "epoch": 0.03899721448467967,
      "grad_norm": 1.5399762392044067,
      "learning_rate": 0.0009961281337047354,
      "loss": 3.1365,
      "step": 140
    },
    {
      "epoch": 0.04178272980501393,
      "grad_norm": 1.2968024015426636,
      "learning_rate": 0.000995849582172702,
      "loss": 2.8939,
      "step": 150
    },
    {
      "epoch": 0.04456824512534819,
      "grad_norm": 1.696082353591919,
      "learning_rate": 0.0009955710306406686,
      "loss": 2.7374,
      "step": 160
    },
    {
      "epoch": 0.04735376044568245,
      "grad_norm": 1.30885648727417,
      "learning_rate": 0.000995292479108635,
      "loss": 2.8485,
      "step": 170
    },
    {
      "epoch": 0.05013927576601671,
      "grad_norm": 1.320600152015686,
      "learning_rate": 0.0009950139275766018,
      "loss": 2.7569,
      "step": 180
    },
    {
      "epoch": 0.052924791086350974,
      "grad_norm": 1.1281540393829346,
      "learning_rate": 0.0009947353760445684,
      "loss": 3.1554,
      "step": 190
    },
    {
      "epoch": 0.055710306406685235,
      "grad_norm": 1.2007540464401245,
      "learning_rate": 0.0009944568245125348,
      "loss": 2.8286,
      "step": 200
    },
    {
      "epoch": 0.0584958217270195,
      "grad_norm": 1.0410748720169067,
      "learning_rate": 0.0009941782729805016,
      "loss": 3.0681,
      "step": 210
    },
    {
      "epoch": 0.06128133704735376,
      "grad_norm": 1.1308516263961792,
      "learning_rate": 0.000993899721448468,
      "loss": 2.823,
      "step": 220
    },
    {
      "epoch": 0.06406685236768803,
      "grad_norm": 1.7718303203582764,
      "learning_rate": 0.0009936211699164345,
      "loss": 2.9794,
      "step": 230
    },
    {
      "epoch": 0.06685236768802229,
      "grad_norm": 1.3107385635375977,
      "learning_rate": 0.0009933426183844011,
      "loss": 2.86,
      "step": 240
    },
    {
      "epoch": 0.06963788300835655,
      "grad_norm": 1.2536839246749878,
      "learning_rate": 0.0009930640668523677,
      "loss": 2.9039,
      "step": 250
    },
    {
      "epoch": 0.07242339832869081,
      "grad_norm": 1.420477032661438,
      "learning_rate": 0.0009927855153203343,
      "loss": 3.126,
      "step": 260
    },
    {
      "epoch": 0.07520891364902507,
      "grad_norm": 1.6711881160736084,
      "learning_rate": 0.0009925069637883009,
      "loss": 2.8972,
      "step": 270
    },
    {
      "epoch": 0.07799442896935933,
      "grad_norm": 1.694988489151001,
      "learning_rate": 0.0009922284122562675,
      "loss": 2.7816,
      "step": 280
    },
    {
      "epoch": 0.0807799442896936,
      "grad_norm": 1.0983426570892334,
      "learning_rate": 0.000991949860724234,
      "loss": 2.8463,
      "step": 290
    },
    {
      "epoch": 0.08356545961002786,
      "grad_norm": 1.1392773389816284,
      "learning_rate": 0.0009916713091922007,
      "loss": 2.9405,
      "step": 300
    },
    {
      "epoch": 0.08635097493036212,
      "grad_norm": 1.1083364486694336,
      "learning_rate": 0.000991392757660167,
      "loss": 2.9489,
      "step": 310
    },
    {
      "epoch": 0.08913649025069638,
      "grad_norm": 1.0049762725830078,
      "learning_rate": 0.0009911142061281338,
      "loss": 2.7545,
      "step": 320
    },
    {
      "epoch": 0.09192200557103064,
      "grad_norm": 1.4989159107208252,
      "learning_rate": 0.0009908356545961002,
      "loss": 2.827,
      "step": 330
    },
    {
      "epoch": 0.0947075208913649,
      "grad_norm": 1.4460601806640625,
      "learning_rate": 0.0009905571030640668,
      "loss": 2.922,
      "step": 340
    },
    {
      "epoch": 0.09749303621169916,
      "grad_norm": 1.2647724151611328,
      "learning_rate": 0.0009902785515320334,
      "loss": 2.6402,
      "step": 350
    },
    {
      "epoch": 0.10027855153203342,
      "grad_norm": 1.137195348739624,
      "learning_rate": 0.00099,
      "loss": 2.8358,
      "step": 360
    },
    {
      "epoch": 0.10306406685236769,
      "grad_norm": 1.1965945959091187,
      "learning_rate": 0.0009897214484679666,
      "loss": 2.871,
      "step": 370
    },
    {
      "epoch": 0.10584958217270195,
      "grad_norm": 1.1259201765060425,
      "learning_rate": 0.0009894428969359332,
      "loss": 2.8081,
      "step": 380
    },
    {
      "epoch": 0.10863509749303621,
      "grad_norm": 2.0894253253936768,
      "learning_rate": 0.0009891643454038998,
      "loss": 2.8969,
      "step": 390
    },
    {
      "epoch": 0.11142061281337047,
      "grad_norm": 1.2286434173583984,
      "learning_rate": 0.0009888857938718664,
      "loss": 2.8072,
      "step": 400
    },
    {
      "epoch": 0.11420612813370473,
      "grad_norm": 1.0757712125778198,
      "learning_rate": 0.000988607242339833,
      "loss": 2.7003,
      "step": 410
    },
    {
      "epoch": 0.116991643454039,
      "grad_norm": 1.7179458141326904,
      "learning_rate": 0.0009883286908077993,
      "loss": 2.7788,
      "step": 420
    },
    {
      "epoch": 0.11977715877437325,
      "grad_norm": 1.3726903200149536,
      "learning_rate": 0.0009880501392757661,
      "loss": 2.5696,
      "step": 430
    },
    {
      "epoch": 0.12256267409470752,
      "grad_norm": 1.14989173412323,
      "learning_rate": 0.0009877715877437327,
      "loss": 2.7331,
      "step": 440
    },
    {
      "epoch": 0.12534818941504178,
      "grad_norm": 1.2878109216690063,
      "learning_rate": 0.000987493036211699,
      "loss": 2.624,
      "step": 450
    },
    {
      "epoch": 0.12813370473537605,
      "grad_norm": 1.1452126502990723,
      "learning_rate": 0.0009872144846796657,
      "loss": 2.6156,
      "step": 460
    },
    {
      "epoch": 0.1309192200557103,
      "grad_norm": 1.4346585273742676,
      "learning_rate": 0.0009869359331476323,
      "loss": 2.6586,
      "step": 470
    },
    {
      "epoch": 0.13370473537604458,
      "grad_norm": 1.4669582843780518,
      "learning_rate": 0.0009866573816155989,
      "loss": 2.7476,
      "step": 480
    },
    {
      "epoch": 0.13649025069637882,
      "grad_norm": 1.610460638999939,
      "learning_rate": 0.0009863788300835655,
      "loss": 2.5211,
      "step": 490
    },
    {
      "epoch": 0.1392757660167131,
      "grad_norm": 1.2787543535232544,
      "learning_rate": 0.000986100278551532,
      "loss": 2.6962,
      "step": 500
    },
    {
      "epoch": 0.14206128133704735,
      "grad_norm": 1.3625420331954956,
      "learning_rate": 0.0009858217270194986,
      "loss": 2.6626,
      "step": 510
    },
    {
      "epoch": 0.14484679665738162,
      "grad_norm": 1.6599339246749878,
      "learning_rate": 0.0009855431754874652,
      "loss": 2.9541,
      "step": 520
    },
    {
      "epoch": 0.14763231197771587,
      "grad_norm": 1.3805036544799805,
      "learning_rate": 0.0009852646239554318,
      "loss": 2.9058,
      "step": 530
    },
    {
      "epoch": 0.15041782729805014,
      "grad_norm": 1.1459840536117554,
      "learning_rate": 0.0009849860724233984,
      "loss": 2.4951,
      "step": 540
    },
    {
      "epoch": 0.1532033426183844,
      "grad_norm": 1.278351068496704,
      "learning_rate": 0.000984707520891365,
      "loss": 2.7882,
      "step": 550
    },
    {
      "epoch": 0.15598885793871867,
      "grad_norm": 1.062248945236206,
      "learning_rate": 0.0009844289693593314,
      "loss": 2.9183,
      "step": 560
    },
    {
      "epoch": 0.15877437325905291,
      "grad_norm": 1.8217440843582153,
      "learning_rate": 0.000984150417827298,
      "loss": 2.7318,
      "step": 570
    },
    {
      "epoch": 0.1615598885793872,
      "grad_norm": 1.2369275093078613,
      "learning_rate": 0.0009838718662952646,
      "loss": 2.7745,
      "step": 580
    },
    {
      "epoch": 0.16434540389972144,
      "grad_norm": 1.242400050163269,
      "learning_rate": 0.0009835933147632312,
      "loss": 2.7332,
      "step": 590
    },
    {
      "epoch": 0.1671309192200557,
      "grad_norm": 1.8199281692504883,
      "learning_rate": 0.0009833147632311977,
      "loss": 2.9746,
      "step": 600
    },
    {
      "epoch": 0.16991643454038996,
      "grad_norm": 1.4614086151123047,
      "learning_rate": 0.0009830362116991643,
      "loss": 2.6833,
      "step": 610
    },
    {
      "epoch": 0.17270194986072424,
      "grad_norm": 1.246872067451477,
      "learning_rate": 0.000982757660167131,
      "loss": 2.8365,
      "step": 620
    },
    {
      "epoch": 0.17548746518105848,
      "grad_norm": 1.0792508125305176,
      "learning_rate": 0.0009824791086350975,
      "loss": 2.795,
      "step": 630
    },
    {
      "epoch": 0.17827298050139276,
      "grad_norm": 1.401904821395874,
      "learning_rate": 0.0009822005571030641,
      "loss": 2.4939,
      "step": 640
    },
    {
      "epoch": 0.181058495821727,
      "grad_norm": 1.273613452911377,
      "learning_rate": 0.0009819220055710307,
      "loss": 2.7808,
      "step": 650
    },
    {
      "epoch": 0.18384401114206128,
      "grad_norm": 1.510461449623108,
      "learning_rate": 0.0009816434540389973,
      "loss": 2.606,
      "step": 660
    },
    {
      "epoch": 0.18662952646239556,
      "grad_norm": 1.4030647277832031,
      "learning_rate": 0.0009813649025069639,
      "loss": 2.7183,
      "step": 670
    },
    {
      "epoch": 0.1894150417827298,
      "grad_norm": 1.3902904987335205,
      "learning_rate": 0.0009810863509749305,
      "loss": 2.6436,
      "step": 680
    },
    {
      "epoch": 0.19220055710306408,
      "grad_norm": 1.282233715057373,
      "learning_rate": 0.000980807799442897,
      "loss": 2.7614,
      "step": 690
    },
    {
      "epoch": 0.19498607242339833,
      "grad_norm": 1.247700572013855,
      "learning_rate": 0.0009805292479108634,
      "loss": 2.7213,
      "step": 700
    },
    {
      "epoch": 0.1977715877437326,
      "grad_norm": 1.9423047304153442,
      "learning_rate": 0.00098025069637883,
      "loss": 2.6238,
      "step": 710
    },
    {
      "epoch": 0.20055710306406685,
      "grad_norm": 1.189522385597229,
      "learning_rate": 0.0009799721448467966,
      "loss": 2.7811,
      "step": 720
    },
    {
      "epoch": 0.20334261838440112,
      "grad_norm": 1.268925428390503,
      "learning_rate": 0.0009796935933147632,
      "loss": 2.5515,
      "step": 730
    },
    {
      "epoch": 0.20612813370473537,
      "grad_norm": 1.566765308380127,
      "learning_rate": 0.0009794150417827298,
      "loss": 2.8544,
      "step": 740
    },
    {
      "epoch": 0.20891364902506965,
      "grad_norm": 1.4222410917282104,
      "learning_rate": 0.0009791364902506964,
      "loss": 2.7452,
      "step": 750
    },
    {
      "epoch": 0.2116991643454039,
      "grad_norm": 1.7793817520141602,
      "learning_rate": 0.000978857938718663,
      "loss": 2.6258,
      "step": 760
    },
    {
      "epoch": 0.21448467966573817,
      "grad_norm": 1.2203317880630493,
      "learning_rate": 0.0009785793871866296,
      "loss": 2.6129,
      "step": 770
    },
    {
      "epoch": 0.21727019498607242,
      "grad_norm": 1.2296749353408813,
      "learning_rate": 0.0009783008356545962,
      "loss": 2.4147,
      "step": 780
    },
    {
      "epoch": 0.2200557103064067,
      "grad_norm": 2.012601137161255,
      "learning_rate": 0.0009780222841225628,
      "loss": 2.8097,
      "step": 790
    },
    {
      "epoch": 0.22284122562674094,
      "grad_norm": 1.5866401195526123,
      "learning_rate": 0.0009777437325905294,
      "loss": 2.7063,
      "step": 800
    },
    {
      "epoch": 0.22562674094707522,
      "grad_norm": 1.1381161212921143,
      "learning_rate": 0.0009774651810584957,
      "loss": 2.6254,
      "step": 810
    },
    {
      "epoch": 0.22841225626740946,
      "grad_norm": 1.323906660079956,
      "learning_rate": 0.0009771866295264623,
      "loss": 2.6625,
      "step": 820
    },
    {
      "epoch": 0.23119777158774374,
      "grad_norm": 1.2379060983657837,
      "learning_rate": 0.000976908077994429,
      "loss": 2.829,
      "step": 830
    },
    {
      "epoch": 0.233983286908078,
      "grad_norm": 0.9392759799957275,
      "learning_rate": 0.0009766295264623955,
      "loss": 2.5653,
      "step": 840
    },
    {
      "epoch": 0.23676880222841226,
      "grad_norm": 1.0966740846633911,
      "learning_rate": 0.0009763509749303622,
      "loss": 2.542,
      "step": 850
    },
    {
      "epoch": 0.2395543175487465,
      "grad_norm": 1.1827309131622314,
      "learning_rate": 0.0009760724233983287,
      "loss": 2.6657,
      "step": 860
    },
    {
      "epoch": 0.24233983286908078,
      "grad_norm": 2.1995315551757812,
      "learning_rate": 0.0009757938718662953,
      "loss": 2.5712,
      "step": 870
    },
    {
      "epoch": 0.24512534818941503,
      "grad_norm": 1.3757152557373047,
      "learning_rate": 0.0009755153203342619,
      "loss": 2.5045,
      "step": 880
    },
    {
      "epoch": 0.2479108635097493,
      "grad_norm": 1.300731897354126,
      "learning_rate": 0.0009752367688022285,
      "loss": 2.5062,
      "step": 890
    },
    {
      "epoch": 0.25069637883008355,
      "grad_norm": 1.7121989727020264,
      "learning_rate": 0.0009749582172701949,
      "loss": 2.5394,
      "step": 900
    },
    {
      "epoch": 0.25348189415041783,
      "grad_norm": 1.4732779264450073,
      "learning_rate": 0.0009746796657381615,
      "loss": 2.467,
      "step": 910
    },
    {
      "epoch": 0.2562674094707521,
      "grad_norm": 1.0222309827804565,
      "learning_rate": 0.0009744011142061282,
      "loss": 2.7814,
      "step": 920
    },
    {
      "epoch": 0.2590529247910863,
      "grad_norm": 1.4269797801971436,
      "learning_rate": 0.0009741225626740947,
      "loss": 2.7467,
      "step": 930
    },
    {
      "epoch": 0.2618384401114206,
      "grad_norm": 1.3660566806793213,
      "learning_rate": 0.0009738440111420613,
      "loss": 2.68,
      "step": 940
    },
    {
      "epoch": 0.2646239554317549,
      "grad_norm": 1.7619974613189697,
      "learning_rate": 0.0009735654596100279,
      "loss": 2.9038,
      "step": 950
    },
    {
      "epoch": 0.26740947075208915,
      "grad_norm": 1.4360049962997437,
      "learning_rate": 0.0009732869080779945,
      "loss": 2.7045,
      "step": 960
    },
    {
      "epoch": 0.27019498607242337,
      "grad_norm": 1.2218104600906372,
      "learning_rate": 0.000973008356545961,
      "loss": 2.5466,
      "step": 970
    },
    {
      "epoch": 0.27298050139275765,
      "grad_norm": 1.2115695476531982,
      "learning_rate": 0.0009727298050139276,
      "loss": 2.6825,
      "step": 980
    },
    {
      "epoch": 0.2757660167130919,
      "grad_norm": 1.121020793914795,
      "learning_rate": 0.0009724512534818942,
      "loss": 2.4503,
      "step": 990
    },
    {
      "epoch": 0.2785515320334262,
      "grad_norm": 1.2568773031234741,
      "learning_rate": 0.0009721727019498607,
      "loss": 2.6551,
      "step": 1000
    },
    {
      "epoch": 0.28133704735376047,
      "grad_norm": 2.096107244491577,
      "learning_rate": 0.0009718941504178273,
      "loss": 2.4537,
      "step": 1010
    },
    {
      "epoch": 0.2841225626740947,
      "grad_norm": 1.1138832569122314,
      "learning_rate": 0.0009716155988857938,
      "loss": 2.6241,
      "step": 1020
    },
    {
      "epoch": 0.28690807799442897,
      "grad_norm": 1.082237720489502,
      "learning_rate": 0.0009713370473537605,
      "loss": 2.8076,
      "step": 1030
    },
    {
      "epoch": 0.28969359331476324,
      "grad_norm": 1.759205937385559,
      "learning_rate": 0.000971058495821727,
      "loss": 2.4967,
      "step": 1040
    },
    {
      "epoch": 0.2924791086350975,
      "grad_norm": 1.4228224754333496,
      "learning_rate": 0.0009707799442896936,
      "loss": 2.5495,
      "step": 1050
    },
    {
      "epoch": 0.29526462395543174,
      "grad_norm": 1.2179782390594482,
      "learning_rate": 0.0009705013927576602,
      "loss": 2.5726,
      "step": 1060
    },
    {
      "epoch": 0.298050139275766,
      "grad_norm": 1.0589041709899902,
      "learning_rate": 0.0009702228412256268,
      "loss": 2.5539,
      "step": 1070
    },
    {
      "epoch": 0.3008356545961003,
      "grad_norm": 1.321881651878357,
      "learning_rate": 0.0009699442896935934,
      "loss": 2.7221,
      "step": 1080
    },
    {
      "epoch": 0.30362116991643456,
      "grad_norm": 1.3781636953353882,
      "learning_rate": 0.0009696657381615599,
      "loss": 2.6005,
      "step": 1090
    },
    {
      "epoch": 0.3064066852367688,
      "grad_norm": 1.297652006149292,
      "learning_rate": 0.0009693871866295266,
      "loss": 2.6716,
      "step": 1100
    },
    {
      "epoch": 0.30919220055710306,
      "grad_norm": 1.3703551292419434,
      "learning_rate": 0.000969108635097493,
      "loss": 2.7372,
      "step": 1110
    },
    {
      "epoch": 0.31197771587743733,
      "grad_norm": 1.2973988056182861,
      "learning_rate": 0.0009688300835654596,
      "loss": 2.6567,
      "step": 1120
    },
    {
      "epoch": 0.3147632311977716,
      "grad_norm": 1.3623809814453125,
      "learning_rate": 0.0009685515320334262,
      "loss": 2.508,
      "step": 1130
    },
    {
      "epoch": 0.31754874651810583,
      "grad_norm": 1.2565559148788452,
      "learning_rate": 0.0009682729805013928,
      "loss": 2.6754,
      "step": 1140
    },
    {
      "epoch": 0.3203342618384401,
      "grad_norm": 1.1795793771743774,
      "learning_rate": 0.0009679944289693593,
      "loss": 2.6742,
      "step": 1150
    },
    {
      "epoch": 0.3231197771587744,
      "grad_norm": 1.4879752397537231,
      "learning_rate": 0.0009677158774373259,
      "loss": 2.4956,
      "step": 1160
    },
    {
      "epoch": 0.32590529247910865,
      "grad_norm": 1.2180157899856567,
      "learning_rate": 0.0009674373259052926,
      "loss": 2.6508,
      "step": 1170
    },
    {
      "epoch": 0.3286908077994429,
      "grad_norm": 1.2524197101593018,
      "learning_rate": 0.0009671587743732591,
      "loss": 2.6679,
      "step": 1180
    },
    {
      "epoch": 0.33147632311977715,
      "grad_norm": 1.35256826877594,
      "learning_rate": 0.0009668802228412257,
      "loss": 2.8273,
      "step": 1190
    },
    {
      "epoch": 0.3342618384401114,
      "grad_norm": 1.5260603427886963,
      "learning_rate": 0.0009666016713091921,
      "loss": 2.6268,
      "step": 1200
    },
    {
      "epoch": 0.3370473537604457,
      "grad_norm": 1.7540775537490845,
      "learning_rate": 0.0009663231197771588,
      "loss": 2.519,
      "step": 1210
    },
    {
      "epoch": 0.3398328690807799,
      "grad_norm": 1.5949130058288574,
      "learning_rate": 0.0009660445682451253,
      "loss": 2.5143,
      "step": 1220
    },
    {
      "epoch": 0.3426183844011142,
      "grad_norm": 1.0860681533813477,
      "learning_rate": 0.0009657660167130919,
      "loss": 2.5586,
      "step": 1230
    },
    {
      "epoch": 0.34540389972144847,
      "grad_norm": 1.1188979148864746,
      "learning_rate": 0.0009654874651810586,
      "loss": 2.5164,
      "step": 1240
    },
    {
      "epoch": 0.34818941504178275,
      "grad_norm": 1.1286648511886597,
      "learning_rate": 0.0009652089136490251,
      "loss": 2.5772,
      "step": 1250
    },
    {
      "epoch": 0.35097493036211697,
      "grad_norm": 1.5116323232650757,
      "learning_rate": 0.0009649303621169917,
      "loss": 2.6543,
      "step": 1260
    },
    {
      "epoch": 0.35376044568245124,
      "grad_norm": 1.458951711654663,
      "learning_rate": 0.0009646518105849582,
      "loss": 2.8363,
      "step": 1270
    },
    {
      "epoch": 0.3565459610027855,
      "grad_norm": 1.2095354795455933,
      "learning_rate": 0.0009643732590529249,
      "loss": 2.6857,
      "step": 1280
    },
    {
      "epoch": 0.3593314763231198,
      "grad_norm": 1.0491148233413696,
      "learning_rate": 0.0009640947075208914,
      "loss": 2.5778,
      "step": 1290
    },
    {
      "epoch": 0.362116991643454,
      "grad_norm": 1.2475234270095825,
      "learning_rate": 0.0009638161559888579,
      "loss": 2.6415,
      "step": 1300
    },
    {
      "epoch": 0.3649025069637883,
      "grad_norm": 1.9963531494140625,
      "learning_rate": 0.0009635376044568245,
      "loss": 2.5831,
      "step": 1310
    },
    {
      "epoch": 0.36768802228412256,
      "grad_norm": 1.413554310798645,
      "learning_rate": 0.0009632590529247911,
      "loss": 2.7378,
      "step": 1320
    },
    {
      "epoch": 0.37047353760445684,
      "grad_norm": 1.80016028881073,
      "learning_rate": 0.0009629805013927577,
      "loss": 2.6622,
      "step": 1330
    },
    {
      "epoch": 0.3732590529247911,
      "grad_norm": 1.4611876010894775,
      "learning_rate": 0.0009627019498607242,
      "loss": 2.503,
      "step": 1340
    },
    {
      "epoch": 0.37604456824512533,
      "grad_norm": 1.1218934059143066,
      "learning_rate": 0.0009624233983286909,
      "loss": 2.6757,
      "step": 1350
    },
    {
      "epoch": 0.3788300835654596,
      "grad_norm": 1.5722981691360474,
      "learning_rate": 0.0009621448467966574,
      "loss": 2.7089,
      "step": 1360
    },
    {
      "epoch": 0.3816155988857939,
      "grad_norm": 1.2269376516342163,
      "learning_rate": 0.000961866295264624,
      "loss": 2.7037,
      "step": 1370
    },
    {
      "epoch": 0.38440111420612816,
      "grad_norm": 1.387017011642456,
      "learning_rate": 0.0009615877437325905,
      "loss": 2.586,
      "step": 1380
    },
    {
      "epoch": 0.3871866295264624,
      "grad_norm": 1.515525221824646,
      "learning_rate": 0.0009613091922005572,
      "loss": 2.6129,
      "step": 1390
    },
    {
      "epoch": 0.38997214484679665,
      "grad_norm": 1.1997807025909424,
      "learning_rate": 0.0009610306406685237,
      "loss": 2.488,
      "step": 1400
    },
    {
      "epoch": 0.39275766016713093,
      "grad_norm": 1.5051579475402832,
      "learning_rate": 0.0009607520891364902,
      "loss": 2.7434,
      "step": 1410
    },
    {
      "epoch": 0.3955431754874652,
      "grad_norm": 1.159185767173767,
      "learning_rate": 0.0009604735376044569,
      "loss": 2.6266,
      "step": 1420
    },
    {
      "epoch": 0.3983286908077994,
      "grad_norm": 1.232654094696045,
      "learning_rate": 0.0009601949860724234,
      "loss": 2.5591,
      "step": 1430
    },
    {
      "epoch": 0.4011142061281337,
      "grad_norm": 1.1168028116226196,
      "learning_rate": 0.00095991643454039,
      "loss": 2.397,
      "step": 1440
    },
    {
      "epoch": 0.403899721448468,
      "grad_norm": 1.3815401792526245,
      "learning_rate": 0.0009596378830083565,
      "loss": 2.3866,
      "step": 1450
    },
    {
      "epoch": 0.40668523676880225,
      "grad_norm": 1.520772933959961,
      "learning_rate": 0.0009593593314763232,
      "loss": 2.5404,
      "step": 1460
    },
    {
      "epoch": 0.40947075208913647,
      "grad_norm": 1.3483422994613647,
      "learning_rate": 0.0009590807799442897,
      "loss": 2.5735,
      "step": 1470
    },
    {
      "epoch": 0.41225626740947074,
      "grad_norm": 1.2592273950576782,
      "learning_rate": 0.0009588022284122563,
      "loss": 2.6864,
      "step": 1480
    },
    {
      "epoch": 0.415041782729805,
      "grad_norm": 1.1354230642318726,
      "learning_rate": 0.000958523676880223,
      "loss": 2.4747,
      "step": 1490
    },
    {
      "epoch": 0.4178272980501393,
      "grad_norm": 1.1164798736572266,
      "learning_rate": 0.0009582451253481894,
      "loss": 2.5945,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 35900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 198686932992000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
