{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 480,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.20833333333333334,
      "grad_norm": 2.349428415298462,
      "learning_rate": 0.00098125,
      "loss": 4.8504,
      "step": 10
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 3.6608529090881348,
      "learning_rate": 0.0009604166666666667,
      "loss": 3.7517,
      "step": 20
    },
    {
      "epoch": 0.625,
      "grad_norm": 2.46658992767334,
      "learning_rate": 0.0009395833333333334,
      "loss": 2.9755,
      "step": 30
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 2.666827440261841,
      "learning_rate": 0.00091875,
      "loss": 2.3901,
      "step": 40
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9979555010795593,
      "eval_runtime": 0.1368,
      "eval_samples_per_second": 306.943,
      "eval_steps_per_second": 43.849,
      "step": 48
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 3.9105544090270996,
      "learning_rate": 0.0008979166666666668,
      "loss": 1.5486,
      "step": 50
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.4128975868225098,
      "learning_rate": 0.0008770833333333333,
      "loss": 1.3296,
      "step": 60
    },
    {
      "epoch": 1.4583333333333333,
      "grad_norm": 2.378140687942505,
      "learning_rate": 0.00085625,
      "loss": 1.2042,
      "step": 70
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.901816725730896,
      "learning_rate": 0.0008354166666666667,
      "loss": 0.9106,
      "step": 80
    },
    {
      "epoch": 1.875,
      "grad_norm": 2.115037679672241,
      "learning_rate": 0.0008145833333333334,
      "loss": 1.1077,
      "step": 90
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.5075667500495911,
      "eval_runtime": 0.0965,
      "eval_samples_per_second": 435.286,
      "eval_steps_per_second": 62.184,
      "step": 96
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 2.394510269165039,
      "learning_rate": 0.00079375,
      "loss": 0.9489,
      "step": 100
    },
    {
      "epoch": 2.2916666666666665,
      "grad_norm": 1.8467353582382202,
      "learning_rate": 0.0007729166666666668,
      "loss": 0.8332,
      "step": 110
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.284929871559143,
      "learning_rate": 0.0007520833333333333,
      "loss": 0.9532,
      "step": 120
    },
    {
      "epoch": 2.7083333333333335,
      "grad_norm": 4.010359287261963,
      "learning_rate": 0.00073125,
      "loss": 0.7469,
      "step": 130
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 2.0802764892578125,
      "learning_rate": 0.0007104166666666667,
      "loss": 0.6739,
      "step": 140
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.2854223847389221,
      "eval_runtime": 0.1047,
      "eval_samples_per_second": 400.982,
      "eval_steps_per_second": 57.283,
      "step": 144
    },
    {
      "epoch": 3.125,
      "grad_norm": 1.6915313005447388,
      "learning_rate": 0.0006895833333333334,
      "loss": 0.777,
      "step": 150
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 3.013339042663574,
      "learning_rate": 0.00066875,
      "loss": 0.7681,
      "step": 160
    },
    {
      "epoch": 3.5416666666666665,
      "grad_norm": 1.5808191299438477,
      "learning_rate": 0.0006479166666666668,
      "loss": 0.8994,
      "step": 170
    },
    {
      "epoch": 3.75,
      "grad_norm": 1.4907116889953613,
      "learning_rate": 0.0006270833333333333,
      "loss": 0.6264,
      "step": 180
    },
    {
      "epoch": 3.9583333333333335,
      "grad_norm": 2.3339545726776123,
      "learning_rate": 0.00060625,
      "loss": 0.6587,
      "step": 190
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.18238946795463562,
      "eval_runtime": 0.168,
      "eval_samples_per_second": 250.051,
      "eval_steps_per_second": 35.722,
      "step": 192
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.970319926738739,
      "learning_rate": 0.0005854166666666667,
      "loss": 0.6695,
      "step": 200
    },
    {
      "epoch": 4.375,
      "grad_norm": 1.9763842821121216,
      "learning_rate": 0.0005645833333333334,
      "loss": 0.7198,
      "step": 210
    },
    {
      "epoch": 4.583333333333333,
      "grad_norm": 1.887213110923767,
      "learning_rate": 0.00054375,
      "loss": 0.7255,
      "step": 220
    },
    {
      "epoch": 4.791666666666667,
      "grad_norm": 1.25445556640625,
      "learning_rate": 0.0005229166666666668,
      "loss": 0.7279,
      "step": 230
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.3510642051696777,
      "learning_rate": 0.0005020833333333333,
      "loss": 0.6302,
      "step": 240
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.20477059483528137,
      "eval_runtime": 0.0817,
      "eval_samples_per_second": 514.158,
      "eval_steps_per_second": 73.451,
      "step": 240
    },
    {
      "epoch": 5.208333333333333,
      "grad_norm": 1.9172561168670654,
      "learning_rate": 0.00048125,
      "loss": 0.7368,
      "step": 250
    },
    {
      "epoch": 5.416666666666667,
      "grad_norm": 2.468553066253662,
      "learning_rate": 0.00046041666666666665,
      "loss": 0.612,
      "step": 260
    },
    {
      "epoch": 5.625,
      "grad_norm": 1.316192388534546,
      "learning_rate": 0.00043958333333333333,
      "loss": 0.4702,
      "step": 270
    },
    {
      "epoch": 5.833333333333333,
      "grad_norm": 3.6292724609375,
      "learning_rate": 0.00041875,
      "loss": 0.6106,
      "step": 280
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.19119037687778473,
      "eval_runtime": 0.0859,
      "eval_samples_per_second": 488.769,
      "eval_steps_per_second": 69.824,
      "step": 288
    },
    {
      "epoch": 6.041666666666667,
      "grad_norm": 1.554007887840271,
      "learning_rate": 0.00039791666666666664,
      "loss": 0.4356,
      "step": 290
    },
    {
      "epoch": 6.25,
      "grad_norm": 1.6278178691864014,
      "learning_rate": 0.00037708333333333333,
      "loss": 0.4235,
      "step": 300
    },
    {
      "epoch": 6.458333333333333,
      "grad_norm": 1.5692864656448364,
      "learning_rate": 0.00035625,
      "loss": 0.4492,
      "step": 310
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 1.2293763160705566,
      "learning_rate": 0.00033541666666666664,
      "loss": 0.6312,
      "step": 320
    },
    {
      "epoch": 6.875,
      "grad_norm": 2.8178703784942627,
      "learning_rate": 0.00031458333333333333,
      "loss": 0.5627,
      "step": 330
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.16926798224449158,
      "eval_runtime": 0.1026,
      "eval_samples_per_second": 409.184,
      "eval_steps_per_second": 58.455,
      "step": 336
    },
    {
      "epoch": 7.083333333333333,
      "grad_norm": 3.4868690967559814,
      "learning_rate": 0.00029375,
      "loss": 0.6502,
      "step": 340
    },
    {
      "epoch": 7.291666666666667,
      "grad_norm": 2.442356824874878,
      "learning_rate": 0.00027291666666666664,
      "loss": 0.3728,
      "step": 350
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.071604013442993,
      "learning_rate": 0.0002520833333333333,
      "loss": 0.5338,
      "step": 360
    },
    {
      "epoch": 7.708333333333333,
      "grad_norm": 2.881418466567993,
      "learning_rate": 0.00023125,
      "loss": 0.4232,
      "step": 370
    },
    {
      "epoch": 7.916666666666667,
      "grad_norm": 2.2664053440093994,
      "learning_rate": 0.00021041666666666667,
      "loss": 0.4619,
      "step": 380
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.16013182699680328,
      "eval_runtime": 0.1392,
      "eval_samples_per_second": 301.735,
      "eval_steps_per_second": 43.105,
      "step": 384
    },
    {
      "epoch": 8.125,
      "grad_norm": 0.9840458631515503,
      "learning_rate": 0.00018958333333333332,
      "loss": 0.6026,
      "step": 390
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 4.1948418617248535,
      "learning_rate": 0.00016875,
      "loss": 0.5546,
      "step": 400
    },
    {
      "epoch": 8.541666666666666,
      "grad_norm": 1.6959645748138428,
      "learning_rate": 0.00014791666666666667,
      "loss": 0.4259,
      "step": 410
    },
    {
      "epoch": 8.75,
      "grad_norm": 1.3805124759674072,
      "learning_rate": 0.00012708333333333332,
      "loss": 0.5839,
      "step": 420
    },
    {
      "epoch": 8.958333333333334,
      "grad_norm": 1.8877958059310913,
      "learning_rate": 0.00010625,
      "loss": 0.4008,
      "step": 430
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.14781005680561066,
      "eval_runtime": 0.0833,
      "eval_samples_per_second": 504.272,
      "eval_steps_per_second": 72.039,
      "step": 432
    },
    {
      "epoch": 9.166666666666666,
      "grad_norm": 3.295362710952759,
      "learning_rate": 8.541666666666666e-05,
      "loss": 0.4694,
      "step": 440
    },
    {
      "epoch": 9.375,
      "grad_norm": 1.738512635231018,
      "learning_rate": 6.458333333333334e-05,
      "loss": 0.4357,
      "step": 450
    },
    {
      "epoch": 9.583333333333334,
      "grad_norm": 2.4147260189056396,
      "learning_rate": 4.375e-05,
      "loss": 0.4318,
      "step": 460
    },
    {
      "epoch": 9.791666666666666,
      "grad_norm": 1.5125720500946045,
      "learning_rate": 2.2916666666666667e-05,
      "loss": 0.4116,
      "step": 470
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.3504444360733032,
      "learning_rate": 2.0833333333333334e-06,
      "loss": 0.4172,
      "step": 480
    }
  ],
  "logging_steps": 10,
  "max_steps": 480,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 62586383892480.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
