{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9749303621169917,
  "eval_steps": 500,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002785515320334262,
      "grad_norm": 1.2840194702148438,
      "learning_rate": 0.00099974930362117,
      "loss": 4.3861,
      "step": 10
    },
    {
      "epoch": 0.005571030640668524,
      "grad_norm": 2.154874086380005,
      "learning_rate": 0.0009994707520891365,
      "loss": 3.4879,
      "step": 20
    },
    {
      "epoch": 0.008356545961002786,
      "grad_norm": 1.0960689783096313,
      "learning_rate": 0.0009991922005571031,
      "loss": 3.1786,
      "step": 30
    },
    {
      "epoch": 0.011142061281337047,
      "grad_norm": 1.6222344636917114,
      "learning_rate": 0.0009989136490250697,
      "loss": 3.4405,
      "step": 40
    },
    {
      "epoch": 0.013927576601671309,
      "grad_norm": 1.4486805200576782,
      "learning_rate": 0.0009986350974930363,
      "loss": 3.2406,
      "step": 50
    },
    {
      "epoch": 0.016713091922005572,
      "grad_norm": 1.4545409679412842,
      "learning_rate": 0.0009983565459610027,
      "loss": 2.9184,
      "step": 60
    },
    {
      "epoch": 0.019498607242339833,
      "grad_norm": 1.2460061311721802,
      "learning_rate": 0.0009980779944289695,
      "loss": 3.2825,
      "step": 70
    },
    {
      "epoch": 0.022284122562674095,
      "grad_norm": 1.1035219430923462,
      "learning_rate": 0.0009977994428969359,
      "loss": 2.9467,
      "step": 80
    },
    {
      "epoch": 0.025069637883008356,
      "grad_norm": 1.084650993347168,
      "learning_rate": 0.0009975208913649025,
      "loss": 2.8749,
      "step": 90
    },
    {
      "epoch": 0.027855153203342618,
      "grad_norm": 1.3431271314620972,
      "learning_rate": 0.000997242339832869,
      "loss": 2.7405,
      "step": 100
    },
    {
      "epoch": 0.03064066852367688,
      "grad_norm": 1.5075708627700806,
      "learning_rate": 0.0009969637883008356,
      "loss": 3.0164,
      "step": 110
    },
    {
      "epoch": 0.033426183844011144,
      "grad_norm": 1.139190673828125,
      "learning_rate": 0.0009966852367688022,
      "loss": 3.1564,
      "step": 120
    },
    {
      "epoch": 0.036211699164345405,
      "grad_norm": 1.4167214632034302,
      "learning_rate": 0.0009964066852367688,
      "loss": 2.9413,
      "step": 130
    },
    {
      "epoch": 0.03899721448467967,
      "grad_norm": 1.5525418519973755,
      "learning_rate": 0.0009961281337047354,
      "loss": 3.1507,
      "step": 140
    },
    {
      "epoch": 0.04178272980501393,
      "grad_norm": 1.2979793548583984,
      "learning_rate": 0.000995849582172702,
      "loss": 2.8883,
      "step": 150
    },
    {
      "epoch": 0.04456824512534819,
      "grad_norm": 1.815700650215149,
      "learning_rate": 0.0009955710306406686,
      "loss": 2.7748,
      "step": 160
    },
    {
      "epoch": 0.04735376044568245,
      "grad_norm": 1.3322603702545166,
      "learning_rate": 0.000995292479108635,
      "loss": 2.8884,
      "step": 170
    },
    {
      "epoch": 0.05013927576601671,
      "grad_norm": 1.5178040266036987,
      "learning_rate": 0.0009950139275766018,
      "loss": 2.7766,
      "step": 180
    },
    {
      "epoch": 0.052924791086350974,
      "grad_norm": 1.1066555976867676,
      "learning_rate": 0.0009947353760445684,
      "loss": 3.1326,
      "step": 190
    },
    {
      "epoch": 0.055710306406685235,
      "grad_norm": 1.3780025243759155,
      "learning_rate": 0.0009944568245125348,
      "loss": 2.837,
      "step": 200
    },
    {
      "epoch": 0.0584958217270195,
      "grad_norm": 1.104160189628601,
      "learning_rate": 0.0009941782729805016,
      "loss": 3.0843,
      "step": 210
    },
    {
      "epoch": 0.06128133704735376,
      "grad_norm": 1.1225481033325195,
      "learning_rate": 0.000993899721448468,
      "loss": 2.8273,
      "step": 220
    },
    {
      "epoch": 0.06406685236768803,
      "grad_norm": 1.7669438123703003,
      "learning_rate": 0.0009936211699164345,
      "loss": 2.9873,
      "step": 230
    },
    {
      "epoch": 0.06685236768802229,
      "grad_norm": 1.3010444641113281,
      "learning_rate": 0.0009933426183844011,
      "loss": 2.8877,
      "step": 240
    },
    {
      "epoch": 0.06963788300835655,
      "grad_norm": 1.6041792631149292,
      "learning_rate": 0.0009930640668523677,
      "loss": 2.8832,
      "step": 250
    },
    {
      "epoch": 0.07242339832869081,
      "grad_norm": 3.745532989501953,
      "learning_rate": 0.0009927855153203343,
      "loss": 3.1192,
      "step": 260
    },
    {
      "epoch": 0.07520891364902507,
      "grad_norm": 1.5474622249603271,
      "learning_rate": 0.0009925069637883009,
      "loss": 3.131,
      "step": 270
    },
    {
      "epoch": 0.07799442896935933,
      "grad_norm": 1.5285918712615967,
      "learning_rate": 0.0009922284122562675,
      "loss": 2.7621,
      "step": 280
    },
    {
      "epoch": 0.0807799442896936,
      "grad_norm": 1.1603755950927734,
      "learning_rate": 0.000991949860724234,
      "loss": 2.7839,
      "step": 290
    },
    {
      "epoch": 0.08356545961002786,
      "grad_norm": 1.2766029834747314,
      "learning_rate": 0.0009916713091922007,
      "loss": 2.9389,
      "step": 300
    },
    {
      "epoch": 0.08635097493036212,
      "grad_norm": 1.3101592063903809,
      "learning_rate": 0.000991392757660167,
      "loss": 2.9411,
      "step": 310
    },
    {
      "epoch": 0.08913649025069638,
      "grad_norm": 1.0913796424865723,
      "learning_rate": 0.0009911142061281338,
      "loss": 2.746,
      "step": 320
    },
    {
      "epoch": 0.09192200557103064,
      "grad_norm": 1.9779218435287476,
      "learning_rate": 0.0009908356545961002,
      "loss": 2.8228,
      "step": 330
    },
    {
      "epoch": 0.0947075208913649,
      "grad_norm": 1.625001072883606,
      "learning_rate": 0.0009905571030640668,
      "loss": 2.9564,
      "step": 340
    },
    {
      "epoch": 0.09749303621169916,
      "grad_norm": 1.529102087020874,
      "learning_rate": 0.0009902785515320334,
      "loss": 2.628,
      "step": 350
    },
    {
      "epoch": 0.10027855153203342,
      "grad_norm": 1.090011715888977,
      "learning_rate": 0.00099,
      "loss": 2.8333,
      "step": 360
    },
    {
      "epoch": 0.10306406685236769,
      "grad_norm": 1.157884120941162,
      "learning_rate": 0.0009897214484679666,
      "loss": 2.8647,
      "step": 370
    },
    {
      "epoch": 0.10584958217270195,
      "grad_norm": 1.417336106300354,
      "learning_rate": 0.0009894428969359332,
      "loss": 2.8201,
      "step": 380
    },
    {
      "epoch": 0.10863509749303621,
      "grad_norm": 1.907312273979187,
      "learning_rate": 0.0009891643454038998,
      "loss": 2.8994,
      "step": 390
    },
    {
      "epoch": 0.11142061281337047,
      "grad_norm": 1.195726752281189,
      "learning_rate": 0.0009888857938718664,
      "loss": 2.8248,
      "step": 400
    },
    {
      "epoch": 0.11420612813370473,
      "grad_norm": 1.2463825941085815,
      "learning_rate": 0.000988607242339833,
      "loss": 2.6675,
      "step": 410
    },
    {
      "epoch": 0.116991643454039,
      "grad_norm": 1.379415512084961,
      "learning_rate": 0.0009883286908077993,
      "loss": 2.7798,
      "step": 420
    },
    {
      "epoch": 0.11977715877437325,
      "grad_norm": 1.220304012298584,
      "learning_rate": 0.0009880501392757661,
      "loss": 2.5676,
      "step": 430
    },
    {
      "epoch": 0.12256267409470752,
      "grad_norm": 1.1389501094818115,
      "learning_rate": 0.0009877715877437327,
      "loss": 2.7481,
      "step": 440
    },
    {
      "epoch": 0.12534818941504178,
      "grad_norm": 1.3198240995407104,
      "learning_rate": 0.000987493036211699,
      "loss": 2.6279,
      "step": 450
    },
    {
      "epoch": 0.12813370473537605,
      "grad_norm": 1.134945034980774,
      "learning_rate": 0.0009872144846796657,
      "loss": 2.6653,
      "step": 460
    },
    {
      "epoch": 0.1309192200557103,
      "grad_norm": 1.6973408460617065,
      "learning_rate": 0.0009869359331476323,
      "loss": 2.6176,
      "step": 470
    },
    {
      "epoch": 0.13370473537604458,
      "grad_norm": 1.4935957193374634,
      "learning_rate": 0.0009866573816155989,
      "loss": 2.7296,
      "step": 480
    },
    {
      "epoch": 0.13649025069637882,
      "grad_norm": 1.3750529289245605,
      "learning_rate": 0.0009863788300835655,
      "loss": 2.5529,
      "step": 490
    },
    {
      "epoch": 0.1392757660167131,
      "grad_norm": 1.1334233283996582,
      "learning_rate": 0.000986100278551532,
      "loss": 2.6938,
      "step": 500
    },
    {
      "epoch": 0.14206128133704735,
      "grad_norm": 1.2611706256866455,
      "learning_rate": 0.0009858217270194986,
      "loss": 2.6381,
      "step": 510
    },
    {
      "epoch": 0.14484679665738162,
      "grad_norm": 1.4956426620483398,
      "learning_rate": 0.0009855431754874652,
      "loss": 2.8845,
      "step": 520
    },
    {
      "epoch": 0.14763231197771587,
      "grad_norm": 1.519185185432434,
      "learning_rate": 0.0009852646239554318,
      "loss": 2.8678,
      "step": 530
    },
    {
      "epoch": 0.15041782729805014,
      "grad_norm": 1.400498628616333,
      "learning_rate": 0.0009849860724233984,
      "loss": 2.5209,
      "step": 540
    },
    {
      "epoch": 0.1532033426183844,
      "grad_norm": 1.174527883529663,
      "learning_rate": 0.000984707520891365,
      "loss": 2.8298,
      "step": 550
    },
    {
      "epoch": 0.15598885793871867,
      "grad_norm": 1.046203851699829,
      "learning_rate": 0.0009844289693593314,
      "loss": 2.9215,
      "step": 560
    },
    {
      "epoch": 0.15877437325905291,
      "grad_norm": 1.573647141456604,
      "learning_rate": 0.000984150417827298,
      "loss": 2.7208,
      "step": 570
    },
    {
      "epoch": 0.1615598885793872,
      "grad_norm": 1.3784769773483276,
      "learning_rate": 0.0009838718662952646,
      "loss": 2.7379,
      "step": 580
    },
    {
      "epoch": 0.16434540389972144,
      "grad_norm": 1.1505237817764282,
      "learning_rate": 0.0009835933147632312,
      "loss": 2.7575,
      "step": 590
    },
    {
      "epoch": 0.1671309192200557,
      "grad_norm": 1.7309839725494385,
      "learning_rate": 0.0009833147632311977,
      "loss": 2.9615,
      "step": 600
    },
    {
      "epoch": 0.16991643454038996,
      "grad_norm": 1.3678911924362183,
      "learning_rate": 0.0009830362116991643,
      "loss": 2.6519,
      "step": 610
    },
    {
      "epoch": 0.17270194986072424,
      "grad_norm": 1.6271007061004639,
      "learning_rate": 0.000982757660167131,
      "loss": 2.8411,
      "step": 620
    },
    {
      "epoch": 0.17548746518105848,
      "grad_norm": 1.1443215608596802,
      "learning_rate": 0.0009824791086350975,
      "loss": 2.7633,
      "step": 630
    },
    {
      "epoch": 0.17827298050139276,
      "grad_norm": 1.3229976892471313,
      "learning_rate": 0.0009822005571030641,
      "loss": 2.5299,
      "step": 640
    },
    {
      "epoch": 0.181058495821727,
      "grad_norm": 1.2686564922332764,
      "learning_rate": 0.0009819220055710307,
      "loss": 2.8143,
      "step": 650
    },
    {
      "epoch": 0.18384401114206128,
      "grad_norm": 1.7103956937789917,
      "learning_rate": 0.0009816434540389973,
      "loss": 2.6153,
      "step": 660
    },
    {
      "epoch": 0.18662952646239556,
      "grad_norm": 1.1940762996673584,
      "learning_rate": 0.0009813649025069639,
      "loss": 2.7772,
      "step": 670
    },
    {
      "epoch": 0.1894150417827298,
      "grad_norm": 1.1911855936050415,
      "learning_rate": 0.0009810863509749305,
      "loss": 2.6748,
      "step": 680
    },
    {
      "epoch": 0.19220055710306408,
      "grad_norm": 1.1384587287902832,
      "learning_rate": 0.000980807799442897,
      "loss": 2.7359,
      "step": 690
    },
    {
      "epoch": 0.19498607242339833,
      "grad_norm": 1.5987355709075928,
      "learning_rate": 0.0009805292479108634,
      "loss": 2.7105,
      "step": 700
    },
    {
      "epoch": 0.1977715877437326,
      "grad_norm": 1.310819387435913,
      "learning_rate": 0.00098025069637883,
      "loss": 2.6184,
      "step": 710
    },
    {
      "epoch": 0.20055710306406685,
      "grad_norm": 1.2290271520614624,
      "learning_rate": 0.0009799721448467966,
      "loss": 2.7928,
      "step": 720
    },
    {
      "epoch": 0.20334261838440112,
      "grad_norm": 1.4798976182937622,
      "learning_rate": 0.0009796935933147632,
      "loss": 2.5798,
      "step": 730
    },
    {
      "epoch": 0.20612813370473537,
      "grad_norm": 10.657740592956543,
      "learning_rate": 0.0009794150417827298,
      "loss": 2.8772,
      "step": 740
    },
    {
      "epoch": 0.20891364902506965,
      "grad_norm": 1.506508231163025,
      "learning_rate": 0.0009791364902506964,
      "loss": 2.7455,
      "step": 750
    },
    {
      "epoch": 0.2116991643454039,
      "grad_norm": 1.8453625440597534,
      "learning_rate": 0.000978857938718663,
      "loss": 2.641,
      "step": 760
    },
    {
      "epoch": 0.21448467966573817,
      "grad_norm": 1.25679349899292,
      "learning_rate": 0.0009785793871866296,
      "loss": 2.6111,
      "step": 770
    },
    {
      "epoch": 0.21727019498607242,
      "grad_norm": 1.1964632272720337,
      "learning_rate": 0.0009783008356545962,
      "loss": 2.4162,
      "step": 780
    },
    {
      "epoch": 0.2200557103064067,
      "grad_norm": 1.8626738786697388,
      "learning_rate": 0.0009780222841225628,
      "loss": 2.8126,
      "step": 790
    },
    {
      "epoch": 0.22284122562674094,
      "grad_norm": 1.968948483467102,
      "learning_rate": 0.0009777437325905294,
      "loss": 2.6974,
      "step": 800
    },
    {
      "epoch": 0.22562674094707522,
      "grad_norm": 1.3703383207321167,
      "learning_rate": 0.0009774651810584957,
      "loss": 2.6127,
      "step": 810
    },
    {
      "epoch": 0.22841225626740946,
      "grad_norm": 1.504210114479065,
      "learning_rate": 0.0009771866295264623,
      "loss": 2.6646,
      "step": 820
    },
    {
      "epoch": 0.23119777158774374,
      "grad_norm": 1.2684354782104492,
      "learning_rate": 0.000976908077994429,
      "loss": 2.8587,
      "step": 830
    },
    {
      "epoch": 0.233983286908078,
      "grad_norm": 1.0541630983352661,
      "learning_rate": 0.0009766295264623955,
      "loss": 2.5336,
      "step": 840
    },
    {
      "epoch": 0.23676880222841226,
      "grad_norm": 1.1500130891799927,
      "learning_rate": 0.0009763509749303622,
      "loss": 2.5435,
      "step": 850
    },
    {
      "epoch": 0.2395543175487465,
      "grad_norm": 1.2419148683547974,
      "learning_rate": 0.0009760724233983287,
      "loss": 2.7044,
      "step": 860
    },
    {
      "epoch": 0.24233983286908078,
      "grad_norm": 1.7566492557525635,
      "learning_rate": 0.0009757938718662953,
      "loss": 2.593,
      "step": 870
    },
    {
      "epoch": 0.24512534818941503,
      "grad_norm": 1.3943686485290527,
      "learning_rate": 0.0009755153203342619,
      "loss": 2.528,
      "step": 880
    },
    {
      "epoch": 0.2479108635097493,
      "grad_norm": 1.9906026124954224,
      "learning_rate": 0.0009752367688022285,
      "loss": 2.5273,
      "step": 890
    },
    {
      "epoch": 0.25069637883008355,
      "grad_norm": 2.0821707248687744,
      "learning_rate": 0.0009749582172701949,
      "loss": 2.5782,
      "step": 900
    },
    {
      "epoch": 0.25348189415041783,
      "grad_norm": 1.6509175300598145,
      "learning_rate": 0.0009746796657381615,
      "loss": 2.4893,
      "step": 910
    },
    {
      "epoch": 0.2562674094707521,
      "grad_norm": 0.9984078407287598,
      "learning_rate": 0.0009744011142061282,
      "loss": 2.8026,
      "step": 920
    },
    {
      "epoch": 0.2590529247910863,
      "grad_norm": 1.4023449420928955,
      "learning_rate": 0.0009741225626740947,
      "loss": 2.7435,
      "step": 930
    },
    {
      "epoch": 0.2618384401114206,
      "grad_norm": 1.3604308366775513,
      "learning_rate": 0.0009738440111420613,
      "loss": 2.6713,
      "step": 940
    },
    {
      "epoch": 0.2646239554317549,
      "grad_norm": 1.4668251276016235,
      "learning_rate": 0.0009735654596100279,
      "loss": 2.8515,
      "step": 950
    },
    {
      "epoch": 0.26740947075208915,
      "grad_norm": 1.1580578088760376,
      "learning_rate": 0.0009732869080779945,
      "loss": 2.7169,
      "step": 960
    },
    {
      "epoch": 0.27019498607242337,
      "grad_norm": 1.3737342357635498,
      "learning_rate": 0.000973008356545961,
      "loss": 2.5633,
      "step": 970
    },
    {
      "epoch": 0.27298050139275765,
      "grad_norm": 1.1599451303482056,
      "learning_rate": 0.0009727298050139276,
      "loss": 2.6884,
      "step": 980
    },
    {
      "epoch": 0.2757660167130919,
      "grad_norm": 1.05137038230896,
      "learning_rate": 0.0009724512534818942,
      "loss": 2.4235,
      "step": 990
    },
    {
      "epoch": 0.2785515320334262,
      "grad_norm": 1.0877658128738403,
      "learning_rate": 0.0009721727019498607,
      "loss": 2.6942,
      "step": 1000
    },
    {
      "epoch": 0.28133704735376047,
      "grad_norm": 2.194101333618164,
      "learning_rate": 0.0009718941504178273,
      "loss": 2.475,
      "step": 1010
    },
    {
      "epoch": 0.2841225626740947,
      "grad_norm": 1.2096844911575317,
      "learning_rate": 0.0009716155988857938,
      "loss": 2.6578,
      "step": 1020
    },
    {
      "epoch": 0.28690807799442897,
      "grad_norm": 1.0541399717330933,
      "learning_rate": 0.0009713370473537605,
      "loss": 2.83,
      "step": 1030
    },
    {
      "epoch": 0.28969359331476324,
      "grad_norm": 1.3901503086090088,
      "learning_rate": 0.000971058495821727,
      "loss": 2.5087,
      "step": 1040
    },
    {
      "epoch": 0.2924791086350975,
      "grad_norm": 1.2318532466888428,
      "learning_rate": 0.0009707799442896936,
      "loss": 2.5932,
      "step": 1050
    },
    {
      "epoch": 0.29526462395543174,
      "grad_norm": 1.2542519569396973,
      "learning_rate": 0.0009705013927576602,
      "loss": 2.5852,
      "step": 1060
    },
    {
      "epoch": 0.298050139275766,
      "grad_norm": 1.1860110759735107,
      "learning_rate": 0.0009702228412256268,
      "loss": 2.5883,
      "step": 1070
    },
    {
      "epoch": 0.3008356545961003,
      "grad_norm": 1.6900781393051147,
      "learning_rate": 0.0009699442896935934,
      "loss": 2.7473,
      "step": 1080
    },
    {
      "epoch": 0.30362116991643456,
      "grad_norm": 1.2406134605407715,
      "learning_rate": 0.0009696657381615599,
      "loss": 2.6102,
      "step": 1090
    },
    {
      "epoch": 0.3064066852367688,
      "grad_norm": 1.1991857290267944,
      "learning_rate": 0.0009693871866295266,
      "loss": 2.6797,
      "step": 1100
    },
    {
      "epoch": 0.30919220055710306,
      "grad_norm": 1.3589164018630981,
      "learning_rate": 0.000969108635097493,
      "loss": 2.7528,
      "step": 1110
    },
    {
      "epoch": 0.31197771587743733,
      "grad_norm": 1.2236847877502441,
      "learning_rate": 0.0009688300835654596,
      "loss": 2.6546,
      "step": 1120
    },
    {
      "epoch": 0.3147632311977716,
      "grad_norm": 1.274904489517212,
      "learning_rate": 0.0009685515320334262,
      "loss": 2.5034,
      "step": 1130
    },
    {
      "epoch": 0.31754874651810583,
      "grad_norm": 1.236973524093628,
      "learning_rate": 0.0009682729805013928,
      "loss": 2.6597,
      "step": 1140
    },
    {
      "epoch": 0.3203342618384401,
      "grad_norm": 1.1496905088424683,
      "learning_rate": 0.0009679944289693593,
      "loss": 2.6729,
      "step": 1150
    },
    {
      "epoch": 0.3231197771587744,
      "grad_norm": 1.8131681680679321,
      "learning_rate": 0.0009677158774373259,
      "loss": 2.5096,
      "step": 1160
    },
    {
      "epoch": 0.32590529247910865,
      "grad_norm": 1.1523754596710205,
      "learning_rate": 0.0009674373259052926,
      "loss": 2.674,
      "step": 1170
    },
    {
      "epoch": 0.3286908077994429,
      "grad_norm": 1.370139241218567,
      "learning_rate": 0.0009671587743732591,
      "loss": 2.6944,
      "step": 1180
    },
    {
      "epoch": 0.33147632311977715,
      "grad_norm": 1.2893624305725098,
      "learning_rate": 0.0009668802228412257,
      "loss": 2.8343,
      "step": 1190
    },
    {
      "epoch": 0.3342618384401114,
      "grad_norm": 1.529947280883789,
      "learning_rate": 0.0009666016713091921,
      "loss": 2.5806,
      "step": 1200
    },
    {
      "epoch": 0.3370473537604457,
      "grad_norm": 1.4873576164245605,
      "learning_rate": 0.0009663231197771588,
      "loss": 2.4799,
      "step": 1210
    },
    {
      "epoch": 0.3398328690807799,
      "grad_norm": 1.774054765701294,
      "learning_rate": 0.0009660445682451253,
      "loss": 2.5528,
      "step": 1220
    },
    {
      "epoch": 0.3426183844011142,
      "grad_norm": 1.0401158332824707,
      "learning_rate": 0.0009657660167130919,
      "loss": 2.5364,
      "step": 1230
    },
    {
      "epoch": 0.34540389972144847,
      "grad_norm": 1.3592889308929443,
      "learning_rate": 0.0009654874651810586,
      "loss": 2.5348,
      "step": 1240
    },
    {
      "epoch": 0.34818941504178275,
      "grad_norm": 1.1431103944778442,
      "learning_rate": 0.0009652089136490251,
      "loss": 2.62,
      "step": 1250
    },
    {
      "epoch": 0.35097493036211697,
      "grad_norm": 1.5082741975784302,
      "learning_rate": 0.0009649303621169917,
      "loss": 2.6316,
      "step": 1260
    },
    {
      "epoch": 0.35376044568245124,
      "grad_norm": 1.2143549919128418,
      "learning_rate": 0.0009646518105849582,
      "loss": 2.8123,
      "step": 1270
    },
    {
      "epoch": 0.3565459610027855,
      "grad_norm": 1.06922447681427,
      "learning_rate": 0.0009643732590529249,
      "loss": 2.6701,
      "step": 1280
    },
    {
      "epoch": 0.3593314763231198,
      "grad_norm": 1.0305991172790527,
      "learning_rate": 0.0009640947075208914,
      "loss": 2.5861,
      "step": 1290
    },
    {
      "epoch": 0.362116991643454,
      "grad_norm": 1.1585032939910889,
      "learning_rate": 0.0009638161559888579,
      "loss": 2.6447,
      "step": 1300
    },
    {
      "epoch": 0.3649025069637883,
      "grad_norm": 1.4382073879241943,
      "learning_rate": 0.0009635376044568245,
      "loss": 2.5628,
      "step": 1310
    },
    {
      "epoch": 0.36768802228412256,
      "grad_norm": 1.4349507093429565,
      "learning_rate": 0.0009632590529247911,
      "loss": 2.7178,
      "step": 1320
    },
    {
      "epoch": 0.37047353760445684,
      "grad_norm": 1.4539517164230347,
      "learning_rate": 0.0009629805013927577,
      "loss": 2.6386,
      "step": 1330
    },
    {
      "epoch": 0.3732590529247911,
      "grad_norm": 1.190468668937683,
      "learning_rate": 0.0009627019498607242,
      "loss": 2.4744,
      "step": 1340
    },
    {
      "epoch": 0.37604456824512533,
      "grad_norm": 1.119303822517395,
      "learning_rate": 0.0009624233983286909,
      "loss": 2.6525,
      "step": 1350
    },
    {
      "epoch": 0.3788300835654596,
      "grad_norm": 1.793784499168396,
      "learning_rate": 0.0009621448467966574,
      "loss": 2.7358,
      "step": 1360
    },
    {
      "epoch": 0.3816155988857939,
      "grad_norm": 1.217052698135376,
      "learning_rate": 0.000961866295264624,
      "loss": 2.6905,
      "step": 1370
    },
    {
      "epoch": 0.38440111420612816,
      "grad_norm": 1.2579952478408813,
      "learning_rate": 0.0009615877437325905,
      "loss": 2.5621,
      "step": 1380
    },
    {
      "epoch": 0.3871866295264624,
      "grad_norm": 1.7327309846878052,
      "learning_rate": 0.0009613091922005572,
      "loss": 2.6191,
      "step": 1390
    },
    {
      "epoch": 0.38997214484679665,
      "grad_norm": 1.1122167110443115,
      "learning_rate": 0.0009610306406685237,
      "loss": 2.4747,
      "step": 1400
    },
    {
      "epoch": 0.39275766016713093,
      "grad_norm": 1.5513404607772827,
      "learning_rate": 0.0009607520891364902,
      "loss": 2.7159,
      "step": 1410
    },
    {
      "epoch": 0.3955431754874652,
      "grad_norm": 1.1327400207519531,
      "learning_rate": 0.0009604735376044569,
      "loss": 2.6202,
      "step": 1420
    },
    {
      "epoch": 0.3983286908077994,
      "grad_norm": 1.3590971231460571,
      "learning_rate": 0.0009601949860724234,
      "loss": 2.5425,
      "step": 1430
    },
    {
      "epoch": 0.4011142061281337,
      "grad_norm": 1.1408050060272217,
      "learning_rate": 0.00095991643454039,
      "loss": 2.411,
      "step": 1440
    },
    {
      "epoch": 0.403899721448468,
      "grad_norm": 1.1366922855377197,
      "learning_rate": 0.0009596378830083565,
      "loss": 2.3751,
      "step": 1450
    },
    {
      "epoch": 0.40668523676880225,
      "grad_norm": 1.4062976837158203,
      "learning_rate": 0.0009593593314763232,
      "loss": 2.5531,
      "step": 1460
    },
    {
      "epoch": 0.40947075208913647,
      "grad_norm": 1.335235834121704,
      "learning_rate": 0.0009590807799442897,
      "loss": 2.5434,
      "step": 1470
    },
    {
      "epoch": 0.41225626740947074,
      "grad_norm": 3.3134031295776367,
      "learning_rate": 0.0009588022284122563,
      "loss": 2.7846,
      "step": 1480
    },
    {
      "epoch": 0.415041782729805,
      "grad_norm": 1.0454902648925781,
      "learning_rate": 0.000958523676880223,
      "loss": 2.5277,
      "step": 1490
    },
    {
      "epoch": 0.4178272980501393,
      "grad_norm": 1.2939006090164185,
      "learning_rate": 0.0009582451253481894,
      "loss": 2.6115,
      "step": 1500
    },
    {
      "epoch": 0.4206128133704735,
      "grad_norm": 1.9945476055145264,
      "learning_rate": 0.000957966573816156,
      "loss": 2.6617,
      "step": 1510
    },
    {
      "epoch": 0.4233983286908078,
      "grad_norm": 1.3265721797943115,
      "learning_rate": 0.0009576880222841225,
      "loss": 2.686,
      "step": 1520
    },
    {
      "epoch": 0.42618384401114207,
      "grad_norm": 0.9371128082275391,
      "learning_rate": 0.0009574094707520892,
      "loss": 2.5515,
      "step": 1530
    },
    {
      "epoch": 0.42896935933147634,
      "grad_norm": 1.3978512287139893,
      "learning_rate": 0.0009571309192200557,
      "loss": 2.6325,
      "step": 1540
    },
    {
      "epoch": 0.43175487465181056,
      "grad_norm": 1.2752435207366943,
      "learning_rate": 0.0009568523676880223,
      "loss": 2.636,
      "step": 1550
    },
    {
      "epoch": 0.43454038997214484,
      "grad_norm": 1.6711556911468506,
      "learning_rate": 0.0009565738161559889,
      "loss": 2.567,
      "step": 1560
    },
    {
      "epoch": 0.4373259052924791,
      "grad_norm": 1.335307240486145,
      "learning_rate": 0.0009562952646239555,
      "loss": 2.6164,
      "step": 1570
    },
    {
      "epoch": 0.4401114206128134,
      "grad_norm": 1.1553456783294678,
      "learning_rate": 0.0009560167130919221,
      "loss": 2.6844,
      "step": 1580
    },
    {
      "epoch": 0.4428969359331476,
      "grad_norm": 1.7144556045532227,
      "learning_rate": 0.0009557381615598885,
      "loss": 2.6237,
      "step": 1590
    },
    {
      "epoch": 0.4456824512534819,
      "grad_norm": 1.1878187656402588,
      "learning_rate": 0.0009554596100278552,
      "loss": 2.5384,
      "step": 1600
    },
    {
      "epoch": 0.44846796657381616,
      "grad_norm": 1.1038094758987427,
      "learning_rate": 0.0009551810584958217,
      "loss": 2.5169,
      "step": 1610
    },
    {
      "epoch": 0.45125348189415043,
      "grad_norm": 1.7697409391403198,
      "learning_rate": 0.0009549025069637883,
      "loss": 2.5856,
      "step": 1620
    },
    {
      "epoch": 0.45403899721448465,
      "grad_norm": 1.2317006587982178,
      "learning_rate": 0.0009546239554317548,
      "loss": 2.6675,
      "step": 1630
    },
    {
      "epoch": 0.4568245125348189,
      "grad_norm": 1.1886661052703857,
      "learning_rate": 0.0009543454038997215,
      "loss": 2.4544,
      "step": 1640
    },
    {
      "epoch": 0.4596100278551532,
      "grad_norm": 1.1133674383163452,
      "learning_rate": 0.0009540668523676881,
      "loss": 2.5635,
      "step": 1650
    },
    {
      "epoch": 0.4623955431754875,
      "grad_norm": 1.9716854095458984,
      "learning_rate": 0.0009537883008356546,
      "loss": 2.8094,
      "step": 1660
    },
    {
      "epoch": 0.46518105849582175,
      "grad_norm": 1.365518569946289,
      "learning_rate": 0.0009535097493036213,
      "loss": 2.6355,
      "step": 1670
    },
    {
      "epoch": 0.467966573816156,
      "grad_norm": 1.402441382408142,
      "learning_rate": 0.0009532311977715878,
      "loss": 2.3999,
      "step": 1680
    },
    {
      "epoch": 0.47075208913649025,
      "grad_norm": 1.7524722814559937,
      "learning_rate": 0.0009529526462395543,
      "loss": 2.7777,
      "step": 1690
    },
    {
      "epoch": 0.4735376044568245,
      "grad_norm": 1.1459492444992065,
      "learning_rate": 0.0009526740947075208,
      "loss": 2.564,
      "step": 1700
    },
    {
      "epoch": 0.4763231197771588,
      "grad_norm": 7.510284423828125,
      "learning_rate": 0.0009523955431754875,
      "loss": 2.6053,
      "step": 1710
    },
    {
      "epoch": 0.479108635097493,
      "grad_norm": 1.5252152681350708,
      "learning_rate": 0.0009521169916434541,
      "loss": 2.4871,
      "step": 1720
    },
    {
      "epoch": 0.4818941504178273,
      "grad_norm": 1.2871932983398438,
      "learning_rate": 0.0009518384401114206,
      "loss": 2.5053,
      "step": 1730
    },
    {
      "epoch": 0.48467966573816157,
      "grad_norm": 1.7470824718475342,
      "learning_rate": 0.0009515598885793872,
      "loss": 2.7847,
      "step": 1740
    },
    {
      "epoch": 0.48746518105849584,
      "grad_norm": 0.9987716674804688,
      "learning_rate": 0.0009512813370473538,
      "loss": 2.7062,
      "step": 1750
    },
    {
      "epoch": 0.49025069637883006,
      "grad_norm": 1.338960886001587,
      "learning_rate": 0.0009510027855153204,
      "loss": 2.5096,
      "step": 1760
    },
    {
      "epoch": 0.49303621169916434,
      "grad_norm": 1.1796753406524658,
      "learning_rate": 0.0009507242339832869,
      "loss": 2.536,
      "step": 1770
    },
    {
      "epoch": 0.4958217270194986,
      "grad_norm": 1.287132740020752,
      "learning_rate": 0.0009504456824512536,
      "loss": 2.5299,
      "step": 1780
    },
    {
      "epoch": 0.4986072423398329,
      "grad_norm": 1.1568644046783447,
      "learning_rate": 0.00095016713091922,
      "loss": 2.5204,
      "step": 1790
    },
    {
      "epoch": 0.5013927576601671,
      "grad_norm": 1.163244605064392,
      "learning_rate": 0.0009498885793871866,
      "loss": 2.5523,
      "step": 1800
    },
    {
      "epoch": 0.5041782729805014,
      "grad_norm": 1.148862600326538,
      "learning_rate": 0.0009496100278551532,
      "loss": 2.1509,
      "step": 1810
    },
    {
      "epoch": 0.5069637883008357,
      "grad_norm": 1.3004590272903442,
      "learning_rate": 0.0009493314763231198,
      "loss": 2.5613,
      "step": 1820
    },
    {
      "epoch": 0.5097493036211699,
      "grad_norm": 1.424458622932434,
      "learning_rate": 0.0009490529247910864,
      "loss": 2.6177,
      "step": 1830
    },
    {
      "epoch": 0.5125348189415042,
      "grad_norm": 1.2391772270202637,
      "learning_rate": 0.0009487743732590529,
      "loss": 2.2701,
      "step": 1840
    },
    {
      "epoch": 0.5153203342618384,
      "grad_norm": 1.0167710781097412,
      "learning_rate": 0.0009484958217270196,
      "loss": 2.561,
      "step": 1850
    },
    {
      "epoch": 0.5181058495821727,
      "grad_norm": 1.1867314577102661,
      "learning_rate": 0.0009482172701949861,
      "loss": 2.6917,
      "step": 1860
    },
    {
      "epoch": 0.520891364902507,
      "grad_norm": 1.193684458732605,
      "learning_rate": 0.0009479387186629527,
      "loss": 2.7426,
      "step": 1870
    },
    {
      "epoch": 0.5236768802228412,
      "grad_norm": 1.7442216873168945,
      "learning_rate": 0.0009476601671309193,
      "loss": 2.6804,
      "step": 1880
    },
    {
      "epoch": 0.5264623955431755,
      "grad_norm": 1.3376418352127075,
      "learning_rate": 0.0009473816155988858,
      "loss": 2.6356,
      "step": 1890
    },
    {
      "epoch": 0.5292479108635098,
      "grad_norm": 1.4306271076202393,
      "learning_rate": 0.0009471030640668524,
      "loss": 2.3171,
      "step": 1900
    },
    {
      "epoch": 0.532033426183844,
      "grad_norm": 1.5463263988494873,
      "learning_rate": 0.0009468245125348189,
      "loss": 2.6849,
      "step": 1910
    },
    {
      "epoch": 0.5348189415041783,
      "grad_norm": 1.184936761856079,
      "learning_rate": 0.0009465459610027855,
      "loss": 2.5248,
      "step": 1920
    },
    {
      "epoch": 0.5376044568245125,
      "grad_norm": 1.2416313886642456,
      "learning_rate": 0.0009462674094707521,
      "loss": 2.7187,
      "step": 1930
    },
    {
      "epoch": 0.5403899721448467,
      "grad_norm": 1.124880313873291,
      "learning_rate": 0.0009459888579387187,
      "loss": 2.3432,
      "step": 1940
    },
    {
      "epoch": 0.5431754874651811,
      "grad_norm": 1.4465066194534302,
      "learning_rate": 0.0009457103064066852,
      "loss": 2.7065,
      "step": 1950
    },
    {
      "epoch": 0.5459610027855153,
      "grad_norm": 1.2358649969100952,
      "learning_rate": 0.0009454317548746519,
      "loss": 2.6932,
      "step": 1960
    },
    {
      "epoch": 0.5487465181058496,
      "grad_norm": 1.2498185634613037,
      "learning_rate": 0.0009451532033426185,
      "loss": 2.556,
      "step": 1970
    },
    {
      "epoch": 0.5515320334261838,
      "grad_norm": 1.4456546306610107,
      "learning_rate": 0.000944874651810585,
      "loss": 2.5335,
      "step": 1980
    },
    {
      "epoch": 0.5543175487465181,
      "grad_norm": 1.2559243440628052,
      "learning_rate": 0.0009445961002785515,
      "loss": 2.3494,
      "step": 1990
    },
    {
      "epoch": 0.5571030640668524,
      "grad_norm": 1.206810712814331,
      "learning_rate": 0.0009443175487465181,
      "loss": 2.5171,
      "step": 2000
    },
    {
      "epoch": 0.5598885793871866,
      "grad_norm": 1.7402015924453735,
      "learning_rate": 0.0009440389972144847,
      "loss": 2.528,
      "step": 2010
    },
    {
      "epoch": 0.5626740947075209,
      "grad_norm": 1.1082751750946045,
      "learning_rate": 0.0009437604456824512,
      "loss": 2.5047,
      "step": 2020
    },
    {
      "epoch": 0.5654596100278552,
      "grad_norm": 1.6649291515350342,
      "learning_rate": 0.0009434818941504178,
      "loss": 2.6178,
      "step": 2030
    },
    {
      "epoch": 0.5682451253481894,
      "grad_norm": 1.6362732648849487,
      "learning_rate": 0.0009432033426183845,
      "loss": 2.5183,
      "step": 2040
    },
    {
      "epoch": 0.5710306406685237,
      "grad_norm": 1.33102285861969,
      "learning_rate": 0.000942924791086351,
      "loss": 2.5807,
      "step": 2050
    },
    {
      "epoch": 0.5738161559888579,
      "grad_norm": 1.0900118350982666,
      "learning_rate": 0.0009426462395543176,
      "loss": 2.4656,
      "step": 2060
    },
    {
      "epoch": 0.5766016713091922,
      "grad_norm": 1.745469570159912,
      "learning_rate": 0.0009423676880222842,
      "loss": 2.4451,
      "step": 2070
    },
    {
      "epoch": 0.5793871866295265,
      "grad_norm": 1.1367565393447876,
      "learning_rate": 0.0009420891364902508,
      "loss": 2.5539,
      "step": 2080
    },
    {
      "epoch": 0.5821727019498607,
      "grad_norm": 1.6965676546096802,
      "learning_rate": 0.0009418105849582172,
      "loss": 2.6322,
      "step": 2090
    },
    {
      "epoch": 0.584958217270195,
      "grad_norm": 1.3401778936386108,
      "learning_rate": 0.0009415320334261838,
      "loss": 2.534,
      "step": 2100
    },
    {
      "epoch": 0.5877437325905293,
      "grad_norm": 1.1287577152252197,
      "learning_rate": 0.0009412534818941504,
      "loss": 2.6249,
      "step": 2110
    },
    {
      "epoch": 0.5905292479108635,
      "grad_norm": 1.3366490602493286,
      "learning_rate": 0.000940974930362117,
      "loss": 2.5586,
      "step": 2120
    },
    {
      "epoch": 0.5933147632311978,
      "grad_norm": 1.8460195064544678,
      "learning_rate": 0.0009406963788300836,
      "loss": 2.6206,
      "step": 2130
    },
    {
      "epoch": 0.596100278551532,
      "grad_norm": 1.9260218143463135,
      "learning_rate": 0.0009404178272980502,
      "loss": 2.7042,
      "step": 2140
    },
    {
      "epoch": 0.5988857938718662,
      "grad_norm": 1.5443943738937378,
      "learning_rate": 0.0009401392757660168,
      "loss": 2.4039,
      "step": 2150
    },
    {
      "epoch": 0.6016713091922006,
      "grad_norm": 0.9831684231758118,
      "learning_rate": 0.0009398607242339833,
      "loss": 2.4131,
      "step": 2160
    },
    {
      "epoch": 0.6044568245125348,
      "grad_norm": 1.2676228284835815,
      "learning_rate": 0.0009395821727019499,
      "loss": 2.5306,
      "step": 2170
    },
    {
      "epoch": 0.6072423398328691,
      "grad_norm": 1.2655693292617798,
      "learning_rate": 0.0009393036211699164,
      "loss": 2.4938,
      "step": 2180
    },
    {
      "epoch": 0.6100278551532033,
      "grad_norm": 0.9881119728088379,
      "learning_rate": 0.000939025069637883,
      "loss": 2.6313,
      "step": 2190
    },
    {
      "epoch": 0.6128133704735376,
      "grad_norm": 1.1482727527618408,
      "learning_rate": 0.0009387465181058496,
      "loss": 2.7808,
      "step": 2200
    },
    {
      "epoch": 0.6155988857938719,
      "grad_norm": 1.144348382949829,
      "learning_rate": 0.0009384679665738161,
      "loss": 2.5364,
      "step": 2210
    },
    {
      "epoch": 0.6183844011142061,
      "grad_norm": 1.1865334510803223,
      "learning_rate": 0.0009381894150417828,
      "loss": 2.3514,
      "step": 2220
    },
    {
      "epoch": 0.6211699164345403,
      "grad_norm": 1.1391347646713257,
      "learning_rate": 0.0009379108635097493,
      "loss": 2.5811,
      "step": 2230
    },
    {
      "epoch": 0.6239554317548747,
      "grad_norm": 1.3156872987747192,
      "learning_rate": 0.0009376323119777159,
      "loss": 2.4006,
      "step": 2240
    },
    {
      "epoch": 0.6267409470752089,
      "grad_norm": 1.3639733791351318,
      "learning_rate": 0.0009373537604456825,
      "loss": 2.5577,
      "step": 2250
    },
    {
      "epoch": 0.6295264623955432,
      "grad_norm": 1.174679160118103,
      "learning_rate": 0.0009370752089136491,
      "loss": 2.7211,
      "step": 2260
    },
    {
      "epoch": 0.6323119777158774,
      "grad_norm": 1.532568335533142,
      "learning_rate": 0.0009367966573816156,
      "loss": 2.7403,
      "step": 2270
    },
    {
      "epoch": 0.6350974930362117,
      "grad_norm": 1.4306436777114868,
      "learning_rate": 0.0009365181058495821,
      "loss": 2.5863,
      "step": 2280
    },
    {
      "epoch": 0.637883008356546,
      "grad_norm": 1.4753378629684448,
      "learning_rate": 0.0009362395543175488,
      "loss": 2.5551,
      "step": 2290
    },
    {
      "epoch": 0.6406685236768802,
      "grad_norm": 1.4872273206710815,
      "learning_rate": 0.0009359610027855153,
      "loss": 2.7422,
      "step": 2300
    },
    {
      "epoch": 0.6434540389972145,
      "grad_norm": 1.1254687309265137,
      "learning_rate": 0.0009356824512534819,
      "loss": 2.5091,
      "step": 2310
    },
    {
      "epoch": 0.6462395543175488,
      "grad_norm": 1.2862012386322021,
      "learning_rate": 0.0009354038997214485,
      "loss": 2.5518,
      "step": 2320
    },
    {
      "epoch": 0.649025069637883,
      "grad_norm": 1.3595821857452393,
      "learning_rate": 0.0009351253481894151,
      "loss": 2.4441,
      "step": 2330
    },
    {
      "epoch": 0.6518105849582173,
      "grad_norm": 1.102573275566101,
      "learning_rate": 0.0009348467966573816,
      "loss": 2.3341,
      "step": 2340
    },
    {
      "epoch": 0.6545961002785515,
      "grad_norm": 1.533652901649475,
      "learning_rate": 0.0009345682451253482,
      "loss": 2.4908,
      "step": 2350
    },
    {
      "epoch": 0.6573816155988857,
      "grad_norm": 1.5299750566482544,
      "learning_rate": 0.0009342896935933149,
      "loss": 2.6004,
      "step": 2360
    },
    {
      "epoch": 0.6601671309192201,
      "grad_norm": 1.0821197032928467,
      "learning_rate": 0.0009340111420612814,
      "loss": 2.6225,
      "step": 2370
    },
    {
      "epoch": 0.6629526462395543,
      "grad_norm": 1.1534849405288696,
      "learning_rate": 0.000933732590529248,
      "loss": 2.4417,
      "step": 2380
    },
    {
      "epoch": 0.6657381615598886,
      "grad_norm": 1.0310934782028198,
      "learning_rate": 0.0009334540389972144,
      "loss": 2.5188,
      "step": 2390
    },
    {
      "epoch": 0.6685236768802229,
      "grad_norm": 1.2364609241485596,
      "learning_rate": 0.0009331754874651811,
      "loss": 2.2814,
      "step": 2400
    },
    {
      "epoch": 0.6713091922005571,
      "grad_norm": 1.021937370300293,
      "learning_rate": 0.0009328969359331476,
      "loss": 2.525,
      "step": 2410
    },
    {
      "epoch": 0.6740947075208914,
      "grad_norm": 1.1188453435897827,
      "learning_rate": 0.0009326183844011142,
      "loss": 2.637,
      "step": 2420
    },
    {
      "epoch": 0.6768802228412256,
      "grad_norm": 1.3072495460510254,
      "learning_rate": 0.0009323398328690808,
      "loss": 2.4784,
      "step": 2430
    },
    {
      "epoch": 0.6796657381615598,
      "grad_norm": 1.2688318490982056,
      "learning_rate": 0.0009320612813370474,
      "loss": 2.5733,
      "step": 2440
    },
    {
      "epoch": 0.6824512534818942,
      "grad_norm": 1.2329766750335693,
      "learning_rate": 0.000931782729805014,
      "loss": 2.5463,
      "step": 2450
    },
    {
      "epoch": 0.6852367688022284,
      "grad_norm": 1.4346177577972412,
      "learning_rate": 0.0009315041782729805,
      "loss": 2.5082,
      "step": 2460
    },
    {
      "epoch": 0.6880222841225627,
      "grad_norm": 2.4677248001098633,
      "learning_rate": 0.0009312256267409472,
      "loss": 2.5901,
      "step": 2470
    },
    {
      "epoch": 0.6908077994428969,
      "grad_norm": 1.1987907886505127,
      "learning_rate": 0.0009309470752089136,
      "loss": 2.5878,
      "step": 2480
    },
    {
      "epoch": 0.6935933147632312,
      "grad_norm": 1.2632218599319458,
      "learning_rate": 0.0009306685236768802,
      "loss": 2.5329,
      "step": 2490
    },
    {
      "epoch": 0.6963788300835655,
      "grad_norm": 1.2860089540481567,
      "learning_rate": 0.0009303899721448468,
      "loss": 2.4634,
      "step": 2500
    },
    {
      "epoch": 0.6991643454038997,
      "grad_norm": 1.378875970840454,
      "learning_rate": 0.0009301114206128134,
      "loss": 2.6547,
      "step": 2510
    },
    {
      "epoch": 0.7019498607242339,
      "grad_norm": 1.2580184936523438,
      "learning_rate": 0.0009298328690807799,
      "loss": 2.7712,
      "step": 2520
    },
    {
      "epoch": 0.7047353760445683,
      "grad_norm": 1.05880868434906,
      "learning_rate": 0.0009295543175487465,
      "loss": 2.2454,
      "step": 2530
    },
    {
      "epoch": 0.7075208913649025,
      "grad_norm": 1.0613309144973755,
      "learning_rate": 0.0009292757660167132,
      "loss": 2.5936,
      "step": 2540
    },
    {
      "epoch": 0.7103064066852368,
      "grad_norm": 1.392040729522705,
      "learning_rate": 0.0009289972144846797,
      "loss": 2.6245,
      "step": 2550
    },
    {
      "epoch": 0.713091922005571,
      "grad_norm": 0.9483211636543274,
      "learning_rate": 0.0009287186629526463,
      "loss": 2.5132,
      "step": 2560
    },
    {
      "epoch": 0.7158774373259053,
      "grad_norm": 1.5085972547531128,
      "learning_rate": 0.0009284401114206127,
      "loss": 2.5447,
      "step": 2570
    },
    {
      "epoch": 0.7186629526462396,
      "grad_norm": 1.1602801084518433,
      "learning_rate": 0.0009281615598885794,
      "loss": 2.4016,
      "step": 2580
    },
    {
      "epoch": 0.7214484679665738,
      "grad_norm": 1.3816580772399902,
      "learning_rate": 0.0009278830083565459,
      "loss": 2.6206,
      "step": 2590
    },
    {
      "epoch": 0.724233983286908,
      "grad_norm": 1.1086705923080444,
      "learning_rate": 0.0009276044568245125,
      "loss": 2.5344,
      "step": 2600
    },
    {
      "epoch": 0.7270194986072424,
      "grad_norm": 1.0299288034439087,
      "learning_rate": 0.0009273259052924792,
      "loss": 2.4897,
      "step": 2610
    },
    {
      "epoch": 0.7298050139275766,
      "grad_norm": 1.7090506553649902,
      "learning_rate": 0.0009270473537604457,
      "loss": 2.5758,
      "step": 2620
    },
    {
      "epoch": 0.7325905292479109,
      "grad_norm": 1.1588163375854492,
      "learning_rate": 0.0009267688022284123,
      "loss": 2.4412,
      "step": 2630
    },
    {
      "epoch": 0.7353760445682451,
      "grad_norm": 1.1340761184692383,
      "learning_rate": 0.0009264902506963788,
      "loss": 2.474,
      "step": 2640
    },
    {
      "epoch": 0.7381615598885793,
      "grad_norm": 2.122035264968872,
      "learning_rate": 0.0009262116991643455,
      "loss": 2.6817,
      "step": 2650
    },
    {
      "epoch": 0.7409470752089137,
      "grad_norm": 1.1821680068969727,
      "learning_rate": 0.000925933147632312,
      "loss": 2.4353,
      "step": 2660
    },
    {
      "epoch": 0.7437325905292479,
      "grad_norm": 1.3817375898361206,
      "learning_rate": 0.0009256545961002786,
      "loss": 2.5588,
      "step": 2670
    },
    {
      "epoch": 0.7465181058495822,
      "grad_norm": 1.2401751279830933,
      "learning_rate": 0.0009253760445682451,
      "loss": 2.2828,
      "step": 2680
    },
    {
      "epoch": 0.7493036211699164,
      "grad_norm": 1.2571775913238525,
      "learning_rate": 0.0009250974930362117,
      "loss": 2.4972,
      "step": 2690
    },
    {
      "epoch": 0.7520891364902507,
      "grad_norm": 1.6825190782546997,
      "learning_rate": 0.0009248189415041783,
      "loss": 2.4345,
      "step": 2700
    },
    {
      "epoch": 0.754874651810585,
      "grad_norm": 1.2267513275146484,
      "learning_rate": 0.0009245403899721448,
      "loss": 2.5957,
      "step": 2710
    },
    {
      "epoch": 0.7576601671309192,
      "grad_norm": 1.5243191719055176,
      "learning_rate": 0.0009242618384401115,
      "loss": 2.4952,
      "step": 2720
    },
    {
      "epoch": 0.7604456824512534,
      "grad_norm": 1.1846650838851929,
      "learning_rate": 0.000923983286908078,
      "loss": 2.5663,
      "step": 2730
    },
    {
      "epoch": 0.7632311977715878,
      "grad_norm": 1.1917568445205688,
      "learning_rate": 0.0009237047353760446,
      "loss": 2.4529,
      "step": 2740
    },
    {
      "epoch": 0.766016713091922,
      "grad_norm": 1.352648377418518,
      "learning_rate": 0.0009234261838440111,
      "loss": 2.6413,
      "step": 2750
    },
    {
      "epoch": 0.7688022284122563,
      "grad_norm": 1.727471947669983,
      "learning_rate": 0.0009231476323119778,
      "loss": 2.3129,
      "step": 2760
    },
    {
      "epoch": 0.7715877437325905,
      "grad_norm": 1.5598509311676025,
      "learning_rate": 0.0009228690807799444,
      "loss": 2.5441,
      "step": 2770
    },
    {
      "epoch": 0.7743732590529248,
      "grad_norm": 1.1470754146575928,
      "learning_rate": 0.0009225905292479108,
      "loss": 2.3836,
      "step": 2780
    },
    {
      "epoch": 0.7771587743732591,
      "grad_norm": 1.4743454456329346,
      "learning_rate": 0.0009223119777158775,
      "loss": 2.7022,
      "step": 2790
    },
    {
      "epoch": 0.7799442896935933,
      "grad_norm": 1.1145402193069458,
      "learning_rate": 0.000922033426183844,
      "loss": 2.3814,
      "step": 2800
    },
    {
      "epoch": 0.7827298050139275,
      "grad_norm": 1.4922983646392822,
      "learning_rate": 0.0009217548746518106,
      "loss": 2.5209,
      "step": 2810
    },
    {
      "epoch": 0.7855153203342619,
      "grad_norm": 1.3594104051589966,
      "learning_rate": 0.0009214763231197771,
      "loss": 2.6745,
      "step": 2820
    },
    {
      "epoch": 0.7883008356545961,
      "grad_norm": 1.466610074043274,
      "learning_rate": 0.0009211977715877438,
      "loss": 2.7521,
      "step": 2830
    },
    {
      "epoch": 0.7910863509749304,
      "grad_norm": 1.4076071977615356,
      "learning_rate": 0.0009209192200557103,
      "loss": 2.511,
      "step": 2840
    },
    {
      "epoch": 0.7938718662952646,
      "grad_norm": 1.1187593936920166,
      "learning_rate": 0.0009206406685236769,
      "loss": 2.399,
      "step": 2850
    },
    {
      "epoch": 0.7966573816155988,
      "grad_norm": 1.06912362575531,
      "learning_rate": 0.0009203621169916436,
      "loss": 2.4725,
      "step": 2860
    },
    {
      "epoch": 0.7994428969359332,
      "grad_norm": 1.273851990699768,
      "learning_rate": 0.00092008356545961,
      "loss": 2.2137,
      "step": 2870
    },
    {
      "epoch": 0.8022284122562674,
      "grad_norm": 1.1153093576431274,
      "learning_rate": 0.0009198050139275766,
      "loss": 2.4395,
      "step": 2880
    },
    {
      "epoch": 0.8050139275766016,
      "grad_norm": 1.678955316543579,
      "learning_rate": 0.0009195264623955431,
      "loss": 2.468,
      "step": 2890
    },
    {
      "epoch": 0.807799442896936,
      "grad_norm": 0.9879109859466553,
      "learning_rate": 0.0009192479108635098,
      "loss": 2.4845,
      "step": 2900
    },
    {
      "epoch": 0.8105849582172702,
      "grad_norm": 1.1129482984542847,
      "learning_rate": 0.0009189693593314763,
      "loss": 2.5903,
      "step": 2910
    },
    {
      "epoch": 0.8133704735376045,
      "grad_norm": 1.3030588626861572,
      "learning_rate": 0.0009186908077994429,
      "loss": 2.5479,
      "step": 2920
    },
    {
      "epoch": 0.8161559888579387,
      "grad_norm": 1.4459642171859741,
      "learning_rate": 0.0009184122562674095,
      "loss": 2.4442,
      "step": 2930
    },
    {
      "epoch": 0.8189415041782729,
      "grad_norm": 1.5102137327194214,
      "learning_rate": 0.0009181337047353761,
      "loss": 2.6095,
      "step": 2940
    },
    {
      "epoch": 0.8217270194986073,
      "grad_norm": 1.2964024543762207,
      "learning_rate": 0.0009178551532033427,
      "loss": 2.6698,
      "step": 2950
    },
    {
      "epoch": 0.8245125348189415,
      "grad_norm": 1.744264841079712,
      "learning_rate": 0.0009175766016713092,
      "loss": 2.7047,
      "step": 2960
    },
    {
      "epoch": 0.8272980501392758,
      "grad_norm": 1.418626308441162,
      "learning_rate": 0.0009172980501392759,
      "loss": 2.4725,
      "step": 2970
    },
    {
      "epoch": 0.83008356545961,
      "grad_norm": 1.689955472946167,
      "learning_rate": 0.0009170194986072423,
      "loss": 2.4886,
      "step": 2980
    },
    {
      "epoch": 0.8328690807799443,
      "grad_norm": 1.708001971244812,
      "learning_rate": 0.0009167409470752089,
      "loss": 2.4697,
      "step": 2990
    },
    {
      "epoch": 0.8356545961002786,
      "grad_norm": 1.0075879096984863,
      "learning_rate": 0.0009164623955431754,
      "loss": 2.5168,
      "step": 3000
    },
    {
      "epoch": 0.8384401114206128,
      "grad_norm": 1.1822031736373901,
      "learning_rate": 0.0009161838440111421,
      "loss": 2.4955,
      "step": 3010
    },
    {
      "epoch": 0.841225626740947,
      "grad_norm": 1.7763776779174805,
      "learning_rate": 0.0009159052924791087,
      "loss": 2.4372,
      "step": 3020
    },
    {
      "epoch": 0.8440111420612814,
      "grad_norm": 1.2953461408615112,
      "learning_rate": 0.0009156267409470752,
      "loss": 2.4257,
      "step": 3030
    },
    {
      "epoch": 0.8467966573816156,
      "grad_norm": 1.6734503507614136,
      "learning_rate": 0.0009153481894150419,
      "loss": 2.5669,
      "step": 3040
    },
    {
      "epoch": 0.8495821727019499,
      "grad_norm": 1.2400703430175781,
      "learning_rate": 0.0009150696378830084,
      "loss": 2.6963,
      "step": 3050
    },
    {
      "epoch": 0.8523676880222841,
      "grad_norm": 1.1290812492370605,
      "learning_rate": 0.000914791086350975,
      "loss": 2.6802,
      "step": 3060
    },
    {
      "epoch": 0.8551532033426184,
      "grad_norm": 1.19234037399292,
      "learning_rate": 0.0009145125348189414,
      "loss": 2.608,
      "step": 3070
    },
    {
      "epoch": 0.8579387186629527,
      "grad_norm": 1.2364051342010498,
      "learning_rate": 0.0009142339832869081,
      "loss": 2.4903,
      "step": 3080
    },
    {
      "epoch": 0.8607242339832869,
      "grad_norm": 1.6729354858398438,
      "learning_rate": 0.0009139554317548747,
      "loss": 2.4627,
      "step": 3090
    },
    {
      "epoch": 0.8635097493036211,
      "grad_norm": 1.8998438119888306,
      "learning_rate": 0.0009136768802228412,
      "loss": 2.4398,
      "step": 3100
    },
    {
      "epoch": 0.8662952646239555,
      "grad_norm": 1.394219160079956,
      "learning_rate": 0.0009133983286908078,
      "loss": 2.5279,
      "step": 3110
    },
    {
      "epoch": 0.8690807799442897,
      "grad_norm": 1.389923095703125,
      "learning_rate": 0.0009131197771587744,
      "loss": 2.4721,
      "step": 3120
    },
    {
      "epoch": 0.871866295264624,
      "grad_norm": 1.3986363410949707,
      "learning_rate": 0.000912841225626741,
      "loss": 2.6389,
      "step": 3130
    },
    {
      "epoch": 0.8746518105849582,
      "grad_norm": 1.2839164733886719,
      "learning_rate": 0.0009125626740947075,
      "loss": 2.5392,
      "step": 3140
    },
    {
      "epoch": 0.8774373259052924,
      "grad_norm": 1.5510696172714233,
      "learning_rate": 0.0009122841225626742,
      "loss": 2.5194,
      "step": 3150
    },
    {
      "epoch": 0.8802228412256268,
      "grad_norm": 1.5165585279464722,
      "learning_rate": 0.0009120055710306407,
      "loss": 2.5704,
      "step": 3160
    },
    {
      "epoch": 0.883008356545961,
      "grad_norm": 1.580206274986267,
      "learning_rate": 0.0009117270194986072,
      "loss": 2.5532,
      "step": 3170
    },
    {
      "epoch": 0.8857938718662952,
      "grad_norm": 1.6651115417480469,
      "learning_rate": 0.0009114484679665738,
      "loss": 2.2884,
      "step": 3180
    },
    {
      "epoch": 0.8885793871866295,
      "grad_norm": 1.1568703651428223,
      "learning_rate": 0.0009111699164345404,
      "loss": 2.6279,
      "step": 3190
    },
    {
      "epoch": 0.8913649025069638,
      "grad_norm": 1.2758097648620605,
      "learning_rate": 0.000910891364902507,
      "loss": 2.2472,
      "step": 3200
    },
    {
      "epoch": 0.8941504178272981,
      "grad_norm": 1.550922155380249,
      "learning_rate": 0.0009106128133704735,
      "loss": 2.6759,
      "step": 3210
    },
    {
      "epoch": 0.8969359331476323,
      "grad_norm": 1.0590204000473022,
      "learning_rate": 0.0009103342618384402,
      "loss": 2.5679,
      "step": 3220
    },
    {
      "epoch": 0.8997214484679665,
      "grad_norm": 1.579368233680725,
      "learning_rate": 0.0009100557103064067,
      "loss": 2.4722,
      "step": 3230
    },
    {
      "epoch": 0.9025069637883009,
      "grad_norm": 1.5835844278335571,
      "learning_rate": 0.0009097771587743733,
      "loss": 2.4494,
      "step": 3240
    },
    {
      "epoch": 0.9052924791086351,
      "grad_norm": 1.220284104347229,
      "learning_rate": 0.0009094986072423399,
      "loss": 2.6299,
      "step": 3250
    },
    {
      "epoch": 0.9080779944289693,
      "grad_norm": 1.1127558946609497,
      "learning_rate": 0.0009092200557103065,
      "loss": 2.4793,
      "step": 3260
    },
    {
      "epoch": 0.9108635097493036,
      "grad_norm": 1.304783582687378,
      "learning_rate": 0.000908941504178273,
      "loss": 2.5737,
      "step": 3270
    },
    {
      "epoch": 0.9136490250696379,
      "grad_norm": 1.5065256357192993,
      "learning_rate": 0.0009086629526462395,
      "loss": 2.3658,
      "step": 3280
    },
    {
      "epoch": 0.9164345403899722,
      "grad_norm": 1.7429677248001099,
      "learning_rate": 0.0009083844011142061,
      "loss": 2.5065,
      "step": 3290
    },
    {
      "epoch": 0.9192200557103064,
      "grad_norm": 1.2562928199768066,
      "learning_rate": 0.0009081058495821727,
      "loss": 2.6153,
      "step": 3300
    },
    {
      "epoch": 0.9220055710306406,
      "grad_norm": 1.0412288904190063,
      "learning_rate": 0.0009078272980501393,
      "loss": 2.3057,
      "step": 3310
    },
    {
      "epoch": 0.924791086350975,
      "grad_norm": 1.628635287284851,
      "learning_rate": 0.0009075487465181058,
      "loss": 2.608,
      "step": 3320
    },
    {
      "epoch": 0.9275766016713092,
      "grad_norm": 1.3479400873184204,
      "learning_rate": 0.0009072701949860725,
      "loss": 2.5453,
      "step": 3330
    },
    {
      "epoch": 0.9303621169916435,
      "grad_norm": 1.532528042793274,
      "learning_rate": 0.0009069916434540391,
      "loss": 2.6629,
      "step": 3340
    },
    {
      "epoch": 0.9331476323119777,
      "grad_norm": 1.1401934623718262,
      "learning_rate": 0.0009067130919220056,
      "loss": 2.4911,
      "step": 3350
    },
    {
      "epoch": 0.935933147632312,
      "grad_norm": 1.4988995790481567,
      "learning_rate": 0.0009064345403899722,
      "loss": 2.4127,
      "step": 3360
    },
    {
      "epoch": 0.9387186629526463,
      "grad_norm": 1.8984172344207764,
      "learning_rate": 0.0009061559888579387,
      "loss": 2.5183,
      "step": 3370
    },
    {
      "epoch": 0.9415041782729805,
      "grad_norm": 2.886582136154175,
      "learning_rate": 0.0009058774373259053,
      "loss": 2.434,
      "step": 3380
    },
    {
      "epoch": 0.9442896935933147,
      "grad_norm": 1.317057728767395,
      "learning_rate": 0.0009055988857938718,
      "loss": 2.5229,
      "step": 3390
    },
    {
      "epoch": 0.947075208913649,
      "grad_norm": 0.9273808002471924,
      "learning_rate": 0.0009053203342618385,
      "loss": 2.3869,
      "step": 3400
    },
    {
      "epoch": 0.9498607242339833,
      "grad_norm": 1.631961703300476,
      "learning_rate": 0.0009050417827298051,
      "loss": 2.5104,
      "step": 3410
    },
    {
      "epoch": 0.9526462395543176,
      "grad_norm": 1.120706558227539,
      "learning_rate": 0.0009047632311977716,
      "loss": 2.6222,
      "step": 3420
    },
    {
      "epoch": 0.9554317548746518,
      "grad_norm": 1.6801543235778809,
      "learning_rate": 0.0009044846796657382,
      "loss": 2.658,
      "step": 3430
    },
    {
      "epoch": 0.958217270194986,
      "grad_norm": 1.4296263456344604,
      "learning_rate": 0.0009042061281337048,
      "loss": 2.6003,
      "step": 3440
    },
    {
      "epoch": 0.9610027855153204,
      "grad_norm": 1.5682204961776733,
      "learning_rate": 0.0009039275766016714,
      "loss": 2.4021,
      "step": 3450
    },
    {
      "epoch": 0.9637883008356546,
      "grad_norm": 1.559866189956665,
      "learning_rate": 0.0009036490250696378,
      "loss": 2.5678,
      "step": 3460
    },
    {
      "epoch": 0.9665738161559888,
      "grad_norm": 1.3528755903244019,
      "learning_rate": 0.0009033704735376044,
      "loss": 2.8601,
      "step": 3470
    },
    {
      "epoch": 0.9693593314763231,
      "grad_norm": 1.7843915224075317,
      "learning_rate": 0.000903091922005571,
      "loss": 2.5616,
      "step": 3480
    },
    {
      "epoch": 0.9721448467966574,
      "grad_norm": 1.2097856998443604,
      "learning_rate": 0.0009028133704735376,
      "loss": 2.5941,
      "step": 3490
    },
    {
      "epoch": 0.9749303621169917,
      "grad_norm": 1.5091629028320312,
      "learning_rate": 0.0009025348189415042,
      "loss": 2.4545,
      "step": 3500
    }
  ],
  "logging_steps": 10,
  "max_steps": 35900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 463602843648000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
